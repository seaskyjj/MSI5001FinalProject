{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:06:15.149634Z",
     "iopub.status.busy": "2025-10-12T11:06:15.148859Z",
     "iopub.status.idle": "2025-10-12T11:06:23.155513Z",
     "shell.execute_reply": "2025-10-12T11:06:23.154782Z",
     "shell.execute_reply.started": "2025-10-12T11:06:15.149605Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# This is for the progress bar.\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:06:23.546816Z",
     "iopub.status.busy": "2025-10-12T11:06:23.546233Z",
     "iopub.status.idle": "2025-10-12T11:06:33.822284Z",
     "shell.execute_reply": "2025-10-12T11:06:33.821362Z",
     "shell.execute_reply.started": "2025-10-12T11:06:23.546794Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualize training data\n",
    "# -------- 载入所有 CSV -> 一个 DataFrame (labels_dataframe) --------\n",
    "BASE = Path(\"/kaggle/input/electrical-component/dataset/\")\n",
    "splits = [\"train\"]\n",
    "\n",
    "rows = []\n",
    "for split in splits:\n",
    "    for csv_path in (BASE / split / \"labels\").glob(\"*.csv\"):\n",
    "        stem = csv_path.stem\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        df = df.copy()\n",
    "        df[\"image\"] = f\"{split}/images/{stem}.npy\"  # 记录图像路径/ID\n",
    "        df[\"split\"] = split\n",
    "        rows.append(df[[\"class\", \"image\", \"split\"]])\n",
    "\n",
    "labels_dataframe = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=[\"class\",\"image\",\"split\"])\n",
    "\n",
    "print(\"===== Dataset Summary =====\")\n",
    "print(f\"Total images (CSV files): \", labels_dataframe[\"image\"].nunique())\n",
    "print(f\"Total object instances  : \", len(labels_dataframe))\n",
    "print(f\"Num classes             : \", labels_dataframe[\"class\"].nunique())\n",
    "\n",
    "# -------- 你的条形标注函数 --------\n",
    "def barw(ax):\n",
    "    for p in ax.patches:\n",
    "        val = p.get_width()\n",
    "        x = p.get_x() + p.get_width()\n",
    "        y = p.get_y() + p.get_height()/2\n",
    "        ax.annotate(f\"{val:.0f}\", (x, y), va='center')\n",
    "\n",
    "# 按目标框逐个计数（CSV 的每一行就是一个实例），看每个类别一共标了多少个目标（密度/样本量）\n",
    "# -------- 每类的“实例数”可视化 --------\n",
    "plt.figure(figsize=(14, 0.4 * labels_dataframe[\"class\"].nunique() + 6))\n",
    "ax0 = sns.countplot(\n",
    "    y=labels_dataframe['class'],\n",
    "    order=labels_dataframe['class'].value_counts().index\n",
    ")\n",
    "ax0.set_title(\"Per-class Instance Count\")\n",
    "ax0.set_xlabel(\"instances\")\n",
    "ax0.set_ylabel(\"class\")\n",
    "barw(ax0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 按图像去重后计数——同一张图里就算出现10个零件也算1个，看每个类别覆盖了多少张图像（分布广度）\n",
    "# -------- 每类覆盖的“文件数”(图像数) 可视化（去重 (label, image)）--------\n",
    "files_per_class = (\n",
    "    labels_dataframe[[\"class\", \"image\"]]\n",
    "      .drop_duplicates()                 # 去重同一张图里同一类的多实例\n",
    "      .groupby(\"class\")[\"image\"]\n",
    "      .nunique()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 0.4 * len(files_per_class) + 6))\n",
    "ax1 = sns.barplot(\n",
    "    y=files_per_class.index,\n",
    "    x=files_per_class.values,\n",
    "    orient=\"h\"\n",
    ")\n",
    "ax1.set_title(\"Per-class File Count - Deduplication\")\n",
    "ax1.set_xlabel(\"files (unique images containing the class)\")\n",
    "ax1.set_ylabel(\"class\")\n",
    "barw(ax1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------- 只看 TOP-K 类别 --------\n",
    "TOP_K = 32\n",
    "top_instances = labels_dataframe['class'].value_counts().head(TOP_K)\n",
    "top_files = files_per_class.head(TOP_K)\n",
    "\n",
    "fig, (ax2, ax3) = plt.subplots(nrows=1, ncols=2, figsize=(18, 0.4 * TOP_K + 6), sharey=True)\n",
    "sns.barplot(y=top_instances.index, x=top_instances.values, orient=\"h\", ax=ax2)\n",
    "ax2.set_title(f\"Top-{TOP_K} by Instances\")\n",
    "ax2.set_xlabel(\"instances\"); ax2.set_ylabel(\"class\")\n",
    "barw(ax2)\n",
    "\n",
    "sns.barplot(y=top_files.index, x=top_files.values, orient=\"h\", ax=ax3)\n",
    "ax3.set_title(f\"Top-{TOP_K} by Files\")\n",
    "ax3.set_xlabel(\"files (unique images)\"); ax3.set_ylabel(\"\")\n",
    "barw(ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:06:49.837466Z",
     "iopub.status.busy": "2025-10-12T11:06:49.836819Z",
     "iopub.status.idle": "2025-10-12T11:06:49.872384Z",
     "shell.execute_reply": "2025-10-12T11:06:49.871700Z",
     "shell.execute_reply.started": "2025-10-12T11:06:49.837443Z"
    }
   },
   "outputs": [],
   "source": [
    "# fastercnn_resnet50\n",
    "def _largest_ndarray(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for k in (\"image\",\"img\",\"array\",\"data\",\"X\",\"arr\"):\n",
    "            if k in obj and isinstance(obj[k], np.ndarray):\n",
    "                return obj[k]\n",
    "        cands = [v for v in obj.values() if isinstance(v, np.ndarray)]\n",
    "        return max(cands, key=lambda a: a.size)\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        cands = [v for v in obj if isinstance(v, np.ndarray)]\n",
    "        return max(cands, key=lambda a: a.size)\n",
    "    return obj\n",
    "\n",
    "def load_image_hwc_uint8(npy_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    假设 .npy 存的是 HWC, ndim=3。\n",
    "    - 若 dtype 非 uint8, 自动判断 0~1 / -1~1 并映射到 0~255\n",
    "    - 若为单通道或带 alpha, 自动处理到 3 通道 RGB\n",
    "    \"\"\"\n",
    "    a = np.load(npy_path, allow_pickle=False)  # 已知是 HWC, ndim=3\n",
    "    if a.dtype != np.uint8:\n",
    "        a = a.astype(np.float32, copy=False)\n",
    "        vmin, vmax = float(a.min()), float(a.max())\n",
    "        if 0.0 <= vmin and vmax <= 1.0:\n",
    "            a = (a * 255.0).round()\n",
    "        elif -1.0 <= vmin and vmax <= 1.0:\n",
    "            a = ((a + 1.0) * 0.5 * 255.0).round()\n",
    "        # 否则认为已经接近 0..255，不再缩放\n",
    "        a = np.clip(a, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # 通道处理：1通道 -> 3通道；4通道 -> 丢 alpha\n",
    "    c = a.shape[2]\n",
    "    if c == 1:\n",
    "        a = np.repeat(a, 3, axis=2)\n",
    "    elif c == 4:\n",
    "        a = a[..., :3]\n",
    "    return a  # HWC uint8(3)\n",
    "\n",
    "class NpyDetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    返回：\n",
    "      image: FloatTensor [3,H,W] (0..1)\n",
    "      target: dict(boxes: [N,4] xyxy, labels: [N], image_id, size=[H,W])\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir, split=\"train\", transform=None):\n",
    "        base = Path(base_dir)\n",
    "        self.img_dir = base / split / \"images\"\n",
    "        self.lbl_dir = base / split / \"labels\"\n",
    "        self.stems = sorted([p.stem for p in self.lbl_dir.glob(\"*.csv\")])\n",
    "        self.transform = transform\n",
    "\n",
    "        # 一次性把所有 CSV 读到内存，避免训练期I/O瓶颈\n",
    "        self.ann = {s: pd.read_csv(self.lbl_dir / f\"{s}.csv\") for s in self.stems}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        stem = self.stems[idx]\n",
    "        img_path = self.img_dir / f\"{stem}.npy\"\n",
    "        img = load_image_hwc_uint8(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        df = self.ann[stem].copy()\n",
    "        x_c = df[\"x_center\"].astype(\"float32\").to_numpy()\n",
    "        y_c = df[\"y_center\"].astype(\"float32\").to_numpy()\n",
    "        bw  = df[\"width\"].astype(\"float32\").to_numpy()\n",
    "        bh  = df[\"height\"].astype(\"float32\").to_numpy()\n",
    "\n",
    "        # 自动识别是否为归一化\n",
    "        if x_c.max() <= 1.0 and y_c.max() <= 1.0 and bw.max() <= 1.0 and bh.max() <= 1.0:\n",
    "            x_c *= w; y_c *= h; bw *= w; bh *= h\n",
    "\n",
    "        x1 = x_c - bw/2; y1 = y_c - bh/2\n",
    "        x2 = x_c + bw/2; y2 = y_c + bh/2\n",
    "        boxes = np.stack([x1,y1,x2,y2], axis=1)\n",
    "        boxes[:, [0,2]] = boxes[:, [0,2]].clip(0, w)\n",
    "        boxes[:, [1,3]] = boxes[:, [1,3]].clip(0, h)\n",
    "\n",
    "        labels = df[\"class\"].astype(\"int64\").to_numpy() + 1  # shift to 1-based; reserve 0 for background\n",
    "\n",
    "        img_t = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "        target = {\n",
    "            \"boxes\":  torch.from_numpy(boxes).float(),\n",
    "            \"labels\": torch.from_numpy(labels).long(),\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "            \"size\": torch.tensor([h,w])\n",
    "        }\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_t, target = self.transform(img_t, target)\n",
    "        return img_t, target\n",
    "\n",
    "def det_collate_fn(batch):\n",
    "    imgs, targets = list(zip(*batch))\n",
    "    return list(imgs), list(targets)\n",
    "\n",
    "def build_model(\n",
    "    num_classes,\n",
    "    small_object=False,\n",
    "    # 推理后处理（eval 时生效）\n",
    "    score_thresh=0.30,     # 统一分类阈值（你也可以用外部 per-class 过滤替代），默认是很低的 0.05 左右\n",
    "    nms_thresh=0.4,       # NMS IoU 从 0.5 降到 0.45 或 0.4 试试\n",
    "    max_dets=100,          # 每图最多保留多少个检测 或 100, 视任务而定\n",
    "    # 训练采样/匹配（让负样本多一些，减少 FP）\n",
    "    roi_batch_size=1024,\n",
    "    roi_pos_fraction=0.10,\n",
    "    roi_fg_iou=0.60,\n",
    "    roi_bg_iou=0.40,\n",
    "    # RPN Top-N（可略优化 proposal 质量）\n",
    "    rpn_pre_topn_train=2000,\n",
    "    rpn_pre_topn_test=1000,\n",
    "    rpn_post_topn_train=1000,\n",
    "    rpn_post_topn_test=500,\n",
    "):\n",
    "    # 预训练 Faster R-CNN + ResNet50-FPN\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\", weights_backbone=\"DEFAULT\")\n",
    "\n",
    "    # 可选：更小的 anchors，利于小目标\n",
    "    if small_object:\n",
    "        # 对 FPN 的 5 个特征层分别设定 anchor 尺寸\n",
    "        anchor_sizes = ((16,), (32,), (64,), (128,), (256,))\n",
    "        aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "        model.rpn.anchor_generator = AnchorGenerator(sizes=anchor_sizes,\n",
    "                                                     aspect_ratios=aspect_ratios)\n",
    "\n",
    "    # 换分类头（额外 +1 个 background）\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    num_classes_with_bg = num_classes + 1\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_with_bg)\n",
    "\n",
    "    # ===== 推理后处理（仅 eval 用到）=====\n",
    "    rh = model.roi_heads\n",
    "    # 不同版本可能叫 score_thresh 或 box_score_thresh；都设置以兼容\n",
    "    if hasattr(rh, \"score_thresh\"):       rh.score_thresh = score_thresh\n",
    "    if hasattr(rh, \"box_score_thresh\"):   rh.box_score_thresh = score_thresh\n",
    "    if hasattr(rh, \"nms_thresh\"):         rh.nms_thresh = nms_thresh\n",
    "    if hasattr(rh, \"box_nms_thresh\"):     rh.box_nms_thresh = nms_thresh\n",
    "    if hasattr(rh, \"detections_per_img\"): rh.detections_per_img = max_dets\n",
    "\n",
    "    # ===== 训练采样/匹配（影响 FP/学习难度）=====\n",
    "    if hasattr(rh, \"box_batch_size_per_image\"): rh.box_batch_size_per_image = roi_batch_size\n",
    "    if hasattr(rh, \"positive_fraction\"):        rh.positive_fraction        = roi_pos_fraction\n",
    "    if hasattr(rh, \"box_fg_iou_thresh\"):        rh.box_fg_iou_thresh        = roi_fg_iou\n",
    "    if hasattr(rh, \"box_bg_iou_thresh\"):        rh.box_bg_iou_thresh        = roi_bg_iou\n",
    "\n",
    "    # ===== RPN Top-N（略提高 proposal 质量/数量）=====\n",
    "    rpn = model.rpn\n",
    "    if hasattr(rpn, \"pre_nms_top_n\") and isinstance(rpn.pre_nms_top_n, dict):\n",
    "        rpn.pre_nms_top_n[\"training\"] = rpn_pre_topn_train\n",
    "        rpn.pre_nms_top_n[\"testing\"]  = rpn_pre_topn_test\n",
    "    if hasattr(rpn, \"post_nms_top_n\") and isinstance(rpn.post_nms_top_n, dict):\n",
    "        rpn.post_nms_top_n[\"training\"] = rpn_post_topn_train\n",
    "        rpn.post_nms_top_n[\"testing\"]  = rpn_post_topn_test\n",
    "        \n",
    "    return model\n",
    "\n",
    "def box_iou_np(boxes1, boxes2):\n",
    "    \"\"\"boxes: [N,4] & [M,4] in xyxy -> IoU [N,M]\"\"\"\n",
    "    if len(boxes1) == 0 or len(boxes2) == 0:\n",
    "        return np.zeros((len(boxes1), len(boxes2)), dtype=np.float32)\n",
    "\n",
    "    boxes1 = np.asarray(boxes1, dtype=np.float32)\n",
    "    boxes2 = np.asarray(boxes2, dtype=np.float32)\n",
    "\n",
    "    x11 = boxes1[:, 0][:, None]\n",
    "    y11 = boxes1[:, 1][:, None]\n",
    "    x12 = boxes1[:, 2][:, None]\n",
    "    y12 = boxes1[:, 3][:, None]\n",
    "\n",
    "    x21 = boxes2[:, 0][None, :]\n",
    "    y21 = boxes2[:, 1][None, :]\n",
    "    x22 = boxes2[:, 2][None, :]\n",
    "    y22 = boxes2[:, 3][None, :]\n",
    "\n",
    "    inter_w = np.maximum(0.0, np.minimum(x12, x22) - np.maximum(x11, x21))\n",
    "    inter_h = np.maximum(0.0, np.minimum(y12, y22) - np.maximum(y11, y21))\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area1 = np.maximum(0.0, boxes1[:, 2] - boxes1[:, 0]) * np.maximum(0.0, boxes1[:, 3] - boxes1[:, 1])\n",
    "    area2 = np.maximum(0.0, boxes2[:, 2] - boxes2[:, 0]) * np.maximum(0.0, boxes2[:, 3] - boxes2[:, 1])\n",
    "    union = area1[:, None] + area2[None, :] - inter\n",
    "\n",
    "    return np.where(union > 0.0, inter / union, 0.0)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    for imgs, targets in loader:\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if scaler:\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16 if device=='cuda' else torch.bfloat16):\n",
    "                loss_dict = model(imgs, targets)\n",
    "                losses = sum(loss_dict.values())\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss_dict = model(imgs, targets)\n",
    "            losses = sum(loss_dict.values())\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_sum += losses.item()\n",
    "    return loss_sum / max(1, len(loader))\n",
    "\n",
    "BLOCKED = {3, 8, 12, 24, 26}  \n",
    "CLASS_THR = { }\n",
    "def filter_predictions(preds, blocked=None, class_thresholds=None, default_thresh=0.30):\n",
    "    \"\"\"\n",
    "    preds: list of dicts from torchvision (boxes, labels, scores)\n",
    "    blocked: 需要完全屏蔽的类别\n",
    "    class_thresholds: 可选，dict{cls:thr} 每类不同分数阈值\n",
    "    \"\"\"\n",
    "    blocked = set(blocked or [])\n",
    "    out = []\n",
    "    for p in preds:\n",
    "        labels, scores = p[\"labels\"], p[\"scores\"]\n",
    "        labels_fg = labels - 1  # convert back to original IDs (0-based)\n",
    "        keep = (labels != 0) & (scores >= default_thresh)\n",
    "        if blocked:\n",
    "            for c in blocked:\n",
    "                keep &= (labels_fg != c)\n",
    "        if class_thresholds:\n",
    "            thr = torch.full_like(scores, default_thresh)\n",
    "            for c, t in class_thresholds.items():\n",
    "                thr = torch.where(labels_fg == c, torch.as_tensor(t, device=scores.device, dtype=scores.dtype), thr)\n",
    "            keep &= (scores >= thr)\n",
    "        filtered = {k: v[keep] for k, v in p.items() if k in (\"boxes\",\"labels\",\"scores\")}\n",
    "        out.append(filtered)\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_loss_and_pr(\n",
    "    model,\n",
    "    loader,\n",
    "    device,\n",
    "    num_classes: int,\n",
    "    iou_thresh: float = 0.5,\n",
    "    score_thresh: float = 0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    适用于 torchvision 检测模型（Faster R-CNN 等）\n",
    "    - 假设类别 id 为 0..num_classes-1（无“背景类”标签）\n",
    "    - 返回：{'loss', 'TP','FP','FN','precision','recall'}\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "\n",
    "    loss_sum = 0.0\n",
    "    n_loss_batches = 0\n",
    "    TP = np.zeros(num_classes, dtype=np.int64)\n",
    "    FP = np.zeros(num_classes, dtype=np.int64)\n",
    "    FN = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    for imgs, targets in loader:\n",
    "        imgs_dev = [im.to(device) for im in imgs]\n",
    "        targets_dev = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # ---- 1) 计算验证 loss（需 train() 才会返回 loss dict）----\n",
    "        model.train()\n",
    "        loss_dict = model(imgs_dev, targets_dev)\n",
    "        loss_val = sum(loss_dict.values()).item()\n",
    "        loss_sum += loss_val\n",
    "        n_loss_batches += 1\n",
    "\n",
    "        # ---- 2) 做预测并统计 per-class PR（需 eval()）----\n",
    "        model.eval()\n",
    "        raw_preds = model(imgs_dev)\n",
    "        preds = filter_predictions(raw_preds, blocked=BLOCKED, class_thresholds=CLASS_THR, default_thresh=0.30)\n",
    "        \n",
    "        for pred, tgt in zip(preds, targets_dev):\n",
    "            pb = pred[\"boxes\"].detach().cpu().numpy()\n",
    "            pl = pred[\"labels\"].detach().cpu().numpy()\n",
    "            ps = pred[\"scores\"].detach().cpu().numpy()\n",
    "\n",
    "            tb = tgt[\"boxes\"].detach().cpu().numpy()\n",
    "            tl = tgt[\"labels\"].detach().cpu().numpy()\n",
    "\n",
    "            # 回到原始 0-based 类别，背景仍保持在 0\n",
    "            keep_pred = pl > 0\n",
    "            pb = pb[keep_pred]\n",
    "            ps = ps[keep_pred]\n",
    "            pl = pl[keep_pred] - 1\n",
    "\n",
    "            tl = tl - 1\n",
    "\n",
    "            # 按类别逐一匹配\n",
    "            for c in range(num_classes):\n",
    "                pb_c = pb[pl == c]\n",
    "                ps_c = ps[pl == c]\n",
    "                tb_c = tb[tl == c]\n",
    "\n",
    "                if len(pb_c) == 0 and len(tb_c) == 0:\n",
    "                    continue\n",
    "                if len(tb_c) == 0:\n",
    "                    FP[c] += len(pb_c)\n",
    "                    continue\n",
    "                if len(pb_c) == 0:\n",
    "                    FN[c] += len(tb_c)\n",
    "                    continue\n",
    "\n",
    "                order = np.argsort(-ps_c)  # 先匹配高分框\n",
    "                pb_c = pb_c[order]\n",
    "                iou = box_iou_np(pb_c, tb_c)\n",
    "\n",
    "                matched = set()\n",
    "                for i in range(len(pb_c)):\n",
    "                    j = int(np.argmax(iou[i]))\n",
    "                    if iou[i, j] >= iou_thresh and j not in matched:\n",
    "                        TP[c] += 1\n",
    "                        matched.add(j)\n",
    "                    else:\n",
    "                        FP[c] += 1\n",
    "                FN[c] += (len(tb_c) - len(matched))\n",
    "\n",
    "    # 恢复原模式\n",
    "    model.train() if was_training else model.eval()\n",
    "\n",
    "    precision = TP / np.clip(TP + FP, 1, None)\n",
    "    recall    = TP / np.clip(TP + FN, 1, None)\n",
    "    mean_loss = loss_sum / max(1, n_loss_batches)\n",
    "\n",
    "    return {\n",
    "        \"loss\": mean_loss,\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:06:53.364619Z",
     "iopub.status.busy": "2025-10-12T11:06:53.363917Z",
     "iopub.status.idle": "2025-10-12T11:11:07.266894Z",
     "shell.execute_reply": "2025-10-12T11:11:07.265715Z",
     "shell.execute_reply.started": "2025-10-12T11:06:53.364595Z"
    }
   },
   "outputs": [],
   "source": [
    "# main function\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--base\", default=\"/kaggle/input/electrical-component/dataset/\", help=\"root directory\")\n",
    "    ap.add_argument(\"--bs\", type=int, default=2)\n",
    "    ap.add_argument(\"--epochs\", type=int, default=10)\n",
    "    ap.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    ap.add_argument(\"--small-object\", action=\"store_true\", help=\"smaller anchors\")\n",
    "    args = ap.parse_args([]) # Pass an empty list to avoid parsing notebook arguments\n",
    "\n",
    "    train_set = NpyDetDataset(args.base, split=\"train\")\n",
    "    test_set  = NpyDetDataset(args.base, split=\"test\")\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=args.bs, shuffle=True,\n",
    "                              num_workers=2, pin_memory=True, collate_fn=det_collate_fn)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=args.bs, shuffle=False,\n",
    "                              num_workers=2, pin_memory=True, collate_fn=det_collate_fn)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = build_model(32, small_object=args.small_object).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-3)\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device==\"cuda\"))\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr = train_one_epoch(model, train_loader, optimizer, device, scaler)\n",
    "        va = evaluate_loss_and_pr(model, test_loader, device, num_classes=32,      # 你的类别数\n",
    "        iou_thresh=0.5,      # PR 的 IoU 阈值\n",
    "        score_thresh=0.2     # 置信度过滤\n",
    ")\n",
    "        print(f\"Epoch {epoch:02d} | train loss {tr:.4f} | val loss {va['loss']:.4f}\")\n",
    "        for c in range(32):\n",
    "          print(f\"class {c:02d} | P={va['precision'][c]:.3f} \"\n",
    "          f\"R={va['recall'][c]:.3f}  TP={va['TP'][c]} FP={va['FP'][c]} FN={va['FN'][c]}\")\n",
    "        if va['loss'] < best_val:\n",
    "            best_val = va['loss']\n",
    "            torch.save(model.state_dict(), \"best_frcnn_resnet50fpn.pt\")\n",
    "            print(\"  (saved best)\")\n",
    "\n",
    "main() # Call the main function directly"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8456082,
     "sourceId": 13336152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
