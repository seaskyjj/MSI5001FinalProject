{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13336152,"sourceType":"datasetVersion","datasetId":8456082}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms.v2 as T\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torchvision.tv_tensors import Image as TVImage, BoundingBoxes as TVBoxes\nfrom PIL import Image as PILImage\nimport os\nimport matplotlib.pyplot as plt\n# This is for the progress bar.\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nimport argparse\n\n#torch.device('cuda')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwZKD59ATKdp","outputId":"843d7219-9a5f-4473-a57b-dd1668294dba","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T10:55:35.147575Z","iopub.execute_input":"2025-10-12T10:55:35.147810Z","iopub.status.idle":"2025-10-12T10:55:46.427990Z","shell.execute_reply.started":"2025-10-12T10:55:35.147788Z","shell.execute_reply":"2025-10-12T10:55:46.427216Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# faster RCNN resnet50\ndef _largest_ndarray(obj):\n    if isinstance(obj, dict):\n        for k in (\"image\",\"img\",\"array\",\"data\",\"X\",\"arr\"):\n            if k in obj and isinstance(obj[k], np.ndarray):\n                return obj[k]\n        cands = [v for v in obj.values() if isinstance(v, np.ndarray)]\n        return max(cands, key=lambda a: a.size)\n    if isinstance(obj, (list, tuple)):\n        cands = [v for v in obj if isinstance(v, np.ndarray)]\n        return max(cands, key=lambda a: a.size)\n    return obj\n\ndef load_image_hwc_uint8(npy_path: str) -> np.ndarray:\n    \"\"\"\n    假设 .npy 存的是 HWC, ndim=3。\n    - 若 dtype 非 uint8, 自动判断 0~1 / -1~1 并映射到 0~255\n    - 若为单通道或带 alpha, 自动处理到 3 通道 RGB\n    \"\"\"\n    a = np.load(npy_path, allow_pickle=False, mmap_mode=\"r\")  # <<< enable mmap，已知是 HWC, ndim=3\n\n    if a.dtype != np.uint8:\n        a = a.astype(np.float32, copy=False)\n        vmin, vmax = float(a.min()), float(a.max())\n        if 0.0 <= vmin and vmax <= 1.0:\n            a = (a * 255.0).round()\n        elif -1.0 <= vmin and vmax <= 1.0:\n            a = ((a + 1.0) * 0.5 * 255.0).round()\n        # 否则认为已经接近 0..255，不再缩放\n        a = np.clip(a, 0, 255).astype(np.uint8)\n\n    # 通道处理：1通道 -> 3通道；4通道 -> 丢 alpha\n    c = a.shape[2]\n    if c == 1:\n        a = np.repeat(a, 3, axis=2)\n    elif c == 4:\n        a = a[..., :3]\n    return a  # HWC uint8(3)\n\ndef sanitize_boxes_and_labels(boxes: torch.Tensor,\n                              labels: torch.Tensor,\n                              H: int, W: int,\n                              min_size: float = 1.0):\n    \"\"\"\n    boxes: Tensor [N,4] (xyxy, float32)\n    labels: Tensor [N]  (int64)\n    将 boxes 限制在 [0,W]x[0,H]，并过滤宽/高 <= min_size 的框。\n    返回过滤后的 (boxes, labels)；允许返回 N==0。\n    \"\"\"\n    if boxes.numel() == 0:\n        return boxes.reshape(0,4).float(), labels.reshape(0).long()\n\n    boxes = boxes.clone()\n    # clip 到图像内\n    boxes[:, 0::2] = boxes[:, 0::2].clamp(0, float(W))\n    boxes[:, 1::2] = boxes[:, 1::2].clamp(0, float(H))\n\n    # 计算宽高\n    ws = boxes[:, 2] - boxes[:, 0]\n    hs = boxes[:, 3] - boxes[:, 1]\n    keep = (ws > min_size) & (hs > min_size)\n\n    if keep.sum() == 0:\n        # 返回空目标，torchvision 支持空 GT\n        return boxes.new_zeros((0,4)), labels.new_zeros((0,), dtype=torch.long)\n\n    return boxes[keep].float(), labels[keep].long()\n\nclass NpyDetDataset(Dataset):\n    \"\"\"\n    返回：\n      image: FloatTensor [3,H,W] (0..1)\n      target: dict(boxes: [N,4] xyxy, labels: [N], image_id, size=[H,W])\n    \"\"\"\n    def __init__(self, base_dir, split=\"train\", transform=None):\n        base = Path(base_dir)\n        self.img_dir = base / split / \"images\"\n        self.lbl_dir = base / split / \"labels\"\n        self.stems = sorted([p.stem for p in self.lbl_dir.glob(\"*.csv\")])\n        self.transform = transform\n\n        # 一次性把所有 CSV 读到内存，避免训练期I/O瓶颈\n        self.ann = {s: pd.read_csv(self.lbl_dir / f\"{s}.csv\") for s in self.stems}\n\n    def __len__(self):\n        return len(self.stems)\n\n    def __getitem__(self, idx):\n        stem = self.stems[idx]\n        img_path = self.img_dir / f\"{stem}.npy\"\n        img = load_image_hwc_uint8(img_path)\n        h, w = img.shape[:2]\n\n        df = self.ann[stem].copy()\n        x_c = df[\"x_center\"].astype(\"float32\").to_numpy()\n        y_c = df[\"y_center\"].astype(\"float32\").to_numpy()\n        bw  = df[\"width\"].astype(\"float32\").to_numpy()\n        bh  = df[\"height\"].astype(\"float32\").to_numpy()\n\n        # 自动识别是否为归一化\n        if x_c.max() <= 1.0 and y_c.max() <= 1.0 and bw.max() <= 1.0 and bh.max() <= 1.0:\n            x_c *= w; y_c *= h; bw *= w; bh *= h\n\n        x1 = x_c - bw/2; y1 = y_c - bh/2\n        x2 = x_c + bw/2; y2 = y_c + bh/2\n        boxes = np.stack([x1,y1,x2,y2], axis=1)\n        boxes[:, [0,2]] = boxes[:, [0,2]].clip(0, w)\n        boxes[:, [1,3]] = boxes[:, [1,3]].clip(0, h)\n\n        labels = df[\"class\"].astype(\"int64\").to_numpy()\n\n        if not img.flags.writeable or not img.flags['C_CONTIGUOUS']:\n            img = np.ascontiguousarray(img)   # 或 img = img.copy()\n\n        img_t = torch.from_numpy(img).permute(2,0,1).to(torch.float32).div_(255.0)\n\n        \n        target = {\n            \"boxes\":  torch.from_numpy(boxes).float(),\n            \"labels\": torch.from_numpy(labels).long(),\n            \"image_id\": torch.tensor([idx]),\n            \"size\": torch.tensor([h,w])\n        }\n\n        if self.transform is not None:\n            # v2 需要 tv_tensors 包装，才能自动同步几何变换\n            img_tv    = TVImage(img_t)  # Tensor子类，保留元信息\n            bboxes_tv = TVBoxes(target[\"boxes\"], format=\"XYXY\", canvas_size=(h, w))\n            tv_target = {\"boxes\": bboxes_tv, \"labels\": target[\"labels\"]}\n    \n            img_tv, tv_target = self.transform(img_tv, tv_target)\n    \n            # 更新尺寸与目标\n            _, H2, W2 = img_tv.shape\n            boxes2  = tv_target[\"boxes\"]\n            if hasattr(boxes2, \"as_tensor\"):  # tv_tensors/datapoints\n                boxes2 = boxes2.as_tensor()\n            labels2 = tv_target[\"labels\"]\n            \n            # 再清洗一次（裁剪/缩放后可能产生 0 宽/高）\n            boxes2, labels2 = sanitize_boxes_and_labels(boxes2, labels2, H=H2, W=W2, min_size=1.0)\n            \n            img_t = img_tv\n            target = {\n                \"boxes\": boxes2,\n                \"labels\": tv_target[\"labels\"],\n                \"image_id\": torch.tensor([idx]),\n                \"size\": torch.tensor([img_t.shape[-2], img_t.shape[-1]]),\n            }\n\n        return img_t, target\n\ndef det_collate_fn(batch):\n    imgs, targets = list(zip(*batch))\n    return list(imgs), list(targets)\n\ndef build_model(\n    num_classes,\n    small_object=False,\n    # 推理后处理（eval 时生效）\n    score_thresh=0.30,     # 统一分类阈值（你也可以用外部 per-class 过滤替代），默认是很低的 0.05 左右\n    nms_thresh=0.4,       # NMS IoU 从 0.5 降到 0.45 或 0.4 试试\n    max_dets=100,          # 每图最多保留多少个检测 或 100, 视任务而定\n    # 训练采样/匹配（让负样本多一些，减少 FP）\n    roi_batch_size=1024,\n    roi_pos_fraction=0.10,\n    roi_fg_iou=0.60,\n    roi_bg_iou=0.40,\n    # RPN Top-N（可略优化 proposal 质量）\n    rpn_pre_topn_train=2000,\n    rpn_pre_topn_test=1000,\n    rpn_post_topn_train=1000,\n    rpn_post_topn_test=500,\n):\n    # 预训练 Faster R-CNN + ResNet50-FPN\n    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\", weights_backbone=\"DEFAULT\")\n\n    # 可选：更小的 anchors，利于小目标\n    if small_object:\n        # 对 FPN 的 5 个特征层分别设定 anchor 尺寸\n        anchor_sizes = ((16,), (32,), (64,), (128,), (256,))\n        aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n        model.rpn.anchor_generator = AnchorGenerator(sizes=anchor_sizes,\n                                                     aspect_ratios=aspect_ratios)\n\n    # 换分类头（num_classes 包含 background）\n\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # ===== 推理后处理（仅 eval 用到）=====\n    rh = model.roi_heads\n    # 不同版本可能叫 score_thresh 或 box_score_thresh；都设置以兼容\n    if hasattr(rh, \"score_thresh\"):       rh.score_thresh = score_thresh\n    if hasattr(rh, \"box_score_thresh\"):   rh.box_score_thresh = score_thresh\n    if hasattr(rh, \"nms_thresh\"):         rh.nms_thresh = nms_thresh\n    if hasattr(rh, \"box_nms_thresh\"):     rh.box_nms_thresh = nms_thresh\n    if hasattr(rh, \"detections_per_img\"): rh.detections_per_img = max_dets\n\n    # ===== 训练采样/匹配（影响 FP/学习难度）=====\n    if hasattr(rh, \"box_batch_size_per_image\"): rh.box_batch_size_per_image = roi_batch_size\n    if hasattr(rh, \"positive_fraction\"):        rh.positive_fraction        = roi_pos_fraction\n    if hasattr(rh, \"box_fg_iou_thresh\"):        rh.box_fg_iou_thresh        = roi_fg_iou\n    if hasattr(rh, \"box_bg_iou_thresh\"):        rh.box_bg_iou_thresh        = roi_bg_iou\n\n    # ===== RPN Top-N（略提高 proposal 质量/数量）=====\n    rpn = model.rpn\n    if hasattr(rpn, \"pre_nms_top_n\") and isinstance(rpn.pre_nms_top_n, dict):\n        rpn.pre_nms_top_n[\"training\"] = rpn_pre_topn_train\n        rpn.pre_nms_top_n[\"testing\"]  = rpn_pre_topn_test\n    if hasattr(rpn, \"post_nms_top_n\") and isinstance(rpn.post_nms_top_n, dict):\n        rpn.post_nms_top_n[\"training\"] = rpn_post_topn_train\n        rpn.post_nms_top_n[\"testing\"]  = rpn_post_topn_test\n        \n    return model\n\ndef box_iou_np(boxes1, boxes2):\n    \"\"\"boxes: [N,4] & [M,4] in xyxy -> IoU [N,M]\"\"\"\n    if len(boxes1)==0 or len(boxes2)==0:\n        return np.zeros((len(boxes1), len(boxes2)), dtype=np.float32)\n    x11,y11,x12,y12 = boxes1[:,0],boxes1[:,1],boxes1[:,2],boxes1[:,3]\n    x21,y21,x22,y22 = boxes2[:,0],boxes2[:,1],boxes2[:,2],boxes2[:,3]\n    inter_w = np.maximum(0, np.minimum(x12, x22) - np.maximum(x11, x21))\n    inter_h = np.maximum(0, np.minimum(y12, y22) - np.maximum(y11, y21))\n    inter = inter_w * inter_h\n    area1 = np.maximum(0, x12-x11) * np.maximum(0, y12-y11)\n    area2 = np.maximum(0, x22-x21) * np.maximum(0, y22-y21)\n    union = area1[:,None] + area2[None,:] - inter\n    return inter / np.clip(union, 1e-6, None)\n\ndef train_one_epoch(model, loader, optimizer, device, scaler=None):\n    model.train()\n    loss_sum = 0.0\n    for imgs, targets in loader:\n        imgs = [img.to(device) for img in imgs]\n        targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n\n        optimizer.zero_grad(set_to_none=True)\n        if scaler:\n            with torch.autocast(device_type=device, dtype=torch.float16 if device=='cuda' else torch.bfloat16):\n                loss_dict = model(imgs, targets)\n                losses = sum(loss_dict.values())\n            scaler.scale(losses).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss_dict = model(imgs, targets)\n            losses = sum(loss_dict.values())\n            losses.backward()\n            optimizer.step()\n\n        loss_sum += losses.item()\n    return loss_sum / max(1, len(loader))\n\nBLOCKED = {3, 8, 12, 24, 26}  \nCLASS_THR = { }\ndef filter_predictions(preds, blocked=None, class_thresholds=None, default_thresh=0.30):\n    \"\"\"\n    preds: list of dicts from torchvision (boxes, labels, scores)\n    blocked: 需要完全屏蔽的类别\n    class_thresholds: 可选，dict{cls:thr} 每类不同分数阈值\n    \"\"\"\n    blocked = set(blocked or [])\n    out = []\n    for p in preds:\n        labels, scores = p[\"labels\"], p[\"scores\"]\n        keep = scores >= default_thresh\n        if blocked:\n            for c in blocked: keep &= (labels != c)\n        if class_thresholds:\n            thr = torch.full_like(scores, default_thresh)\n            for c,t in class_thresholds.items():\n                thr = torch.where(labels==c, torch.as_tensor(t, device=scores.device, dtype=scores.dtype), thr)\n            keep &= (scores >= thr)\n        out.append({k: v[keep] for k,v in p.items() if k in (\"boxes\",\"labels\",\"scores\")})\n    return out\n\n@torch.no_grad()\ndef evaluate_loss_and_pr(\n    model,\n    loader,\n    device,\n    num_classes: int,\n    iou_thresh: float = 0.5,\n    score_thresh: float = 0.05,\n):\n    \"\"\"\n    适用于 torchvision 检测模型（Faster R-CNN 等）\n    - 假设类别 id 为 0..num_classes-1（无“背景类”标签）\n    - 返回：{'loss', 'TP','FP','FN','precision','recall'}\n    \"\"\"\n    was_training = model.training\n\n    loss_sum = 0.0\n    n_loss_batches = 0\n    TP = np.zeros(num_classes, dtype=np.int64)\n    FP = np.zeros(num_classes, dtype=np.int64)\n    FN = np.zeros(num_classes, dtype=np.int64)\n\n    for imgs, targets in loader:\n        imgs_dev = [im.to(device) for im in imgs]\n        targets_dev = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        # ---- 1) 计算验证 loss（需 train() 才会返回 loss dict）----\n        model.train()\n        loss_dict = model(imgs_dev, targets_dev)\n        loss_val = sum(loss_dict.values()).item()\n        loss_sum += loss_val\n        n_loss_batches += 1\n\n        # ---- 2) 做预测并统计 per-class PR（需 eval()）----\n        model.eval()\n        raw_preds = model(imgs_dev)\n        preds = filter_predictions(raw_preds, blocked=BLOCKED, class_thresholds=CLASS_THR, default_thresh=0.30)\n        \n        for pred, tgt in zip(preds, targets_dev):\n            pb = pred[\"boxes\"].detach().cpu().numpy()\n            pl = pred[\"labels\"].detach().cpu().numpy()\n            ps = pred[\"scores\"].detach().cpu().numpy()\n\n            tb = tgt[\"boxes\"].detach().cpu().numpy()\n            tl = tgt[\"labels\"].detach().cpu().numpy()\n\n            # 按类别逐一匹配\n            for c in range(num_classes):\n                pb_c = pb[pl == c]\n                ps_c = ps[pl == c]\n                tb_c = tb[tl == c]\n\n                if len(pb_c) == 0 and len(tb_c) == 0:\n                    continue\n                if len(tb_c) == 0:\n                    FP[c] += len(pb_c)\n                    continue\n                if len(pb_c) == 0:\n                    FN[c] += len(tb_c)\n                    continue\n\n                order = np.argsort(-ps_c)  # 先匹配高分框\n                pb_c = pb_c[order]\n                iou = box_iou_np(pb_c, tb_c)\n\n                matched = set()\n                for i in range(len(pb_c)):\n                    j = int(np.argmax(iou[i]))\n                    if iou[i, j] >= iou_thresh and j not in matched:\n                        TP[c] += 1\n                        matched.add(j)\n                    else:\n                        FP[c] += 1\n                FN[c] += (len(tb_c) - len(matched))\n\n    # 恢复原模式\n    model.train() if was_training else model.eval()\n\n    precision = TP / np.clip(TP + FP, 1, None)\n    recall    = TP / np.clip(TP + FN, 1, None)\n    mean_loss = loss_sum / max(1, n_loss_batches)\n\n    return {\n        \"loss\": mean_loss,\n        \"TP\": TP,\n        \"FP\": FP,\n        \"FN\": FN,\n        \"precision\": precision,\n        \"recall\": recall,\n    }\n","metadata":{"id":"nLVc6EuKv5PD","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T10:55:49.329544Z","iopub.execute_input":"2025-10-12T10:55:49.329898Z","iopub.status.idle":"2025-10-12T10:55:49.380415Z","shell.execute_reply.started":"2025-10-12T10:55:49.329872Z","shell.execute_reply":"2025-10-12T10:55:49.378536Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#main function\n\ndef main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--base\", default=\"/kaggle/input/electrical-component/dataset/\", help=\"root directory\")\n    ap.add_argument(\"--bs\", type=int, default=2)\n    ap.add_argument(\"--epochs\", type=int, default=10)\n    ap.add_argument(\"--lr\", type=float, default=1e-4)\n    ap.add_argument(\"--small-object\", action=\"store_true\", help=\"smaller anchors\")\n    args = ap.parse_args([]) # Pass an empty list to avoid parsing notebook arguments\n    num_cpus = os.cpu_count() or 2          # Kaggle 常见是 2\n    sizes = [640, 704, 768, 832, 896]\n    \n    train_tf = T.Compose([\n        T.RandomHorizontalFlip(0.5),\n        T.RandomVerticalFlip(0.2),\n        T.RandomIoUCrop(\n            min_scale=0.5, max_scale=1.0,  # 提高 min_scale 降低裁剪难度\n            sampler_options=[0.3, 0.7],    # 精简采样档位\n        ),\n        # T.RandomIoUCrop(min_scale=0.3, max_scale=1.0,\n        #                 min_aspect_ratio=0.75, max_aspect_ratio=1.33,\n        #                 sampler_options=[0.1, 0.3, 0.5, 0.7, 0.9]),\n        T.RandomChoice([T.Resize((s, s)) for s in sizes]),  # ← 多尺度随机\n        T.ColorJitter(0.2, 0.2, 0.2, 0.05),\n        # 如果你这里也报错说没有 SanitizeBoundingBoxes，就先删掉这一行或看方案 B 的 fallback\n        # T.SanitizeBoundingBoxes(min_size=2),\n    ])\n\n    test_tf = None  # 验证/测试通常不做随机增广（可以只做 Resize/Normalize 等）\n    \n    train_set = NpyDetDataset(args.base, split=\"train\", transform=train_tf)\n    test_set  = NpyDetDataset(args.base, split=\"test\",  transform=test_tf)\n\n    train_loader = DataLoader(train_set, batch_size=args.bs, shuffle=True,\n                              num_workers=2, pin_memory=True, pin_memory_device=\"cuda\",\n                                prefetch_factor=4,                  # 默认 2，适当加大\n                                persistent_workers=True,            # 复用 worker，跨 epoch 不重启\n                                collate_fn=det_collate_fn)\n    test_loader  = DataLoader(test_set,  batch_size=args.bs, shuffle=False,\n                              num_workers=1, pin_memory=True, pin_memory_device=\"cuda\",\n                                prefetch_factor=2,                  # 默认 2，适当加大\n                                persistent_workers=True,            # 复用 worker，跨 epoch 不重启\n                                collate_fn=det_collate_fn)\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = build_model(32, small_object=args.small_object).to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-3)\n    scaler = torch.amp.GradScaler('cuda', enabled=(device==\"cuda\"))\n\n    best_val = float(\"inf\")\n    for epoch in range(1, args.epochs + 1):\n        tr = train_one_epoch(model, train_loader, optimizer, device, scaler)\n        va = evaluate_loss_and_pr(model, test_loader, device, num_classes=32,      # 你的类别数\n        iou_thresh=0.5,      # PR 的 IoU 阈值\n        score_thresh=0.2     # 置信度过滤\n)\n        print(f\"Epoch {epoch:02d} | train loss {tr:.4f} | val loss {va['loss']:.4f}\")\n        for c in range(32):\n          print(f\"class {c:02d} | P={va['precision'][c]:.3f} \"\n          f\"R={va['recall'][c]:.3f}  TP={va['TP'][c]} FP={va['FP'][c]} FN={va['FN'][c]}\")\n        if va['loss'] < best_val:\n            best_val = va['loss']\n            torch.save(model.state_dict(), \"best_frcnn_resnet50fpn.pt\")\n            print(\"  (saved best)\")\n\nmain() # Call the main function directly","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llsH2GxZ6RZQ","outputId":"be1284fb-c74f-40d0-cd6a-129d9ae3ea3a","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:22.005447Z","iopub.execute_input":"2025-10-12T09:43:22.005736Z","iopub.status.idle":"2025-10-12T10:41:27.629900Z","shell.execute_reply.started":"2025-10-12T09:43:22.005716Z","shell.execute_reply":"2025-10-12T10:41:27.627816Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/162457324.py:115: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n  img_t = torch.from_numpy(img).permute(2,0,1).to(torch.float32).div_(255.0)\n/tmp/ipykernel_37/162457324.py:115: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n  img_t = torch.from_numpy(img).permute(2,0,1).to(torch.float32).div_(255.0)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1796583905.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  (saved best)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call the main function directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_37/1796583905.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mbest_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         va = evaluate_loss_and_pr(model, test_loader, device, num_classes=32,      # 你的类别数\n\u001b[1;32m     56\u001b[0m         \u001b[0miou_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# PR 的 IoU 阈值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/162457324.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, device, scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":23}]}