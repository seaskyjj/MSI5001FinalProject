{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254ff11c",
   "metadata": {
    "papermill": {
     "duration": 0.004731,
     "end_time": "2025-10-21T07:01:15.851900",
     "exception": false,
     "start_time": "2025-10-21T07:01:15.847169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Electrical Component Detection Pipeline\n",
    "\n",
    "This notebook consolidates the refactored Faster R-CNN training and inference workflow into a single place for convenient experimentation on Kaggle. It provides reusable configuration objects, dataset loaders with optional augmentation, detailed metric utilities (including per-class TP/FP/FN and mAP), and helpers for both training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ea6263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:15.860657Z",
     "iopub.status.busy": "2025-10-21T07:01:15.860399Z",
     "iopub.status.idle": "2025-10-21T07:01:27.269948Z",
     "shell.execute_reply": "2025-10-21T07:01:27.269289Z"
    },
    "papermill": {
     "duration": 11.415509,
     "end_time": "2025-10-21T07:01:27.271402",
     "exception": false,
     "start_time": "2025-10-21T07:01:15.855893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import contextlib\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Mapping, Optional, Sequence, Set, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image as PILImage, ImageDraw, ImageEnhance, ImageFont\n",
    "from torch import Tensor, nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import (\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.transforms import functional as TVF\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85042471",
   "metadata": {
    "papermill": {
     "duration": 0.003251,
     "end_time": "2025-10-21T07:01:27.278475",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.275224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e69414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.286115Z",
     "iopub.status.busy": "2025-10-21T07:01:27.285751Z",
     "iopub.status.idle": "2025-10-21T07:01:27.296393Z",
     "shell.execute_reply": "2025-10-21T07:01:27.295821Z"
    },
    "papermill": {
     "duration": 0.015709,
     "end_time": "2025-10-21T07:01:27.297445",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.281736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Configuration objects for the electrical component detection project.\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "DEFAULT_PRETRAINED_URL = (\n",
    "    \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\"\n",
    ")\n",
    "\n",
    "#0.999 menas class does not exist\n",
    "DEFAULT_CLASS_SCORE_THRESHOLDS = {\n",
    "    3: 0.999,  \n",
    "    6: 0.8,\n",
    "    7: 0.9,\n",
    "    8: 0.999,\n",
    "    12: 0.999,\n",
    "    16: 0.97,\n",
    "    17: 0.999,\n",
    "    20: 0.9,\n",
    "    21: 0.9,\n",
    "    24: 0.999,\n",
    "    25: 0.97,\n",
    "    26: 0.999,\n",
    "    30: 0.95,\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Configuration describing the dataset layout and metadata.\"\"\"\n",
    "\n",
    "    base_dir: Path = Path(\"data\")\n",
    "    train_split: str = \"train\"\n",
    "    valid_split: str = \"valid\"\n",
    "    test_split: str = \"test\"\n",
    "    image_folder: str = \"images\"\n",
    "    label_folder: str = \"labels\"\n",
    "    num_classes: int = 32\n",
    "    class_names: Tuple[str, ...] = ()\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if not self.class_names:\n",
    "            # Fallback names are useful for logging when a mapping file is not provided.\n",
    "            self.class_names = tuple(f\"class_{idx:02d}\" for idx in range(self.num_classes))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Hyper-parameters and runtime settings for model training.\"\"\"\n",
    "\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 5e-5\n",
    "    weight_decay: float = 5e-5\n",
    "    num_workers: int = 0\n",
    "    amp: bool = True\n",
    "    augmentation: bool = True\n",
    "    mosaic_prob: float = 0.6\n",
    "    mixup_prob: float = 0.6\n",
    "    mixup_alpha: float = 0.4\n",
    "    scale_jitter_min: float = 0.8\n",
    "    scale_jitter_max: float = 1.2\n",
    "    rotation_prob: float = 0.5\n",
    "    rotation_max_degrees: float = 30.0\n",
    "    affine_prob: float = 0.3\n",
    "    affine_translate: Tuple[float, float] = (0.1, 0.1)\n",
    "    affine_scale_range: Tuple[float, float] = (0.9, 1.1)\n",
    "    affine_shear: Tuple[float, float] = (5, 5)\n",
    "    small_object: bool = True\n",
    "    score_threshold: float = 0.6\n",
    "    iou_threshold: float = 0.5\n",
    "    eval_interval: int = 1\n",
    "    seed: int = 37\n",
    "    output_dir: Path = Path(\"outputs\")\n",
    "    checkpoint_path: Path = Path(\"outputs/best_model.pth\")\n",
    "    pretrained_weights_path: Path = Path(\"weights/fasterrcnn_resnet50_fpn_v2_coco.pth\")\n",
    "    pretrained_weights_url: str = DEFAULT_PRETRAINED_URL\n",
    "    log_every: int = 20\n",
    "    resume: bool = False\n",
    "    resume_path: Optional[Path] = None\n",
    "    last_checkpoint_path: Path = Path(\"outputs/last_checkpoint.pth\")\n",
    "    class_score_thresholds: Dict[int, float] = field(\n",
    "        default_factory=lambda: DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    )\n",
    "    exclude_samples: Tuple[str, ...] = tuple()\n",
    "    fp_visual_dir: Optional[Path] = Path(\"outputs/fp_images\")\n",
    "    fp_report_path: Optional[Path] = None\n",
    "    fp_list_path: Optional[Path] = None\n",
    "    fp_classes: Tuple[int, ...] = (16, 30)\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        \"\"\"Create output directories if they do not exist.\"\"\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.pretrained_weights_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.last_checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if self.fp_visual_dir:\n",
    "            self.fp_visual_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    \"\"\"Options for running model inference and visualisation.\"\"\"\n",
    "\n",
    "    score_threshold: float = 0.7\n",
    "    max_images: int = 200\n",
    "    output_dir: Path = Path(\"outputs/inference\")\n",
    "    draw_ground_truth: bool = True\n",
    "    class_colors: List[str] = field(default_factory=list)\n",
    "    class_score_thresholds: Dict[int, float] = field(\n",
    "        default_factory=lambda: DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    )\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b06fe",
   "metadata": {
    "papermill": {
     "duration": 0.002924,
     "end_time": "2025-10-21T07:01:27.303648",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.300724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset loading and augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9c00ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.310981Z",
     "iopub.status.busy": "2025-10-21T07:01:27.310767Z",
     "iopub.status.idle": "2025-10-21T07:01:27.338390Z",
     "shell.execute_reply": "2025-10-21T07:01:27.337847Z"
    },
    "papermill": {
     "duration": 0.032579,
     "end_time": "2025-10-21T07:01:27.339401",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.306822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Dataset and data loading utilities for electrical component detection.\"\"\"\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image as PILImage, ImageEnhance\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.transforms import functional as TVF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationParams:\n",
    "    \"\"\"Parameters controlling the dataset level image augmentations.\"\"\"\n",
    "\n",
    "    horizontal_flip_prob: float = 0.5\n",
    "    vertical_flip_prob: float = 0.2\n",
    "    brightness: float = 0.2\n",
    "    contrast: float = 0.2\n",
    "    saturation: float = 0.2\n",
    "    hue: float = 0.02\n",
    "    rotation_prob: float = 0.0\n",
    "    rotation_max_degrees: float = 0.0\n",
    "    affine_prob: float = 0.0\n",
    "    affine_translate: Tuple[float, float] = (0.0, 0.0)\n",
    "    affine_scale_range: Tuple[float, float] = (1.0, 1.0)\n",
    "    affine_shear: Tuple[float, float] = (0.0, 0.0)\n",
    "    mosaic_prob: float = 0.0\n",
    "    mixup_prob: float = 0.0\n",
    "    mixup_alpha: float = 0.4\n",
    "    scale_jitter_range: Tuple[float, float] = (1.0, 1.0)\n",
    "\n",
    "\n",
    "def load_image_hwc_uint8(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load an ``.npy`` image stored as HWC and return an ``uint8`` array.\"\"\"\n",
    "    image = np.load(path, allow_pickle=False, mmap_mode=\"r\")\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.float32, copy=False)\n",
    "        vmin, vmax = float(image.min()), float(image.max())\n",
    "        if 0.0 <= vmin and vmax <= 1.0:\n",
    "            image = (image * 255.0).round()\n",
    "        elif -1.0 <= vmin and vmax <= 1.0:\n",
    "            image = ((image + 1.0) * 0.5 * 255.0).round()\n",
    "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    channels = image.shape[2]\n",
    "    if channels == 1:\n",
    "        image = np.repeat(image, 3, axis=2)\n",
    "    elif channels == 4:\n",
    "        image = image[..., :3]\n",
    "    if not image.flags.writeable or not image.flags.c_contiguous:\n",
    "        image = np.array(image, copy=True)\n",
    "    return image\n",
    "\n",
    "\n",
    "class ElectricalComponentsDataset(Dataset):\n",
    "    \"\"\"Dataset of electrical component detections stored as ``.npy`` images and CSV labels.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Path,\n",
    "        split: str,\n",
    "        class_names: Iterable[str],\n",
    "        transform: Optional[AugmentationParams] = None,\n",
    "        use_augmentation: bool = False,\n",
    "        exclude_stems: Optional[Iterable[str]] = None,\n",
    "    ) -> None:\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.class_names = list(class_names)\n",
    "        self.transform_params = transform or AugmentationParams()\n",
    "        self.use_augmentation = use_augmentation\n",
    "\n",
    "        self.image_dir = self.root / split / \"images\"\n",
    "        self.label_dir = self.root / split / \"labels\"\n",
    "\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing image directory: {self.image_dir}\")\n",
    "        if not self.label_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing label directory: {self.label_dir}\")\n",
    "\n",
    "        self.image_stems = sorted(p.stem for p in self.label_dir.glob(\"*.csv\"))\n",
    "        if not self.image_stems:\n",
    "            raise RuntimeError(f\"No label files found in {self.label_dir}\")\n",
    "\n",
    "        exclude_set: Set[str] = set()\n",
    "        if exclude_stems:\n",
    "            exclude_set = {Path(stem).stem for stem in exclude_stems}\n",
    "            if exclude_set:\n",
    "                before = len(self.image_stems)\n",
    "                self.image_stems = [stem for stem in self.image_stems if stem not in exclude_set]\n",
    "                removed = before - len(self.image_stems)\n",
    "                if removed:\n",
    "                    LOGGER.info(\n",
    "                        \"Split %s: excluded %d samples based on provided stem filter.\",\n",
    "                        self.split,\n",
    "                        removed,\n",
    "                    )\n",
    "\n",
    "        self.excluded_stems = sorted(exclude_set)\n",
    "\n",
    "        # Pre-load all annotations to reduce I/O during training.\n",
    "        self.annotations: Dict[str, pd.DataFrame] = {\n",
    "            stem: pd.read_csv(self.label_dir / f\"{stem}.csv\") for stem in self.image_stems\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_stems)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        stem = self.image_stems[index]\n",
    "        image, boxes, labels = self._load_raw_sample(stem)\n",
    "\n",
    "        if self.use_augmentation:\n",
    "            image, boxes, labels = self._apply_composite_augmentations(stem, image, boxes, labels)\n",
    "            image, boxes = self._apply_augmentations(image, boxes)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        boxes_tensor = torch.from_numpy(boxes).float() if boxes.size else torch.zeros((0, 4), dtype=torch.float32)\n",
    "        labels_tensor = (\n",
    "            torch.from_numpy(labels).long() if labels.size else torch.zeros((0,), dtype=torch.long)\n",
    "        )\n",
    "\n",
    "        boxes_tensor, labels_tensor = sanitize_boxes_and_labels(\n",
    "            boxes_tensor, labels_tensor, height, width\n",
    "        )\n",
    "\n",
    "        target: Dict[str, torch.Tensor] = {\n",
    "            \"boxes\": boxes_tensor,\n",
    "            \"labels\": labels_tensor,\n",
    "            \"image_id\": torch.tensor(index, dtype=torch.int64),\n",
    "            \"area\": (boxes_tensor[:, 2] - boxes_tensor[:, 0])\n",
    "            * (boxes_tensor[:, 3] - boxes_tensor[:, 1])\n",
    "            if boxes_tensor.numel()\n",
    "            else torch.tensor([], dtype=torch.float32),\n",
    "            \"iscrowd\": torch.zeros((boxes_tensor.shape[0],), dtype=torch.int64),\n",
    "            \"orig_size\": torch.tensor([height, width], dtype=torch.int64),\n",
    "        }\n",
    "\n",
    "        return image_tensor, target\n",
    "\n",
    "    def _load_raw_sample(self, stem: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        image_path = self.image_dir / f\"{stem}.npy\"\n",
    "        image = load_image_hwc_uint8(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        ann = self.annotations[stem]\n",
    "        boxes, labels = self._annotation_to_boxes(ann, width, height)\n",
    "        return image, boxes, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def _annotation_to_boxes(\n",
    "        ann: pd.DataFrame, width: int, height: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if ann.empty:\n",
    "            return np.zeros((0, 4), dtype=np.float32), np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "        x_center = ann[\"x_center\"].to_numpy(dtype=np.float32)\n",
    "        y_center = ann[\"y_center\"].to_numpy(dtype=np.float32)\n",
    "        box_width = ann[\"width\"].to_numpy(dtype=np.float32)\n",
    "        box_height = ann[\"height\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # Auto-detect normalised coordinates and scale back to pixel space.\n",
    "        if (\n",
    "            (x_center.size == 0 or float(x_center.max()) <= 1.0)\n",
    "            and (y_center.size == 0 or float(y_center.max()) <= 1.0)\n",
    "            and (box_width.size == 0 or float(box_width.max()) <= 1.0)\n",
    "            and (box_height.size == 0 or float(box_height.max()) <= 1.0)\n",
    "        ):\n",
    "            x_center = x_center * width\n",
    "            y_center = y_center * height\n",
    "            box_width = box_width * width\n",
    "            box_height = box_height * height\n",
    "\n",
    "        x1 = x_center - box_width / 2.0\n",
    "        y1 = y_center - box_height / 2.0\n",
    "        x2 = x_center + box_width / 2.0\n",
    "        y2 = y_center + box_height / 2.0\n",
    "\n",
    "        boxes = np.stack([x1, y1, x2, y2], axis=1).astype(np.float32)\n",
    "        labels = ann[\"class\"].to_numpy(dtype=np.int64) + 1  # shift to 1..K so 0 remains reserved for background\n",
    "        return boxes, labels\n",
    "\n",
    "    def _apply_composite_augmentations(\n",
    "        self,\n",
    "        stem: str,\n",
    "        image: np.ndarray,\n",
    "        boxes: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        params = self.transform_params\n",
    "\n",
    "        if (\n",
    "            params.mosaic_prob > 0.0\n",
    "            and random.random() < params.mosaic_prob\n",
    "            and len(self.image_stems) >= 4\n",
    "        ):\n",
    "            image, boxes, labels = self._apply_mosaic(stem, image, boxes, labels)\n",
    "\n",
    "        if (\n",
    "            params.mixup_prob > 0.0\n",
    "            and params.mixup_alpha > 0.0\n",
    "            and random.random() < params.mixup_prob\n",
    "        ):\n",
    "            image, boxes, labels = self._apply_mixup(stem, image, boxes, labels)\n",
    "\n",
    "        if params.scale_jitter_range != (1.0, 1.0):\n",
    "            image, boxes = self._apply_scale_jitter(image, boxes, params.scale_jitter_range)\n",
    "\n",
    "        return image, boxes, labels\n",
    "\n",
    "    def _apply_augmentations(\n",
    "        self, image: np.ndarray, boxes: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        params = self.transform_params\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        if (\n",
    "            params.rotation_prob > 0.0\n",
    "            and params.rotation_max_degrees > 0.0\n",
    "            and random.random() < params.rotation_prob\n",
    "        ):\n",
    "            angle = random.uniform(-params.rotation_max_degrees, params.rotation_max_degrees)\n",
    "            image, boxes = self._apply_affine_transform(\n",
    "                image,\n",
    "                boxes,\n",
    "                angle=angle,\n",
    "                translate=(0.0, 0.0),\n",
    "                scale=1.0,\n",
    "                shear=(0.0, 0.0),\n",
    "            )\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "        if params.affine_prob > 0.0 and random.random() < params.affine_prob:\n",
    "            max_tx = abs(params.affine_translate[0]) * width\n",
    "            max_ty = abs(params.affine_translate[1]) * height\n",
    "            translate = (\n",
    "                random.uniform(-max_tx, max_tx),\n",
    "                random.uniform(-max_ty, max_ty),\n",
    "            )\n",
    "\n",
    "            scale_min, scale_max = params.affine_scale_range\n",
    "            if scale_min > scale_max:\n",
    "                scale_min, scale_max = scale_max, scale_min\n",
    "            scale_min = max(scale_min, 0.0)\n",
    "            scale_max = max(scale_max, 0.0)\n",
    "            scale = 1.0\n",
    "            if scale_max > 0.0:\n",
    "                if math.isclose(scale_min, scale_max):\n",
    "                    scale = max(scale_min, 1e-3)\n",
    "                else:\n",
    "                    scale = max(random.uniform(scale_min, scale_max), 1e-3)\n",
    "\n",
    "            shear_x = params.affine_shear[0]\n",
    "            shear_y = params.affine_shear[1]\n",
    "            shear = (\n",
    "                random.uniform(-abs(shear_x), abs(shear_x)),\n",
    "                random.uniform(-abs(shear_y), abs(shear_y)),\n",
    "            )\n",
    "\n",
    "            image, boxes = self._apply_affine_transform(\n",
    "                image,\n",
    "                boxes,\n",
    "                angle=0.0,\n",
    "                translate=translate,\n",
    "                scale=scale,\n",
    "                shear=shear,\n",
    "            )\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "        if boxes.size and random.random() < params.horizontal_flip_prob:\n",
    "            image = np.ascontiguousarray(image[:, ::-1, :])\n",
    "            x1 = width - boxes[:, 2]\n",
    "            x2 = width - boxes[:, 0]\n",
    "            boxes[:, 0], boxes[:, 2] = x1, x2\n",
    "\n",
    "        if boxes.size and random.random() < params.vertical_flip_prob:\n",
    "            image = np.ascontiguousarray(image[::-1, :, :])\n",
    "            y1 = height - boxes[:, 3]\n",
    "            y2 = height - boxes[:, 1]\n",
    "            boxes[:, 1], boxes[:, 3] = y1, y2\n",
    "\n",
    "        if params.brightness or params.contrast or params.saturation or params.hue:\n",
    "            pil = PILImage.fromarray(image)\n",
    "            if params.brightness:\n",
    "                enhancer = ImageEnhance.Brightness(pil)\n",
    "                factor = 1.0 + random.uniform(-params.brightness, params.brightness)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.contrast:\n",
    "                enhancer = ImageEnhance.Contrast(pil)\n",
    "                factor = 1.0 + random.uniform(-params.contrast, params.contrast)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.saturation:\n",
    "                enhancer = ImageEnhance.Color(pil)\n",
    "                factor = 1.0 + random.uniform(-params.saturation, params.saturation)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.hue:\n",
    "                hsv_image = pil.convert(\"HSV\")\n",
    "                h_channel, s_channel, v_channel = hsv_image.split()\n",
    "                delta = int(params.hue * 255.0 * random.choice([-1, 1]))\n",
    "                h_channel = h_channel.point(lambda h: (h + delta) % 255)\n",
    "                hsv_image = PILImage.merge(\"HSV\", (h_channel, s_channel, v_channel))\n",
    "                pil = hsv_image.convert(\"RGB\")\n",
    "            image = np.array(pil)\n",
    "\n",
    "        if boxes.size:\n",
    "            boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, width)\n",
    "            boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, height)\n",
    "        return image, boxes\n",
    "\n",
    "    def _apply_scale_jitter(\n",
    "        self, image: np.ndarray, boxes: np.ndarray, scale_range: Tuple[float, float]\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        min_scale, max_scale = scale_range\n",
    "        if max_scale <= 0 or min_scale <= 0:\n",
    "            return image, boxes\n",
    "\n",
    "        factor = random.uniform(min_scale, max_scale)\n",
    "        if np.isclose(factor, 1.0):\n",
    "            return image, boxes\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        new_height = max(1, int(round(height * factor)))\n",
    "        new_width = max(1, int(round(width * factor)))\n",
    "\n",
    "        pil = PILImage.fromarray(image)\n",
    "        resized = pil.resize((new_width, new_height), resample=PILImage.BILINEAR)\n",
    "        image = np.array(resized)\n",
    "\n",
    "        if boxes.size:\n",
    "            boxes = boxes.copy()\n",
    "            boxes[:, [0, 2]] *= float(new_width) / float(width)\n",
    "            boxes[:, [1, 3]] *= float(new_height) / float(height)\n",
    "        return image, boxes\n",
    "\n",
    "    def _apply_affine_transform(\n",
    "        self,\n",
    "        image: np.ndarray,\n",
    "        boxes: np.ndarray,\n",
    "        *,\n",
    "        angle: float,\n",
    "        translate: Tuple[float, float],\n",
    "        scale: float,\n",
    "        shear: Tuple[float, float],\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if not np.isfinite(scale) or scale <= 0.0:\n",
    "            scale = 1.0\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        pil = PILImage.fromarray(image)\n",
    "        translate_int = (\n",
    "            int(round(float(translate[0]))),\n",
    "            int(round(float(translate[1]))),\n",
    "        )\n",
    "        transformed = TVF.affine(\n",
    "            pil,\n",
    "            angle=float(angle),\n",
    "            translate=translate_int,\n",
    "            scale=float(max(scale, 1e-3)),\n",
    "            shear=(float(shear[0]), float(shear[1])),\n",
    "            interpolation=InterpolationMode.BILINEAR,\n",
    "            fill=0,\n",
    "        )\n",
    "        image_out = np.array(transformed)\n",
    "        out_height, out_width = image_out.shape[:2]\n",
    "\n",
    "        if not boxes.size:\n",
    "            return image_out, boxes.astype(np.float32, copy=False)\n",
    "\n",
    "        matrix = _compute_affine_forward_matrix(\n",
    "            center=(width * 0.5, height * 0.5),\n",
    "            angle=float(angle),\n",
    "            translate=(float(translate_int[0]), float(translate_int[1])),\n",
    "            scale=float(max(scale, 1e-3)),\n",
    "            shear=(float(shear[0]), float(shear[1])),\n",
    "        )\n",
    "\n",
    "        corners = _boxes_to_corners(boxes)\n",
    "        ones = np.ones((corners.shape[0], 1), dtype=np.float32)\n",
    "        coords = np.concatenate([corners, ones], axis=1)\n",
    "        full_matrix = np.vstack([matrix, [0.0, 0.0, 1.0]])\n",
    "        transformed_coords = coords @ full_matrix.T\n",
    "        transformed_corners = transformed_coords[:, :2].reshape(-1, 4, 2)\n",
    "        min_xy = transformed_corners.min(axis=1)\n",
    "        max_xy = transformed_corners.max(axis=1)\n",
    "\n",
    "        boxes_out = np.concatenate([min_xy, max_xy], axis=1)\n",
    "        boxes_out[:, [0, 2]] = boxes_out[:, [0, 2]].clip(0, out_width)\n",
    "        boxes_out[:, [1, 3]] = boxes_out[:, [1, 3]].clip(0, out_height)\n",
    "        return image_out, boxes_out.astype(np.float32, copy=False)\n",
    "\n",
    "    def _apply_mosaic(\n",
    "        self,\n",
    "        stem: str,\n",
    "        image: np.ndarray,\n",
    "        boxes: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        height, width = image.shape[:2]\n",
    "        candidate_stems = [s for s in self.image_stems if s != stem]\n",
    "        if len(candidate_stems) < 3:\n",
    "            return image, boxes, labels\n",
    "\n",
    "        selected = random.sample(candidate_stems, 3)\n",
    "\n",
    "        images: List[np.ndarray] = [image]\n",
    "        boxes_list: List[np.ndarray] = [boxes]\n",
    "        labels_list: List[np.ndarray] = [labels]\n",
    "\n",
    "        for other_stem in selected:\n",
    "            other_img, other_boxes, other_labels = self._load_raw_sample(other_stem)\n",
    "            other_img, other_boxes = self._resize_like(other_img, other_boxes, width, height)\n",
    "            images.append(other_img)\n",
    "            boxes_list.append(other_boxes)\n",
    "            labels_list.append(other_labels)\n",
    "\n",
    "        canvas = np.zeros((height * 2, width * 2, 3), dtype=np.uint8)\n",
    "        offsets = [(0, 0), (0, width), (height, 0), (height, width)]\n",
    "        combined_boxes: List[np.ndarray] = []\n",
    "        combined_labels: List[np.ndarray] = []\n",
    "\n",
    "        for img, bxs, lbls, (y_off, x_off) in zip(images, boxes_list, labels_list, offsets):\n",
    "            canvas[y_off : y_off + height, x_off : x_off + width] = img\n",
    "            if bxs.size:\n",
    "                shifted = bxs.copy()\n",
    "                shifted[:, [0, 2]] += x_off\n",
    "                shifted[:, [1, 3]] += y_off\n",
    "                combined_boxes.append(shifted)\n",
    "                combined_labels.append(lbls)\n",
    "\n",
    "        if combined_boxes:\n",
    "            boxes = np.concatenate(combined_boxes, axis=0)\n",
    "            labels = np.concatenate(combined_labels, axis=0)\n",
    "        else:\n",
    "            boxes = np.zeros((0, 4), dtype=np.float32)\n",
    "            labels = np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "        crop_x = random.randint(0, width)\n",
    "        crop_y = random.randint(0, height)\n",
    "        canvas = canvas[crop_y : crop_y + height, crop_x : crop_x + width]\n",
    "\n",
    "        if boxes.size:\n",
    "            boxes = boxes.copy()\n",
    "            boxes[:, [0, 2]] -= crop_x\n",
    "            boxes[:, [1, 3]] -= crop_y\n",
    "\n",
    "            keep = (\n",
    "                (boxes[:, 2] > 0)\n",
    "                & (boxes[:, 3] > 0)\n",
    "                & (boxes[:, 0] < width)\n",
    "                & (boxes[:, 1] < height)\n",
    "            )\n",
    "            boxes = boxes[keep]\n",
    "            labels = labels[keep]\n",
    "            boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, width)\n",
    "            boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, height)\n",
    "\n",
    "        return canvas, boxes, labels\n",
    "\n",
    "    def _apply_mixup(\n",
    "        self,\n",
    "        stem: str,\n",
    "        image: np.ndarray,\n",
    "        boxes: np.ndarray,\n",
    "        labels: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        other_stem = self._sample_alternative_stem(stem)\n",
    "        if other_stem is None:\n",
    "            return image, boxes, labels\n",
    "\n",
    "        other_img, other_boxes, other_labels = self._load_raw_sample(other_stem)\n",
    "        height, width = image.shape[:2]\n",
    "        other_img, other_boxes = self._resize_like(other_img, other_boxes, width, height)\n",
    "\n",
    "        alpha = max(self.transform_params.mixup_alpha, 1e-3)\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam = float(np.clip(lam, 0.3, 0.7))\n",
    "\n",
    "        mixed = (\n",
    "            image.astype(np.float32) * lam + other_img.astype(np.float32) * (1.0 - lam)\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "        if boxes.size and other_boxes.size:\n",
    "            boxes = np.concatenate([boxes, other_boxes], axis=0)\n",
    "            labels = np.concatenate([labels, other_labels], axis=0)\n",
    "        elif other_boxes.size:\n",
    "            boxes = other_boxes.copy()\n",
    "            labels = other_labels.copy()\n",
    "\n",
    "        return mixed, boxes, labels\n",
    "\n",
    "    def _sample_alternative_stem(self, current: str) -> Optional[str]:\n",
    "        if len(self.image_stems) <= 1:\n",
    "            return None\n",
    "        candidates = [stem for stem in self.image_stems if stem != current]\n",
    "        if not candidates:\n",
    "            return None\n",
    "        return random.choice(candidates)\n",
    "\n",
    "    @staticmethod\n",
    "    def _resize_like(\n",
    "        image: np.ndarray, boxes: np.ndarray, target_width: int, target_height: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        height, width = image.shape[:2]\n",
    "        if height == target_height and width == target_width:\n",
    "            return image, boxes\n",
    "\n",
    "        pil = PILImage.fromarray(image)\n",
    "        resized = pil.resize((target_width, target_height), resample=PILImage.BILINEAR)\n",
    "        image = np.array(resized)\n",
    "\n",
    "        if boxes.size:\n",
    "            boxes = boxes.copy()\n",
    "            boxes[:, [0, 2]] *= float(target_width) / float(width)\n",
    "            boxes[:, [1, 3]] *= float(target_height) / float(height)\n",
    "        return image, boxes\n",
    "\n",
    "\n",
    "def _boxes_to_corners(boxes: np.ndarray) -> np.ndarray:\n",
    "    corners = np.stack(\n",
    "        [\n",
    "            boxes[:, [0, 1]],\n",
    "            boxes[:, [2, 1]],\n",
    "            boxes[:, [2, 3]],\n",
    "            boxes[:, [0, 3]],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    return corners.reshape(-1, 2).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def _compute_affine_forward_matrix(\n",
    "    *,\n",
    "    center: Tuple[float, float],\n",
    "    angle: float,\n",
    "    translate: Tuple[float, float],\n",
    "    scale: float,\n",
    "    shear: Tuple[float, float],\n",
    ") -> np.ndarray:\n",
    "    rot = math.radians(angle)\n",
    "    shear_x = math.radians(shear[0])\n",
    "    shear_y = math.radians(shear[1])\n",
    "\n",
    "    cx, cy = center\n",
    "    tx, ty = translate\n",
    "\n",
    "    cos_sy = math.cos(shear_y)\n",
    "    if abs(cos_sy) < 1e-6:\n",
    "        cos_sy = 1e-6 if cos_sy >= 0 else -1e-6\n",
    "\n",
    "    a = math.cos(rot - shear_y) / cos_sy\n",
    "    b = -math.cos(rot - shear_y) * math.tan(shear_x) / cos_sy - math.sin(rot)\n",
    "    c = math.sin(rot - shear_y) / cos_sy\n",
    "    d = -math.sin(rot - shear_y) * math.tan(shear_x) / cos_sy + math.cos(rot)\n",
    "\n",
    "    matrix = [a, b, 0.0, c, d, 0.0]\n",
    "    matrix = [x * scale for x in matrix]\n",
    "\n",
    "    matrix[2] += matrix[0] * (-cx) + matrix[1] * (-cy)\n",
    "    matrix[5] += matrix[3] * (-cx) + matrix[4] * (-cy)\n",
    "    matrix[2] += cx + tx\n",
    "    matrix[5] += cy + ty\n",
    "\n",
    "    return np.array(matrix, dtype=np.float32).reshape(2, 3)\n",
    "\n",
    "\n",
    "def detection_collate(batch: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]):\n",
    "    \"\"\"Collate function for detection datasets returning lists of tensors.\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "\n",
    "def _safe_worker_count(requested: int) -> int:\n",
    "    cpu_count = os.cpu_count() or 1\n",
    "    if requested <= 0:\n",
    "        return 0\n",
    "    # Leave one core free so that the main process remains responsive on small machines.\n",
    "    max_workers = max(1, cpu_count - 1)\n",
    "    return min(requested, max_workers)\n",
    "\n",
    "\n",
    "def _should_force_single_worker(dataset: Dataset) -> bool:\n",
    "    \"\"\"Determine whether multiprocessing workers should be disabled.\"\"\"\n",
    "\n",
    "    module_name = getattr(dataset.__class__, \"__module__\", \"\")\n",
    "    if module_name in {\"__main__\", \"__mp_main__\", \"builtins\"}:\n",
    "        return True\n",
    "\n",
    "    if module_name.startswith(\"ipykernel\"):  # pragma: no cover - notebook specific\n",
    "        return True\n",
    "\n",
    "    return running_in_ipython_kernel()\n",
    "\n",
    "\n",
    "def create_data_loaders(\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    num_workers: int,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Create a :class:`~torch.utils.data.DataLoader` for the detection dataset.\n",
    "\n",
    "    Kaggle notebooks occasionally run in restricted multiprocessing environments where\n",
    "    ``fork`` based workers cannot be reaped cleanly.  We therefore favour a conservative\n",
    "    default (``num_workers=0``), detect in-notebook dataset definitions that cannot be\n",
    "    spawned safely, and fall back to single-process loading automatically when worker\n",
    "    start-up fails.\n",
    "    \"\"\"\n",
    "\n",
    "    worker_count = _safe_worker_count(num_workers)\n",
    "    if worker_count > 0 and _should_force_single_worker(dataset):\n",
    "        LOGGER.info(\n",
    "            \"Detected interactive environment or in-notebook dataset definition; forcing num_workers=0.\"\n",
    "        )\n",
    "        worker_count = 0\n",
    "\n",
    "    loader_kwargs = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=detection_collate,\n",
    "    )\n",
    "\n",
    "    if worker_count > 0:\n",
    "        loader_kwargs[\"num_workers\"] = worker_count\n",
    "        loader_kwargs[\"persistent_workers\"] = True\n",
    "        # ``spawn`` avoids PID mismatches that surface as ``AssertionError: can only\n",
    "        # test a child process`` when the notebook kernel re-uses processes.\n",
    "        loader_kwargs[\"multiprocessing_context\"] = mp.get_context(\"spawn\")\n",
    "    else:\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "\n",
    "    try:\n",
    "        return DataLoader(**loader_kwargs)\n",
    "    except (RuntimeError, OSError, AssertionError) as exc:\n",
    "        if worker_count == 0:\n",
    "            raise\n",
    "        warnings.warn(\n",
    "            \"Falling back to num_workers=0 because DataLoader worker initialisation \"\n",
    "            f\"failed with: {exc}\",\n",
    "            RuntimeWarning,\n",
    "        )\n",
    "        LOGGER.warning(\"DataLoader workers failed to start (%s). Using num_workers=0 instead.\", exc)\n",
    "        loader_kwargs.pop(\"persistent_workers\", None)\n",
    "        loader_kwargs.pop(\"multiprocessing_context\", None)\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "        return DataLoader(**loader_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e689c",
   "metadata": {
    "papermill": {
     "duration": 0.002974,
     "end_time": "2025-10-21T07:01:27.345614",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.342640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility helpers and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3637ad51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.353389Z",
     "iopub.status.busy": "2025-10-21T07:01:27.353214Z",
     "iopub.status.idle": "2025-10-21T07:01:27.378943Z",
     "shell.execute_reply": "2025-10-21T07:01:27.378326Z"
    },
    "papermill": {
     "duration": 0.030954,
     "end_time": "2025-10-21T07:01:27.379919",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.348965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Utility helpers for training and evaluating the detection model.\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ``DEFAULT_COLORS`` previously lived in the Kaggle notebook version of the\n",
    "# project.  The constant was referenced when rendering detections but never\n",
    "# actually defined in the standalone module, which caused a ``NameError`` when\n",
    "# the training script attempted to export visualisations.  Keeping the palette\n",
    "# here restores the expected behaviour while remaining independent from the\n",
    "# notebook.\n",
    "DEFAULT_COLORS: Tuple[str, ...] = (\n",
    "    \"#FF6B6B\",\n",
    "    \"#4ECDC4\",\n",
    "    \"#FFD93D\",\n",
    "    \"#1A535C\",\n",
    "    \"#FF9F1C\",\n",
    "    \"#2EC4B6\",\n",
    "    \"#E71D36\",\n",
    "    \"#9B5DE5\",\n",
    "    \"#F15BB5\",\n",
    "    \"#00BBF9\",\n",
    "    \"#00F5D4\",\n",
    "    \"#6C5CE7\",\n",
    "    \"#45B7D1\",\n",
    "    \"#F9C80E\",\n",
    "    \"#F86624\",\n",
    "    \"#EA3546\",\n",
    "    \"#662E9B\",\n",
    "    \"#43BCCD\",\n",
    "    \"#A1C181\",\n",
    "    \"#BB9F06\",\n",
    ")\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set seeds for the Python, NumPy and PyTorch RNGs.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def sanitize_boxes_and_labels(\n",
    "    boxes: Tensor, labels: Tensor, height: int, width: int, min_size: float = 1.0\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Clamp bounding boxes to the image size and drop invalid boxes.\"\"\"\n",
    "    if boxes.numel() == 0:\n",
    "        return boxes.reshape(0, 4).float(), labels.reshape(0).long()\n",
    "\n",
    "    boxes = boxes.clone()\n",
    "    boxes[:, 0::2] = boxes[:, 0::2].clamp(0, float(width))\n",
    "    boxes[:, 1::2] = boxes[:, 1::2].clamp(0, float(height))\n",
    "\n",
    "    widths = boxes[:, 2] - boxes[:, 0]\n",
    "    heights = boxes[:, 3] - boxes[:, 1]\n",
    "    keep = (widths > min_size) & (heights > min_size)\n",
    "\n",
    "    if keep.sum() == 0:\n",
    "        return boxes.new_zeros((0, 4)), labels.new_zeros((0,), dtype=torch.long)\n",
    "    return boxes[keep].float(), labels[keep].long()\n",
    "\n",
    "\n",
    "def compute_iou_matrix(boxes1: np.ndarray, boxes2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the IoU matrix between two sets of boxes in ``xyxy`` format.\"\"\"\n",
    "    if boxes1.size == 0 or boxes2.size == 0:\n",
    "        return np.zeros((boxes1.shape[0], boxes2.shape[0]), dtype=np.float32)\n",
    "\n",
    "    x11, y11, x12, y12 = np.split(boxes1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(boxes2, 4, axis=1)\n",
    "\n",
    "    inter_x1 = np.maximum(x11, x21.T)\n",
    "    inter_y1 = np.maximum(y11, y21.T)\n",
    "    inter_x2 = np.minimum(x12, x22.T)\n",
    "    inter_y2 = np.minimum(y12, y22.T)\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, a_min=0.0, a_max=None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, a_min=0.0, a_max=None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area1 = (x12 - x11) * (y12 - y11)\n",
    "    area2 = (x22 - x21) * (y22 - y21)\n",
    "\n",
    "    union = area1 + area2.T - inter_area\n",
    "    return np.divide(inter_area, union, out=np.zeros_like(inter_area), where=union > 0)\n",
    "\n",
    "\n",
    "def compute_average_precision(recalls: np.ndarray, precisions: np.ndarray) -> float:\n",
    "    \"\"\"Compute the interpolated Average Precision (AP) following COCO style.\"\"\"\n",
    "    if recalls.size == 0 or precisions.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    mrec = np.concatenate(([0.0], recalls, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precisions, [0.0]))\n",
    "\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "\n",
    "    recall_points = np.linspace(0, 1, 101)\n",
    "    precision_interp = np.interp(recall_points, mrec, mpre)\n",
    "    return float(np.trapz(precision_interp, recall_points))\n",
    "\n",
    "\n",
    "def accumulate_classification_stats(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[List[float]], List[List[int]], np.ndarray]:\n",
    "    \"\"\"Accumulate TP/FP/FN statistics and matched predictions for AP computation.\"\"\"\n",
    "    tp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fn = np.zeros(num_classes, dtype=np.int64)\n",
    "    scores: List[List[float]] = [[] for _ in range(num_classes)]\n",
    "    matches: List[List[int]] = [[] for _ in range(num_classes)]\n",
    "    gt_counter = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    for pred, tgt in zip(predictions, targets):\n",
    "        pred_boxes = pred[\"boxes\"]\n",
    "        pred_scores = pred[\"scores\"]\n",
    "        pred_labels = pred[\"labels\"].astype(np.int64)\n",
    "\n",
    "        gt_boxes = tgt[\"boxes\"]\n",
    "        gt_labels = tgt[\"labels\"].astype(np.int64)\n",
    "\n",
    "        unique_classes = np.unique(np.concatenate((pred_labels, gt_labels)))\n",
    "        for cls in unique_classes:\n",
    "            pb = pred_boxes[pred_labels == cls]\n",
    "            ps = pred_scores[pred_labels == cls]\n",
    "            tb = gt_boxes[gt_labels == cls]\n",
    "            gt_counter[cls] += len(tb)\n",
    "\n",
    "            if len(tb) == 0:\n",
    "                fp[cls] += len(pb)\n",
    "                scores[cls].extend(ps.tolist())\n",
    "                matches[cls].extend([0] * len(pb))\n",
    "                continue\n",
    "\n",
    "            order = np.argsort(-ps)\n",
    "            pb = pb[order]\n",
    "            ps = ps[order]\n",
    "            iou_matrix = compute_iou_matrix(pb, tb)\n",
    "\n",
    "            matched_gt: set[int] = set()\n",
    "            for det_idx, score in enumerate(ps):\n",
    "                if tb.size == 0:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "                    continue\n",
    "\n",
    "                best_gt = int(np.argmax(iou_matrix[det_idx]))\n",
    "                best_iou = iou_matrix[det_idx, best_gt]\n",
    "\n",
    "                if best_iou >= iou_threshold and best_gt not in matched_gt:\n",
    "                    tp[cls] += 1\n",
    "                    matched_gt.add(best_gt)\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(1)\n",
    "                else:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "\n",
    "            fn[cls] += len(tb) - len(matched_gt)\n",
    "\n",
    "    return tp, fp, fn, scores, matches, gt_counter\n",
    "\n",
    "\n",
    "def identify_false_positive_predictions(\n",
    "    prediction: Dict[str, np.ndarray],\n",
    "    target: Dict[str, np.ndarray],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> List[Dict[str, Union[int, float, List[float]]]]:\n",
    "    \"\"\"Return detailed records for false-positive detections in a single sample.\"\"\"\n",
    "\n",
    "    boxes = np.asarray(prediction.get(\"boxes\", np.empty((0, 4), dtype=np.float32)), dtype=np.float32)\n",
    "    scores = np.asarray(prediction.get(\"scores\", np.empty((0,), dtype=np.float32)), dtype=np.float32)\n",
    "    labels = np.asarray(prediction.get(\"labels\", np.empty((0,), dtype=np.int64)), dtype=np.int64)\n",
    "\n",
    "    gt_boxes = np.asarray(target.get(\"boxes\", np.empty((0, 4), dtype=np.float32)), dtype=np.float32)\n",
    "    gt_labels = np.asarray(target.get(\"labels\", np.empty((0,), dtype=np.int64)), dtype=np.int64)\n",
    "\n",
    "    if boxes.size == 0:\n",
    "        return []\n",
    "\n",
    "    fp_records: List[Dict[str, Union[int, float, List[float]]]] = []\n",
    "    unique_classes = np.unique(labels) if labels.size else np.asarray([], dtype=np.int64)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        cls = int(cls)\n",
    "        cls_mask = labels == cls\n",
    "        cls_indices = np.nonzero(cls_mask)[0]\n",
    "        if cls_indices.size == 0:\n",
    "            continue\n",
    "\n",
    "        pb = boxes[cls_mask]\n",
    "        ps = scores[cls_mask]\n",
    "        order = np.argsort(-ps)\n",
    "        pb_sorted = pb[order]\n",
    "        ps_sorted = ps[order]\n",
    "        original_indices = cls_indices[order]\n",
    "\n",
    "        tb = gt_boxes[gt_labels == cls]\n",
    "        iou_matrix = compute_iou_matrix(pb_sorted, tb) if tb.size else np.zeros((pb_sorted.shape[0], 0), dtype=np.float32)\n",
    "        matched_gt: set[int] = set()\n",
    "\n",
    "        for rank, (pred_idx, score_value) in enumerate(zip(original_indices, ps_sorted)):\n",
    "            if iou_matrix.shape[1]:\n",
    "                row = iou_matrix[rank]\n",
    "                best_gt = int(row.argmax())\n",
    "                best_iou = float(row[best_gt])\n",
    "            else:\n",
    "                best_gt = -1\n",
    "                best_iou = 0.0\n",
    "\n",
    "            is_true_positive = (\n",
    "                iou_matrix.shape[1] > 0\n",
    "                and best_iou >= iou_threshold\n",
    "                and best_gt not in matched_gt\n",
    "            )\n",
    "\n",
    "            if is_true_positive:\n",
    "                matched_gt.add(best_gt)\n",
    "                continue\n",
    "\n",
    "            fp_records.append(\n",
    "                {\n",
    "                    \"index\": int(pred_idx),\n",
    "                    \"class\": cls,\n",
    "                    \"score\": float(score_value),\n",
    "                    \"best_iou\": best_iou,\n",
    "                    \"box\": boxes[pred_idx].astype(float).tolist(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return fp_records\n",
    "\n",
    "\n",
    "def compute_detection_metrics(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Compute per-class metrics and mAP for detection results.\"\"\"\n",
    "    tp, fp, fn, scores, matches, gt_counter = accumulate_classification_stats(\n",
    "        predictions, targets, num_classes, iou_threshold\n",
    "    )\n",
    "\n",
    "    precision = np.divide(tp, np.clip(tp + fp, a_min=1, a_max=None))\n",
    "    recall = np.divide(tp, np.clip(tp + fn, a_min=1, a_max=None))\n",
    "\n",
    "    ap = np.zeros(num_classes, dtype=np.float32)\n",
    "    for cls in range(num_classes):\n",
    "        if gt_counter[cls] == 0:\n",
    "            ap[cls] = np.nan\n",
    "            continue\n",
    "        if not scores[cls]:\n",
    "            ap[cls] = 0.0\n",
    "            continue\n",
    "\n",
    "        order = np.argsort(-np.asarray(scores[cls]))\n",
    "        match_array = np.asarray(matches[cls], dtype=np.int32)[order]\n",
    "        cumulative_tp = np.cumsum(match_array)\n",
    "        cumulative_fp = np.cumsum(1 - match_array)\n",
    "\n",
    "        recalls = cumulative_tp / gt_counter[cls]\n",
    "        precisions = cumulative_tp / np.maximum(cumulative_tp + cumulative_fp, 1)\n",
    "        ap[cls] = compute_average_precision(recalls, precisions)\n",
    "\n",
    "    valid_ap = ap[np.isfinite(ap)]\n",
    "    map_value = float(valid_ap.mean()) if valid_ap.size else 0.0\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"AP\": ap,\n",
    "        \"mAP\": map_value,\n",
    "        \"gt_counter\": gt_counter,\n",
    "    }\n",
    "\n",
    "\n",
    "def score_threshold_mask(\n",
    "    scores: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    default_threshold: float,\n",
    "    class_thresholds: Mapping[int, float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return a boolean mask keeping predictions that pass per-class thresholds.\"\"\"\n",
    "\n",
    "    if scores.size == 0:\n",
    "        return np.zeros_like(scores, dtype=bool)\n",
    "\n",
    "    labels_int = labels.astype(np.int64, copy=False)\n",
    "    thresholds = np.full(scores.shape, default_threshold, dtype=scores.dtype)\n",
    "    if class_thresholds:\n",
    "        labels_fg = labels_int - 1  # convert to original 0-based ids\n",
    "        for cls, value in class_thresholds.items():\n",
    "            thresholds[labels_fg == int(cls)] = float(value)\n",
    "\n",
    "    keep = labels_int != 0  # drop background predictions outright\n",
    "    keep &= scores >= thresholds\n",
    "    return keep\n",
    "\n",
    "\n",
    "def parse_class_threshold_entries(entries: Sequence[str]) -> Dict[int, float]:\n",
    "    \"\"\"Parse ``CLS=THRESH`` strings into a mapping of per-class thresholds.\"\"\"\n",
    "\n",
    "    thresholds: Dict[int, float] = {}\n",
    "    for entry in entries:\n",
    "        if not entry:\n",
    "            continue\n",
    "\n",
    "        if \"=\" in entry:\n",
    "            key, value = entry.split(\"=\", 1)\n",
    "        elif \":\" in entry:\n",
    "            key, value = entry.split(\":\", 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid class threshold format: {entry!r}\")\n",
    "\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        if not key or not value:\n",
    "            raise ValueError(f\"Invalid class threshold entry: {entry!r}\")\n",
    "\n",
    "        thresholds[int(key)] = float(value)\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "def running_in_ipython_kernel() -> bool:\n",
    "    \"\"\"Return ``True`` when executing inside an IPython/Jupyter kernel.\"\"\"\n",
    "\n",
    "    try:  # ``IPython`` may be absent in some execution environments.\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "    except Exception:  # pragma: no cover - depends on environment\n",
    "        return False\n",
    "\n",
    "    shell = get_ipython()\n",
    "    return bool(shell and getattr(shell, \"kernel\", None))\n",
    "\n",
    "\n",
    "def emit_metric_lines(\n",
    "    lines: Sequence[str],\n",
    "    *,\n",
    "    logger: Optional[logging.Logger] = None,\n",
    "    force_print: Optional[bool] = None,\n",
    ") -> None:\n",
    "    \"\"\"Log metric lines and optionally echo them to ``stdout``.\n",
    "\n",
    "    Kaggle notebooks buffer ``logging`` output differently from regular Python\n",
    "    scripts, so we proactively mirror the messages with ``print`` when we detect\n",
    "    an IPython kernel.  Callers may override this behaviour by passing\n",
    "    ``force_print`` explicitly.\n",
    "    \"\"\"\n",
    "\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "\n",
    "    should_print = force_print if force_print is not None else running_in_ipython_kernel()\n",
    "\n",
    "    for line in lines:\n",
    "        if logger is not None:\n",
    "            logger.info(line)\n",
    "        if should_print:\n",
    "            print(line)\n",
    "\n",
    "\n",
    "def _resolve_class_label(dataset_cfg: DatasetConfig, index: int) -> str:\n",
    "    if index < len(dataset_cfg.class_names):\n",
    "        label = dataset_cfg.class_names[index]\n",
    "    else:\n",
    "        label = f\"class_{index:02d}\"\n",
    "\n",
    "    if label.startswith(\"class_\") and label[6:].isdigit():\n",
    "        return f\"class {int(label[6:]):02d}\"\n",
    "    return label\n",
    "\n",
    "\n",
    "def format_epoch_metrics(\n",
    "    epoch: Optional[int],\n",
    "    train_loss: Optional[float],\n",
    "    metrics: Dict[str, torch.Tensor | float | List[float]],\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    *,\n",
    "    header: Optional[str] = None,\n",
    ") -> List[str]:\n",
    "    lines: List[str] = []\n",
    "\n",
    "    val_loss = float(metrics.get(\"loss\", float(\"nan\")))\n",
    "    map_value = float(metrics.get(\"mAP\", float(\"nan\")))\n",
    "\n",
    "    if header is not None:\n",
    "        summary = header\n",
    "    elif epoch is not None:\n",
    "        summary = f\"Epoch {epoch:02d}\"\n",
    "    else:\n",
    "        summary = \"Metrics\"\n",
    "\n",
    "    if train_loss is not None and np.isfinite(train_loss):\n",
    "        summary += f\" | train loss {train_loss:.4f}\"\n",
    "    if np.isfinite(val_loss):\n",
    "        summary += f\" | val loss {val_loss:.4f}\"\n",
    "    if np.isfinite(map_value):\n",
    "        summary += f\" | mAP {map_value:.4f}\"\n",
    "    lines.append(summary)\n",
    "\n",
    "    precision = np.asarray(metrics.get(\"precision\", []), dtype=float)\n",
    "    recall = np.asarray(metrics.get(\"recall\", []), dtype=float)\n",
    "    tp = np.asarray(metrics.get(\"TP\", []), dtype=int)\n",
    "    fp = np.asarray(metrics.get(\"FP\", []), dtype=int)\n",
    "    fn = np.asarray(metrics.get(\"FN\", []), dtype=int)\n",
    "    ap = np.asarray(metrics.get(\"AP\", []), dtype=float)\n",
    "    gt_counter = np.asarray(metrics.get(\"gt_counter\", np.zeros_like(tp)), dtype=int)\n",
    "\n",
    "    num_classes = min(len(tp), dataset_cfg.num_classes)\n",
    "    for cls_idx in range(num_classes):\n",
    "        gt_value = int(gt_counter[cls_idx]) if gt_counter.size > cls_idx else 0\n",
    "        tp_value = int(tp[cls_idx]) if tp.size > cls_idx else 0\n",
    "        fp_value = int(fp[cls_idx]) if fp.size > cls_idx else 0\n",
    "        fn_value = int(fn[cls_idx]) if fn.size > cls_idx else 0\n",
    "\n",
    "        if gt_value == 0 and tp_value == 0 and fp_value == 0 and fn_value == 0:\n",
    "            continue\n",
    "\n",
    "        label = _resolve_class_label(dataset_cfg, cls_idx)\n",
    "        p_val = (\n",
    "            float(np.nan_to_num(precision[cls_idx], nan=0.0))\n",
    "            if precision.size > cls_idx\n",
    "            else 0.0\n",
    "        )\n",
    "        r_val = (\n",
    "            float(np.nan_to_num(recall[cls_idx], nan=0.0))\n",
    "            if recall.size > cls_idx\n",
    "            else 0.0\n",
    "        )\n",
    "        line = f\"{label} | P={p_val:.3f} R={r_val:.3f}  TP={tp_value} FP={fp_value} FN={fn_value}\"\n",
    "        if ap.size > cls_idx and np.isfinite(ap[cls_idx]):\n",
    "            line += f\" AP={ap[cls_idx]:.3f}\"\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def load_default_font() -> ImageFont.FreeTypeFont | ImageFont.ImageFont:\n",
    "    \"\"\"Load a truetype font when available, otherwise fall back to default.\"\"\"\n",
    "\n",
    "    try:\n",
    "        return ImageFont.truetype(\"DejaVuSans.ttf\", size=14)\n",
    "    except Exception:  # pragma: no cover - fallback when font unavailable\n",
    "        return ImageFont.load_default()\n",
    "\n",
    "\n",
    "def _resolve_class_name(class_names: Sequence[str], label: int) -> str:\n",
    "    if 0 <= label < len(class_names):\n",
    "        name = class_names[label]\n",
    "    else:\n",
    "        name = f\"class_{label:02d}\"\n",
    "\n",
    "    if name.startswith(\"class_\") and name[6:].isdigit():\n",
    "        return f\"class {int(name[6:]):02d}\"\n",
    "    return name\n",
    "\n",
    "\n",
    "def render_detections(\n",
    "    image: np.ndarray,\n",
    "    prediction: Mapping[str, np.ndarray],\n",
    "    target: Mapping[str, np.ndarray] | None,\n",
    "    class_names: Sequence[str],\n",
    "    score_threshold: float,\n",
    "    class_thresholds: Mapping[int, float],\n",
    "    draw_ground_truth: bool,\n",
    ") -> PILImage:\n",
    "    \"\"\"Render detection predictions (and optional ground truth) onto an image.\"\"\"\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image_array = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        image_array = image\n",
    "\n",
    "    pil = PILImage.fromarray(image_array)\n",
    "    draw = ImageDraw.Draw(pil)\n",
    "    font = load_default_font()\n",
    "\n",
    "    boxes = np.asarray(prediction.get(\"boxes\", np.empty((0, 4))), dtype=float)\n",
    "    labels = np.asarray(prediction.get(\"labels\", np.empty((0,), dtype=int)), dtype=int)\n",
    "    scores = np.asarray(prediction.get(\"scores\", np.empty((0,), dtype=float)), dtype=float)\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        threshold = class_thresholds.get(int(label), score_threshold)\n",
    "        if score < threshold:\n",
    "            continue\n",
    "\n",
    "        color = DEFAULT_COLORS[int(label) % len(DEFAULT_COLORS)] if len(DEFAULT_COLORS) else \"#FF6B6B\"\n",
    "        x1, y1, x2, y2 = [float(coord) for coord in box]\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "\n",
    "        caption = f\"{_resolve_class_name(class_names, int(label))} {score:.2f}\"\n",
    "        text_width = draw.textlength(caption, font=font)\n",
    "        draw.rectangle([x1, y1 - 16, x1 + text_width + 8, y1], fill=color)\n",
    "        draw.text((x1 + 4, y1 - 14), caption, fill=\"white\", font=font)\n",
    "\n",
    "    if draw_ground_truth and target is not None:\n",
    "        gt_boxes = np.asarray(target.get(\"boxes\", np.empty((0, 4))), dtype=float)\n",
    "        gt_labels = np.asarray(target.get(\"labels\", np.empty((0,), dtype=int)), dtype=int)\n",
    "        for box, label in zip(gt_boxes, gt_labels):\n",
    "            x1, y1, x2, y2 = [float(coord) for coord in box]\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"#FFFFFF\", width=1)\n",
    "            caption = f\"GT {_resolve_class_name(class_names, int(label))}\"\n",
    "            text_width = draw.textlength(caption, font=font)\n",
    "            draw.rectangle([x1, y2, x1 + text_width + 6, y2 + 14], fill=\"#FFFFFF\")\n",
    "            draw.text((x1 + 3, y2), caption, fill=\"black\", font=font)\n",
    "\n",
    "    return pil\n",
    "\n",
    "\n",
    "def save_detection_visual(\n",
    "    image: np.ndarray,\n",
    "    prediction: Mapping[str, np.ndarray],\n",
    "    target: Mapping[str, np.ndarray] | None,\n",
    "    class_names: Sequence[str],\n",
    "    score_threshold: float,\n",
    "    class_thresholds: Mapping[int, float],\n",
    "    draw_ground_truth: bool,\n",
    "    output_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"Render and persist a detection visualisation to ``output_path``.\"\"\"\n",
    "\n",
    "    visual = render_detections(\n",
    "        image,\n",
    "        prediction,\n",
    "        target,\n",
    "        class_names,\n",
    "        score_threshold,\n",
    "        class_thresholds,\n",
    "        draw_ground_truth,\n",
    "    )\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    visual.save(output_path)\n",
    "\n",
    "\n",
    "def write_false_positive_report(\n",
    "    fp_records: Sequence[Dict[str, object]],\n",
    "    report_path: Path,\n",
    "    *,\n",
    "    split: str,\n",
    "    score_threshold: float,\n",
    "    class_score_thresholds: Mapping[int, float],\n",
    "    iou_threshold: float,\n",
    ") -> None:\n",
    "    \"\"\"Serialise detailed false-positive information to JSON.\"\"\"\n",
    "\n",
    "    report_payload = {\n",
    "        \"split\": split,\n",
    "        \"score_threshold\": score_threshold,\n",
    "        \"class_score_thresholds\": dict(class_score_thresholds),\n",
    "        \"iou_threshold\": iou_threshold,\n",
    "        \"false_positive_images\": list(fp_records),\n",
    "    }\n",
    "    report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    report_path.write_text(json.dumps(report_payload, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "def write_false_positive_list(fp_records: Sequence[Dict[str, object]], list_path: Path) -> None:\n",
    "    \"\"\"Write newline separated image identifiers that triggered false positives.\"\"\"\n",
    "\n",
    "    stems = sorted({str(record[\"image_id\"]) for record in fp_records})\n",
    "    list_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    list_path.write_text(\"\\n\".join(stems) + (\"\\n\" if stems else \"\"))\n",
    "\n",
    "\n",
    "class SmoothedValue:\n",
    "    \"\"\"Track a series of values and provide access to smoothed statistics.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size: int = 20) -> None:\n",
    "        self.window_size = window_size\n",
    "        self.deque: List[float] = []\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value: float) -> None:\n",
    "        if len(self.deque) == self.window_size:\n",
    "            self.total -= self.deque.pop(0)\n",
    "        self.deque.append(value)\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "\n",
    "    @property\n",
    "    def avg(self) -> float:\n",
    "        if not self.deque:\n",
    "            return 0.0\n",
    "        return self.total / len(self.deque)\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    \"\"\"Helper class that logs running averages for multiple metrics.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.meters: Dict[str, SmoothedValue] = {}\n",
    "\n",
    "    def update(self, **kwargs: float) -> None:\n",
    "        for name, value in kwargs.items():\n",
    "            if name not in self.meters:\n",
    "                self.meters[name] = SmoothedValue()\n",
    "            self.meters[name].update(float(value))\n",
    "\n",
    "    def format(self) -> str:\n",
    "        parts = [f\"{name}: {meter.avg:.4f}\" for name, meter in self.meters.items()]\n",
    "        return \" | \".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca99e12",
   "metadata": {
    "papermill": {
     "duration": 0.003005,
     "end_time": "2025-10-21T07:01:27.386218",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.383213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07e4d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.393604Z",
     "iopub.status.busy": "2025-10-21T07:01:27.393381Z",
     "iopub.status.idle": "2025-10-21T07:01:27.401990Z",
     "shell.execute_reply": "2025-10-21T07:01:27.401426Z"
    },
    "papermill": {
     "duration": 0.013596,
     "end_time": "2025-10-21T07:01:27.403015",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.389419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Model building utilities for Faster R-CNN based detectors.\"\"\"\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _save_state_dict(model: nn.Module, path: Path) -> None:\n",
    "    try:\n",
    "        torch.save(model.state_dict(), path)\n",
    "        LOGGER.info(\"Saved pretrained weights to %s\", path)\n",
    "    except Exception as exc:  # pragma: no cover - safety net\n",
    "        LOGGER.warning(\"Unable to save pretrained weights: %s\", exc)\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> nn.Module:\n",
    "    \"\"\"Create a Faster R-CNN model adjusted for the project dataset.\"\"\"\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = _load_pretrained_model(train_cfg)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    num_classes_with_background = dataset_cfg.num_classes + 1\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num_classes_with_background\n",
    "    )\n",
    "\n",
    "    if train_cfg.small_object:\n",
    "        anchor_generator = AnchorGenerator(\n",
    "            #sizes=((16,), (32,), (64,), (128,), (256,)),\n",
    "            #aspect_ratios=((0.5, 1.0, 2.0),) * 5,\n",
    "            sizes=((16, 24), (32, 48), (64, 96), (128, 192), (256, 384)),\n",
    "            aspect_ratios=((0.2, 0.5, 1.0, 2.0, 5.0),) * 5\n",
    "        )\n",
    "        model.rpn.anchor_generator = anchor_generator\n",
    "        LOGGER.info(\"Using custom anchor sizes optimised for small objects\")\n",
    "\n",
    "        # 1. \u4ece\u65e7\u7684 RPNHead \u4e2d\u83b7\u53d6 in_channels\n",
    "        in_channels = model.rpn.head.cls_logits.in_channels\n",
    "\n",
    "        # 2. \u4ece\u65b0\u7684 AnchorGenerator \u83b7\u53d6\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u951a\u6846\u6570\n",
    "        #    (\u4f8b\u5982\uff0c5 \u4e2a aspect_ratios * 2 \u4e2a sizes = 10)\n",
    "        num_anchors_per_location = anchor_generator.num_anchors_per_location()[0]\n",
    "    \n",
    "        # 3. \u521b\u5efa\u5e76\u66ff\u6362 RPNHead\n",
    "        new_head = RPNHead(in_channels, num_anchors_per_location)\n",
    "        model.rpn.head = new_head\n",
    "        LOGGER.info(\n",
    "            \"Re-created RPN head for %d anchors per location to match AnchorGenerator.\",\n",
    "            num_anchors_per_location\n",
    "        )\n",
    "\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _load_pretrained_model(train_cfg: TrainingConfig) -> nn.Module:\n",
    "    \"\"\"Load a Faster R-CNN model with fallback to local weights when offline.\"\"\"\n",
    "    pretrained_path = train_cfg.pretrained_weights_path\n",
    "    pretrained_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    weights_enum = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    try:\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=weights_enum)\n",
    "        LOGGER.info(\"Loaded torchvision Faster R-CNN weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            _save_state_dict(model, pretrained_path)\n",
    "        return model\n",
    "    except Exception:  # pragma: no cover - fallback when torchvision download fails\n",
    "        LOGGER.warning(\"Falling back to locally saved pretrained detector weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            raise RuntimeError(\n",
    "                \"No pretrained weights available. Download the torchvision weights manually \"\n",
    "                \"and place them at %s\" % pretrained_path\n",
    "            )\n",
    "        state_dict = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=None)\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb051f6",
   "metadata": {
    "papermill": {
     "duration": 0.003072,
     "end_time": "2025-10-21T07:01:27.409284",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.406212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820377d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.416584Z",
     "iopub.status.busy": "2025-10-21T07:01:27.416371Z",
     "iopub.status.idle": "2025-10-21T07:01:27.440605Z",
     "shell.execute_reply": "2025-10-21T07:01:27.440046Z"
    },
    "papermill": {
     "duration": 0.029234,
     "end_time": "2025-10-21T07:01:27.441714",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.412480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Training script for the electrical component Faster R-CNN detector.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import contextlib\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from torch.amp import GradScaler  # PyTorch 2.1+\n",
    "except ImportError:  # pragma: no cover - compatibility path\n",
    "    from torch.cuda.amp import GradScaler  # type: ignore[attr-defined]\n",
    "\n",
    "try:\n",
    "    from torch.serialization import add_safe_globals\n",
    "except ImportError:  # pragma: no cover - compatibility path\n",
    "    add_safe_globals = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(\"train\")\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--data-dir\", type=Path, default=DatasetConfig().base_dir)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=4)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=TrainingConfig().num_workers)\n",
    "    parser.add_argument(\"--no-augmentation\", action=\"store_true\", help=\"Disable data augmentation\")\n",
    "    parser.add_argument(\n",
    "        \"--mosaic-prob\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().mosaic_prob,\n",
    "        help=\"Probability of applying mosaic augmentation (four-image collage)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mixup-prob\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().mixup_prob,\n",
    "        help=\"Probability of mixing an additional image into the current sample\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mixup-alpha\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().mixup_alpha,\n",
    "        help=\"Alpha parameter for the Beta distribution controlling MixUp strength\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--scale-jitter\", nargs=2, type=float, metavar=(\"MIN\", \"MAX\"), default=None,\n",
    "        help=\"Uniform scale jitter range applied to each image before flips/jitter\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--rotation-prob\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().rotation_prob,\n",
    "        help=\"Probability of applying a random in-place rotation.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--rotation-max-degrees\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().rotation_max_degrees,\n",
    "        help=\"Maximum absolute angle in degrees for random rotations.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--affine-prob\",\n",
    "        type=float,\n",
    "        default=TrainingConfig().affine_prob,\n",
    "        help=\"Probability of applying a random affine transform (translate/scale/shear).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--affine-translate\",\n",
    "        nargs=2,\n",
    "        type=float,\n",
    "        metavar=(\"FRAC_X\", \"FRAC_Y\"),\n",
    "        default=None,\n",
    "        help=\"Maximum absolute translation as a fraction of image width/height.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--affine-scale\",\n",
    "        nargs=2,\n",
    "        type=float,\n",
    "        metavar=(\"MIN\", \"MAX\"),\n",
    "        default=None,\n",
    "        help=\"Uniform scaling range applied during affine augmentation.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--affine-shear\",\n",
    "        nargs=2,\n",
    "        type=float,\n",
    "        metavar=(\"SHEAR_X\", \"SHEAR_Y\"),\n",
    "        default=None,\n",
    "        help=\"Maximum absolute shear angles (degrees) for the affine augmentation.\",\n",
    "    )\n",
    "    parser.add_argument(\"--small-object\", action=\"store_true\", help=\"Use smaller RPN anchors\")\n",
    "    parser.add_argument(\"--score-threshold\", type=float, default=0.6)\n",
    "    parser.add_argument(\n",
    "        \"--class-threshold\",\n",
    "        action=\"append\",\n",
    "        default=[],\n",
    "        metavar=\"CLS=THRESH\",\n",
    "        help=\"Override per-class score thresholds (e.g. --class-threshold 3=0.8)\",\n",
    "    )\n",
    "    parser.add_argument(\"--iou-threshold\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--no-amp\", action=\"store_true\", help=\"Disable automatic mixed precision\")\n",
    "    parser.add_argument(\"--eval-interval\", type=int, default=1)\n",
    "    parser.add_argument(\"--seed\", type=int, default=2024)\n",
    "    parser.add_argument(\"--checkpoint\", type=Path, default=TrainingConfig().checkpoint_path)\n",
    "    parser.add_argument(\"--pretrained-path\", type=Path, default=TrainingConfig().pretrained_weights_path)\n",
    "    parser.add_argument(\"--resume\", action=\"store_true\", help=\"Resume training from a saved checkpoint.\")\n",
    "    parser.add_argument(\n",
    "        \"--resume-path\",\n",
    "        type=Path,\n",
    "        default=None,\n",
    "        help=\"Optional path to the checkpoint used for resuming training. Defaults to the last-checkpoint file.\",\n",
    "    )\n",
    "    parser.add_argument(\"--log-every\", type=int, default=20)\n",
    "    parser.add_argument(\"--train-split\", default=DatasetConfig().train_split)\n",
    "    parser.add_argument(\"--valid-split\", default=DatasetConfig().valid_split)\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=DatasetConfig().num_classes)\n",
    "    parser.add_argument(\n",
    "        \"--exclude-list\",\n",
    "        action=\"append\",\n",
    "        default=[],\n",
    "        type=Path,\n",
    "        help=\"Path(s) to files listing image stems to exclude from training (text or JSON).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--exclude-sample\",\n",
    "        action=\"append\",\n",
    "        default=[],\n",
    "        help=\"Additional image stems to remove from the training split.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp-dir\",\n",
    "        type=Path,\n",
    "        default=None,\n",
    "        help=\"Directory where false-positive visualisations from the final epoch are written.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp-report\",\n",
    "        type=Path,\n",
    "        help=\"Optional path to write a JSON report describing final-epoch false positives.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp-list\",\n",
    "        type=Path,\n",
    "        help=\"Optional path to write newline separated image stems containing final-epoch false positives.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp-class\",\n",
    "        action=\"append\",\n",
    "        type=int,\n",
    "        default=[],\n",
    "        help=\"Restrict false-positive exports to specific classes (repeatable).\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def _normalise_stem(value: str) -> str:\n",
    "    return Path(value).stem if value else value\n",
    "\n",
    "\n",
    "def _load_exclusions_from_file(path: Path) -> List[str]:\n",
    "    try:\n",
    "        text = path.read_text(encoding=\"utf-8\")\n",
    "    except OSError as exc:\n",
    "        LOGGER.warning(\"Unable to read exclude list %s: %s\", path, exc)\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        payload = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "        return [_normalise_stem(line) for line in lines]\n",
    "\n",
    "    stems: List[str] = []\n",
    "    if isinstance(payload, dict):\n",
    "        for key in (\"stems\", \"image_ids\", \"images\"):\n",
    "            if key in payload and isinstance(payload[key], list):\n",
    "                stems.extend(_normalise_stem(str(item)) for item in payload[key])\n",
    "        if \"false_positive_images\" in payload and isinstance(payload[\"false_positive_images\"], list):\n",
    "            for entry in payload[\"false_positive_images\"]:\n",
    "                if isinstance(entry, dict):\n",
    "                    if \"image_id\" in entry:\n",
    "                        stems.append(_normalise_stem(str(entry[\"image_id\"])))\n",
    "                    elif \"image\" in entry:\n",
    "                        stems.append(_normalise_stem(str(entry[\"image\"])))\n",
    "    elif isinstance(payload, list):\n",
    "        for entry in payload:\n",
    "            if isinstance(entry, dict):\n",
    "                if \"image_id\" in entry:\n",
    "                    stems.append(_normalise_stem(str(entry[\"image_id\"])))\n",
    "                elif \"image\" in entry:\n",
    "                    stems.append(_normalise_stem(str(entry[\"image\"])))\n",
    "            else:\n",
    "                stems.append(_normalise_stem(str(entry)))\n",
    "\n",
    "    return [stem for stem in stems if stem]\n",
    "\n",
    "\n",
    "def _resolve_exclusions(paths: List[Path], samples: List[str]) -> List[str]:\n",
    "    stems: Set[str] = {_normalise_stem(sample) for sample in samples if sample}\n",
    "    for path in paths:\n",
    "        if path is None:\n",
    "            continue\n",
    "        if not path.exists():\n",
    "            LOGGER.warning(\"Exclude list %s does not exist; skipping.\", path)\n",
    "            continue\n",
    "        stems.update(_load_exclusions_from_file(path))\n",
    "    return sorted(stem for stem in stems if stem)\n",
    "\n",
    "\n",
    "def prepare_configs(args: argparse.Namespace) -> tuple[DatasetConfig, TrainingConfig]:\n",
    "    default_train_cfg = TrainingConfig()\n",
    "    dataset_cfg = DatasetConfig(\n",
    "        base_dir=args.data_dir,\n",
    "        train_split=args.train_split,\n",
    "        valid_split=args.valid_split,\n",
    "        num_classes=args.num_classes,\n",
    "    )\n",
    "\n",
    "    class_thresholds = DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    overrides = parse_class_threshold_entries(args.class_threshold)\n",
    "    class_thresholds.update(overrides)\n",
    "\n",
    "    exclude_samples = _resolve_exclusions(args.exclude_list, args.exclude_sample)\n",
    "\n",
    "    if args.fp_class:\n",
    "        fp_class_values = sorted({int(value) for value in args.fp_class})\n",
    "        fp_classes = tuple(fp_class_values)\n",
    "    else:\n",
    "        fp_classes = default_train_cfg.fp_classes\n",
    "\n",
    "    if args.fp_dir is not None:\n",
    "        fp_dir = Path(args.fp_dir)\n",
    "    else:\n",
    "        fp_dir = default_train_cfg.fp_visual_dir\n",
    "\n",
    "    fp_report_path = Path(args.fp_report) if args.fp_report is not None else args.fp_report\n",
    "    fp_list_path = Path(args.fp_list) if args.fp_list is not None else args.fp_list\n",
    "\n",
    "    if args.scale_jitter:\n",
    "        scale_min, scale_max = args.scale_jitter\n",
    "    else:\n",
    "        scale_min = default_train_cfg.scale_jitter_min\n",
    "        scale_max = default_train_cfg.scale_jitter_max\n",
    "\n",
    "    rotation_prob = args.rotation_prob\n",
    "    rotation_max = args.rotation_max_degrees\n",
    "\n",
    "    affine_prob = args.affine_prob\n",
    "    if args.affine_translate is not None:\n",
    "        affine_translate = (float(args.affine_translate[0]), float(args.affine_translate[1]))\n",
    "    else:\n",
    "        affine_translate = default_train_cfg.affine_translate\n",
    "\n",
    "    if args.affine_scale is not None:\n",
    "        affine_scale_range = (float(args.affine_scale[0]), float(args.affine_scale[1]))\n",
    "    else:\n",
    "        affine_scale_range = default_train_cfg.affine_scale_range\n",
    "\n",
    "    if args.affine_shear is not None:\n",
    "        affine_shear = (float(args.affine_shear[0]), float(args.affine_shear[1]))\n",
    "    else:\n",
    "        affine_shear = default_train_cfg.affine_shear\n",
    "\n",
    "    checkpoint_path = Path(args.checkpoint)\n",
    "    pretrained_path = Path(args.pretrained_path)\n",
    "    last_checkpoint_path = checkpoint_path.parent / \"last_checkpoint.pth\"\n",
    "    if args.resume_path is not None:\n",
    "        resume_path = Path(args.resume_path)\n",
    "    elif args.resume:\n",
    "        resume_path = last_checkpoint_path\n",
    "    else:\n",
    "        resume_path = None\n",
    "\n",
    "    train_cfg = TrainingConfig(\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.lr,\n",
    "        weight_decay=args.weight_decay,\n",
    "        num_workers=args.num_workers,\n",
    "        amp=not args.no_amp,\n",
    "        augmentation=not args.no_augmentation,\n",
    "        mosaic_prob=args.mosaic_prob,\n",
    "        mixup_prob=args.mixup_prob,\n",
    "        mixup_alpha=args.mixup_alpha,\n",
    "        scale_jitter_min=scale_min,\n",
    "        scale_jitter_max=scale_max,\n",
    "        rotation_prob=rotation_prob,\n",
    "        rotation_max_degrees=rotation_max,\n",
    "        affine_prob=affine_prob,\n",
    "        affine_translate=affine_translate,\n",
    "        affine_scale_range=affine_scale_range,\n",
    "        affine_shear=affine_shear,\n",
    "        small_object=args.small_object,\n",
    "        score_threshold=args.score_threshold,\n",
    "        iou_threshold=args.iou_threshold,\n",
    "        eval_interval=args.eval_interval,\n",
    "        seed=args.seed,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        pretrained_weights_path=pretrained_path,\n",
    "        resume=args.resume,\n",
    "        resume_path=resume_path,\n",
    "        last_checkpoint_path=last_checkpoint_path,\n",
    "        log_every=args.log_every,\n",
    "        class_score_thresholds=class_thresholds,\n",
    "        exclude_samples=tuple(exclude_samples),\n",
    "        fp_visual_dir=fp_dir,\n",
    "        fp_report_path=fp_report_path,\n",
    "        fp_list_path=fp_list_path,\n",
    "        fp_classes=fp_classes,\n",
    "    )\n",
    "    train_cfg.ensure_directories()\n",
    "    return dataset_cfg, train_cfg\n",
    "\n",
    "\n",
    "def move_to_device(targets: List[Dict[str, torch.Tensor]], device: torch.device) -> List[Dict[str, torch.Tensor]]:\n",
    "    return [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scaler: GradScaler,\n",
    "    device: torch.device,\n",
    "    amp: bool,\n",
    "    log_every: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger()\n",
    "    progress = tqdm(loader, desc=\"Train\", leave=False)\n",
    "\n",
    "    for step, (images, targets) in enumerate(progress, start=1):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = move_to_device(targets, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        autocast_enabled = amp and device.type == \"cuda\"\n",
    "        autocast_context = (\n",
    "            torch.amp.autocast(device_type=\"cuda\") if autocast_enabled else contextlib.nullcontext()\n",
    "        )\n",
    "        with autocast_context:\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss_dict.values())\n",
    "\n",
    "        if torch.isfinite(loss):\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:  # pragma: no cover - guard for invalid losses\n",
    "            LOGGER.warning(\"Skipping step %s due to non-finite loss\", step)\n",
    "            scaler.update()\n",
    "            continue\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        if step % log_every == 0:\n",
    "            progress.set_postfix_str(metric_logger.format())\n",
    "\n",
    "    return metric_logger.meters.get(\"loss\").avg if metric_logger.meters else 0.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    *,\n",
    "    dataset: ElectricalComponentsDataset | None = None,\n",
    "    collect_details: bool = False,\n",
    ") -> tuple[Dict[str, torch.Tensor | float | List[float]], List[Dict[str, object]]]:\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    targets_for_eval = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    sample_details: List[Dict[str, object]] = []\n",
    "    dataset_ref = dataset if dataset is not None else getattr(loader, \"dataset\", None)\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets_device = move_to_device(targets, device)\n",
    "\n",
    "        model.train()\n",
    "        loss_dict = model(images, targets_device)\n",
    "        total_loss += sum(loss_dict.values()).item()\n",
    "        num_batches += 1\n",
    "        model.eval()\n",
    "\n",
    "        outputs = model(images)\n",
    "        for output, target_device, target_cpu in zip(outputs, targets_device, targets):\n",
    "            boxes_np = output[\"boxes\"].detach().cpu().numpy()\n",
    "            scores_np = output[\"scores\"].detach().cpu().numpy()\n",
    "            labels_np = output[\"labels\"].detach().cpu().numpy().astype(np.int64, copy=False)\n",
    "            keep = score_threshold_mask(\n",
    "                scores_np,\n",
    "                labels_np,\n",
    "                train_cfg.score_threshold,\n",
    "                train_cfg.class_score_thresholds,\n",
    "            )\n",
    "            boxes_np = boxes_np[keep]\n",
    "            scores_np = scores_np[keep]\n",
    "            labels_np = labels_np[keep].astype(np.int64, copy=True)\n",
    "            if labels_np.size:\n",
    "                labels_np -= 1\n",
    "\n",
    "            target_boxes = target_device[\"boxes\"].detach().cpu().numpy()\n",
    "            target_labels = target_device[\"labels\"].detach().cpu().numpy().astype(np.int64, copy=True)\n",
    "            if target_labels.size:\n",
    "                gt_keep = target_labels > 0\n",
    "                target_boxes = target_boxes[gt_keep]\n",
    "                target_labels = target_labels[gt_keep] - 1\n",
    "\n",
    "            prediction_np = {\n",
    "                \"boxes\": boxes_np,\n",
    "                \"scores\": scores_np,\n",
    "                \"labels\": labels_np,\n",
    "            }\n",
    "            target_np = {\n",
    "                \"boxes\": target_boxes,\n",
    "                \"labels\": target_labels,\n",
    "            }\n",
    "\n",
    "            predictions.append(prediction_np)\n",
    "            targets_for_eval.append(target_np)\n",
    "\n",
    "            if collect_details:\n",
    "                image_identifier = target_cpu.get(\"image_id\", -1)\n",
    "                if isinstance(image_identifier, torch.Tensor):\n",
    "                    image_index = int(image_identifier.item())\n",
    "                else:\n",
    "                    try:\n",
    "                        image_index = int(image_identifier)\n",
    "                    except Exception:\n",
    "                        image_index = -1\n",
    "                if dataset_ref is not None and 0 <= image_index < len(getattr(dataset_ref, \"image_stems\", [])):\n",
    "                    image_id = dataset_ref.image_stems[image_index]\n",
    "                else:\n",
    "                    image_id = f\"{dataset_cfg.valid_split}_{len(sample_details):04d}\"\n",
    "\n",
    "                fp_info = identify_false_positive_predictions(\n",
    "                    prediction_np,\n",
    "                    target_np,\n",
    "                    dataset_cfg.num_classes,\n",
    "                    train_cfg.iou_threshold,\n",
    "                )\n",
    "\n",
    "                sample_details.append(\n",
    "                    {\n",
    "                        \"image_index\": image_index,\n",
    "                        \"image_id\": image_id,\n",
    "                        \"prediction\": prediction_np,\n",
    "                        \"target\": target_np,\n",
    "                        \"false_positives\": fp_info,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, train_cfg.iou_threshold\n",
    "    )\n",
    "    metrics[\"loss\"] = total_loss / max(num_batches, 1)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return metrics, sample_details\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "    *,\n",
    "    path: Path,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer | None,\n",
    "    scaler: GradScaler | None,\n",
    "    epoch: int,\n",
    "    best_map: float,\n",
    "    history: List[Dict[str, float]],\n",
    "    train_cfg: TrainingConfig,\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n",
    "        \"scaler\": scaler.state_dict() if scaler is not None and getattr(scaler, \"is_enabled\", lambda: True)() else None,\n",
    "        \"epoch\": epoch,\n",
    "        \"best_map\": float(best_map),\n",
    "        \"history\": list(history),\n",
    "        \"config\": asdict(train_cfg),\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    LOGGER.info(\"Saved checkpoint to %s (epoch %d, best mAP %.4f)\", path, epoch, best_map)\n",
    "\n",
    "\n",
    "def _load_checkpoint_file(path: Path, device: torch.device) -> object:\n",
    "    load_kwargs = {\"map_location\": device}\n",
    "    try:\n",
    "        return torch.load(path, **load_kwargs)\n",
    "    except pickle.UnpicklingError:\n",
    "        safe_objects: List[object] = []\n",
    "        if add_safe_globals is not None:\n",
    "            safe_objects.append(TrainingConfig)\n",
    "            try:\n",
    "                safe_objects.append(type(Path(\".\")))\n",
    "            except Exception:  # pragma: no cover - defensive\n",
    "                pass\n",
    "            add_safe_globals(safe_objects)\n",
    "        load_params = inspect.signature(torch.load).parameters\n",
    "        if \"weights_only\" in load_params:\n",
    "            load_kwargs[\"weights_only\"] = False\n",
    "        return torch.load(path, **load_kwargs)\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    *,\n",
    "    path: Path,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer | None,\n",
    "    scaler: GradScaler | None,\n",
    "    device: torch.device,\n",
    ") -> tuple[int, float, List[Dict[str, float]]]:\n",
    "    if not path.exists():\n",
    "        LOGGER.warning(\"Checkpoint %s does not exist; starting fresh.\", path)\n",
    "        return 1, -float(\"inf\"), []\n",
    "\n",
    "    checkpoint_obj = _load_checkpoint_file(path, device)\n",
    "\n",
    "    if isinstance(checkpoint_obj, dict) and \"model\" in checkpoint_obj:\n",
    "        model.load_state_dict(checkpoint_obj[\"model\"])\n",
    "        if optimizer is not None and checkpoint_obj.get(\"optimizer\") is not None:\n",
    "            optimizer.load_state_dict(checkpoint_obj[\"optimizer\"])\n",
    "        if scaler is not None and checkpoint_obj.get(\"scaler\") is not None:\n",
    "            try:\n",
    "                scaler.load_state_dict(checkpoint_obj[\"scaler\"])\n",
    "            except Exception as exc:  # pragma: no cover - fallback if scaler config changed\n",
    "                LOGGER.warning(\"Unable to load scaler state from %s: %s\", path, exc)\n",
    "        epoch = int(checkpoint_obj.get(\"epoch\", 0))\n",
    "        best_map = float(checkpoint_obj.get(\"best_map\", -float(\"inf\")))\n",
    "        history = checkpoint_obj.get(\"history\", [])\n",
    "        LOGGER.info(\n",
    "            \"Loaded checkpoint from %s (epoch %d, best mAP %.4f)\",\n",
    "            path,\n",
    "            epoch,\n",
    "            best_map,\n",
    "        )\n",
    "        return epoch + 1, best_map, list(history)\n",
    "\n",
    "    # Legacy checkpoint: assume it's a plain state dict.\n",
    "    model.load_state_dict(checkpoint_obj)\n",
    "    LOGGER.info(\"Loaded model weights from legacy checkpoint %s\", path)\n",
    "    return 1, -float(\"inf\"), []\n",
    "\n",
    "\n",
    "def _create_grad_scaler(amp_enabled: bool, device: torch.device) -> GradScaler:\n",
    "    \"\"\"Create a GradScaler compatible with both legacy and new AMP APIs.\"\"\"\n",
    "    scaler_enabled = amp_enabled and device.type == \"cuda\"\n",
    "    init_params = inspect.signature(GradScaler.__init__).parameters\n",
    "    kwargs = {\"enabled\": scaler_enabled}\n",
    "    if \"device_type\" in init_params:\n",
    "        kwargs[\"device_type\"] = device.type\n",
    "    return GradScaler(**kwargs)\n",
    "\n",
    "\n",
    "def export_false_positive_visuals(\n",
    "    *,\n",
    "    dataset: ElectricalComponentsDataset,\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    sample_details: List[Dict[str, object]],\n",
    ") -> List[Dict[str, object]]:\n",
    "    \"\"\"Export false-positive visuals for the configured classes and return records.\"\"\"\n",
    "\n",
    "    if not train_cfg.fp_visual_dir:\n",
    "        return []\n",
    "\n",
    "    relevant_classes = {int(cls) for cls in train_cfg.fp_classes}\n",
    "    if not relevant_classes:\n",
    "        return []\n",
    "\n",
    "    output_dir = train_cfg.fp_visual_dir\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Keep only the last-epoch visuals by clearing previous outputs.\n",
    "    for existing in output_dir.glob(\"*.png\"):\n",
    "        try:\n",
    "            existing.unlink()\n",
    "        except OSError:\n",
    "            LOGGER.debug(\"Unable to remove previous FP visual %s\", existing)\n",
    "\n",
    "    fp_records: List[Dict[str, object]] = []\n",
    "\n",
    "    for detail in sample_details:\n",
    "        raw_records = detail.get(\"false_positives\", [])\n",
    "        if not raw_records:\n",
    "            continue\n",
    "\n",
    "        filtered = [fp for fp in raw_records if int(fp.get(\"class\", -1)) in relevant_classes]\n",
    "        if not filtered:\n",
    "            continue\n",
    "\n",
    "        image_id = str(detail.get(\"image_id\", detail.get(\"image_index\", \"unknown\")))\n",
    "        try:\n",
    "            image_np, _, _ = dataset._load_raw_sample(image_id)\n",
    "        except Exception as exc:  # pragma: no cover - defensive\n",
    "            LOGGER.warning(\"Skipping FP visual for %s due to load error: %s\", image_id, exc)\n",
    "            continue\n",
    "\n",
    "        output_path = output_dir / f\"{image_id}.png\"\n",
    "        save_detection_visual(\n",
    "            image_np,\n",
    "            detail.get(\"prediction\", {}),\n",
    "            detail.get(\"target\", {}),\n",
    "            dataset_cfg.class_names,\n",
    "            train_cfg.score_threshold,\n",
    "            train_cfg.class_score_thresholds,\n",
    "            True,\n",
    "            output_path,\n",
    "        )\n",
    "        fp_records.append({\"image_id\": image_id, \"false_positives\": filtered})\n",
    "\n",
    "    return fp_records\n",
    "\n",
    "\n",
    "def run_training(args: argparse.Namespace) -> None:\n",
    "    dataset_cfg, train_cfg = prepare_configs(args)\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "    set_seed(train_cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "\n",
    "    train_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.train_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        transform=AugmentationParams(\n",
    "            mosaic_prob=train_cfg.mosaic_prob,\n",
    "            mixup_prob=train_cfg.mixup_prob,\n",
    "            mixup_alpha=train_cfg.mixup_alpha,\n",
    "            scale_jitter_range=(train_cfg.scale_jitter_min, train_cfg.scale_jitter_max),\n",
    "            rotation_prob=train_cfg.rotation_prob,\n",
    "            rotation_max_degrees=train_cfg.rotation_max_degrees,\n",
    "            affine_prob=train_cfg.affine_prob,\n",
    "            affine_translate=train_cfg.affine_translate,\n",
    "            affine_scale_range=train_cfg.affine_scale_range,\n",
    "            affine_shear=train_cfg.affine_shear,\n",
    "        ),\n",
    "        use_augmentation=train_cfg.augmentation,\n",
    "        exclude_stems=train_cfg.exclude_samples,\n",
    "    )\n",
    "    valid_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.valid_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "\n",
    "    if train_cfg.exclude_samples:\n",
    "        sample_preview = \", \".join(train_cfg.exclude_samples[:5])\n",
    "        if len(train_cfg.exclude_samples) > 5:\n",
    "            sample_preview += \", ...\"\n",
    "        LOGGER.info(\n",
    "            \"Excluding %d training samples: %s\",\n",
    "            len(train_cfg.exclude_samples),\n",
    "            sample_preview,\n",
    "        )\n",
    "\n",
    "    train_loader = create_data_loaders(\n",
    "        train_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "    )\n",
    "    if train_cfg.num_workers > 1:\n",
    "        valid_workers = max(1, train_cfg.num_workers // 2)\n",
    "    else:\n",
    "        valid_workers = train_cfg.num_workers\n",
    "\n",
    "    valid_loader = create_data_loaders(\n",
    "        valid_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=valid_workers,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=train_cfg.learning_rate, weight_decay=train_cfg.weight_decay)\n",
    "    scaler = _create_grad_scaler(train_cfg.amp, device)\n",
    "\n",
    "    start_epoch = 1\n",
    "    best_map = -float(\"inf\")\n",
    "    history: List[Dict[str, float]] = []\n",
    "\n",
    "    if train_cfg.resume or train_cfg.resume_path is not None:\n",
    "        resume_source = train_cfg.resume_path or train_cfg.last_checkpoint_path\n",
    "        start_epoch, best_map, history = load_checkpoint(\n",
    "            path=resume_source,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            device=device,\n",
    "        )\n",
    "        if start_epoch > train_cfg.epochs:\n",
    "            LOGGER.info(\n",
    "                \"Checkpoint %s already reached epoch %d; target epochs=%d. Nothing left to train. \"\n",
    "                \"Increase --epochs if you want to continue.\",\n",
    "                resume_source,\n",
    "                start_epoch - 1,\n",
    "                train_cfg.epochs,\n",
    "            )\n",
    "            return\n",
    "\n",
    "    for epoch in range(start_epoch, train_cfg.epochs + 1):\n",
    "        LOGGER.info(\"Epoch %s/%s\", epoch, train_cfg.epochs)\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, scaler, device, train_cfg.amp, train_cfg.log_every\n",
    "        )\n",
    "\n",
    "        should_evaluate = (epoch % train_cfg.eval_interval == 0) or (epoch == train_cfg.epochs)\n",
    "        collect_fp = should_evaluate and epoch == train_cfg.epochs\n",
    "\n",
    "        if should_evaluate:\n",
    "            metrics, sample_details = evaluate(\n",
    "                model,\n",
    "                valid_loader,\n",
    "                device,\n",
    "                dataset_cfg,\n",
    "                train_cfg,\n",
    "                dataset=valid_dataset,\n",
    "                collect_details=collect_fp,\n",
    "            )\n",
    "            metric_lines = format_epoch_metrics(epoch, train_loss, metrics, dataset_cfg)\n",
    "            emit_metric_lines(metric_lines, logger=LOGGER)\n",
    "\n",
    "            history.append(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": float(train_loss),\n",
    "                    \"val_loss\": float(metrics[\"loss\"]),\n",
    "                    \"mAP\": float(metrics[\"mAP\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if metrics[\"mAP\"] > best_map:\n",
    "                best_map = float(metrics[\"mAP\"])\n",
    "                save_checkpoint(\n",
    "                    path=train_cfg.checkpoint_path,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scaler=scaler,\n",
    "                    epoch=epoch,\n",
    "                    best_map=best_map,\n",
    "                    history=history,\n",
    "                    train_cfg=train_cfg,\n",
    "                )\n",
    "\n",
    "            if collect_fp:\n",
    "                fp_records = export_false_positive_visuals(\n",
    "                    dataset=valid_dataset,\n",
    "                    dataset_cfg=dataset_cfg,\n",
    "                    train_cfg=train_cfg,\n",
    "                    sample_details=sample_details,\n",
    "                )\n",
    "                if train_cfg.fp_report_path:\n",
    "                    write_false_positive_report(\n",
    "                        fp_records,\n",
    "                        train_cfg.fp_report_path,\n",
    "                        split=dataset_cfg.valid_split,\n",
    "                        score_threshold=train_cfg.score_threshold,\n",
    "                        class_score_thresholds=train_cfg.class_score_thresholds,\n",
    "                        iou_threshold=train_cfg.iou_threshold,\n",
    "                    )\n",
    "                    LOGGER.info(\n",
    "                        \"Saved false-positive report for %d images to %s\",\n",
    "                        len(fp_records),\n",
    "                        train_cfg.fp_report_path,\n",
    "                    )\n",
    "                if train_cfg.fp_list_path:\n",
    "                    write_false_positive_list(fp_records, train_cfg.fp_list_path)\n",
    "                    LOGGER.info(\n",
    "                        \"Saved list of %d false-positive image ids to %s\",\n",
    "                        len({str(record[\"image_id\"]) for record in fp_records}),\n",
    "                        train_cfg.fp_list_path,\n",
    "                    )\n",
    "        else:\n",
    "            LOGGER.info(\n",
    "                \"Epoch %02d | train loss %.4f | evaluation skipped (eval_interval=%d)\",\n",
    "                epoch,\n",
    "                train_loss,\n",
    "                train_cfg.eval_interval,\n",
    "            )\n",
    "\n",
    "        save_checkpoint(\n",
    "            path=train_cfg.last_checkpoint_path,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            epoch=epoch,\n",
    "            best_map=best_map,\n",
    "            history=history,\n",
    "            train_cfg=train_cfg,\n",
    "        )\n",
    "\n",
    "    (train_cfg.output_dir / \"training_history.json\").write_text(json.dumps(history, indent=2))\n",
    "    LOGGER.info(\"Training complete. Best mAP: %.4f\", best_map)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = parse_args()\n",
    "    run_training(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6760e",
   "metadata": {
    "papermill": {
     "duration": 0.003126,
     "end_time": "2025-10-21T07:01:27.448074",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.444948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f63ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.455528Z",
     "iopub.status.busy": "2025-10-21T07:01:27.455315Z",
     "iopub.status.idle": "2025-10-21T07:01:27.470282Z",
     "shell.execute_reply": "2025-10-21T07:01:27.469714Z"
    },
    "papermill": {
     "duration": 0.020147,
     "end_time": "2025-10-21T07:01:27.471429",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.451282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Inference utilities for evaluating trained models on the test split.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import pickle\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from torch.serialization import add_safe_globals\n",
    "except ImportError:  # pragma: no cover - compatibility for older PyTorch\n",
    "    add_safe_globals = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(\"inference\")\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--data-dir\", type=Path, default=DatasetConfig().base_dir)\n",
    "    parser.add_argument(\"--split\", default=DatasetConfig().test_split)\n",
    "    parser.add_argument(\"--checkpoint\", type=Path, required=True)\n",
    "    parser.add_argument(\"--output-dir\", type=Path, default=InferenceConfig().output_dir)\n",
    "    parser.add_argument(\"--score-threshold\", type=float, default=InferenceConfig().score_threshold)\n",
    "    parser.add_argument(\n",
    "        \"--class-threshold\",\n",
    "        action=\"append\",\n",
    "        default=[],\n",
    "        metavar=\"CLS=THRESH\",\n",
    "        help=\"Override per-class score thresholds for inference\",\n",
    "    )\n",
    "    parser.add_argument(\"--iou-threshold\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--max-images\", type=int, default=InferenceConfig().max_images)\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=DatasetConfig().num_classes)\n",
    "    parser.add_argument(\"--draw-ground-truth\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=2024)\n",
    "    parser.add_argument(\"--pretrained-path\", type=Path, default=TrainingConfig().pretrained_weights_path)\n",
    "    parser.add_argument(\n",
    "        \"--fp-report\",\n",
    "        type=Path,\n",
    "        help=\"Optional path to write a JSON report of images containing false positives.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fp-list\",\n",
    "        type=Path,\n",
    "        help=\"Optional path to write newline separated image stems that produced false positives.\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def _load_checkpoint_state(path: Path, device: torch.device) -> Dict[str, torch.Tensor]:\n",
    "    load_kwargs = {\"map_location\": device}\n",
    "    try:\n",
    "        checkpoint_obj = torch.load(path, **load_kwargs)\n",
    "    except pickle.UnpicklingError:\n",
    "        if add_safe_globals is not None:\n",
    "            add_safe_globals([TrainingConfig])\n",
    "        load_params = inspect.signature(torch.load).parameters\n",
    "        if \"weights_only\" in load_params:\n",
    "            load_kwargs[\"weights_only\"] = False\n",
    "        checkpoint_obj = torch.load(path, **load_kwargs)\n",
    "\n",
    "    if isinstance(checkpoint_obj, dict) and \"model\" in checkpoint_obj:\n",
    "        return checkpoint_obj[\"model\"]\n",
    "\n",
    "    return checkpoint_obj\n",
    "@torch.no_grad()\n",
    "def run_inference(args: argparse.Namespace) -> None:\n",
    "    dataset_cfg = DatasetConfig(\n",
    "        base_dir=args.data_dir,\n",
    "        test_split=args.split,\n",
    "        num_classes=args.num_classes,\n",
    "    )\n",
    "    class_thresholds = DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    overrides = parse_class_threshold_entries(args.class_threshold)\n",
    "    class_thresholds.update(overrides)\n",
    "\n",
    "    inference_cfg = InferenceConfig(\n",
    "        score_threshold=args.score_threshold,\n",
    "        max_images=args.max_images,\n",
    "        output_dir=args.output_dir,\n",
    "        draw_ground_truth=args.draw_ground_truth,\n",
    "        class_score_thresholds=class_thresholds,\n",
    "    )\n",
    "    inference_cfg.ensure_directories()\n",
    "\n",
    "    train_cfg = TrainingConfig(\n",
    "        augmentation=False,\n",
    "        score_threshold=args.score_threshold,\n",
    "        iou_threshold=args.iou_threshold,\n",
    "        pretrained_weights_path=args.pretrained_path,\n",
    "        class_score_thresholds=class_thresholds,\n",
    "    )\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "    state_dict = _load_checkpoint_state(args.checkpoint, device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=args.split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "    loader = create_data_loaders(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    predictions: List[Dict[str, np.ndarray]] = []\n",
    "    targets_for_eval: List[Dict[str, np.ndarray]] = []\n",
    "\n",
    "    progress = tqdm(loader, desc=\"Infer\")\n",
    "    fp_records: List[Dict[str, object]] = []\n",
    "    for idx, (images, targets) in enumerate(progress):\n",
    "        image = images[0].to(device)\n",
    "        output = model([image])[0]\n",
    "\n",
    "        boxes_np = output[\"boxes\"].detach().cpu().numpy()\n",
    "        scores_np = output[\"scores\"].detach().cpu().numpy()\n",
    "        labels_np = output[\"labels\"].detach().cpu().numpy().astype(np.int64, copy=False)\n",
    "        keep = score_threshold_mask(\n",
    "            scores_np,\n",
    "            labels_np,\n",
    "            inference_cfg.score_threshold,\n",
    "            inference_cfg.class_score_thresholds,\n",
    "        )\n",
    "        boxes_np = boxes_np[keep]\n",
    "        scores_np = scores_np[keep]\n",
    "        labels_np = labels_np[keep].astype(np.int64, copy=True)\n",
    "        if labels_np.size:\n",
    "            labels_np -= 1\n",
    "\n",
    "        target_boxes = targets[0][\"boxes\"].detach().cpu().numpy()\n",
    "        target_labels = targets[0][\"labels\"].detach().cpu().numpy().astype(np.int64, copy=True)\n",
    "        if target_labels.size:\n",
    "            gt_keep = target_labels > 0\n",
    "            target_boxes = target_boxes[gt_keep]\n",
    "            target_labels = target_labels[gt_keep] - 1\n",
    "\n",
    "        prediction_np = {\n",
    "            \"boxes\": boxes_np,\n",
    "            \"scores\": scores_np,\n",
    "            \"labels\": labels_np,\n",
    "        }\n",
    "        target_np = {\n",
    "            \"boxes\": target_boxes,\n",
    "            \"labels\": target_labels,\n",
    "        }\n",
    "\n",
    "        predictions.append(prediction_np)\n",
    "        targets_for_eval.append(target_np)\n",
    "\n",
    "        fp_details = identify_false_positive_predictions(\n",
    "            prediction_np,\n",
    "            target_np,\n",
    "            dataset_cfg.num_classes,\n",
    "            args.iou_threshold,\n",
    "        )\n",
    "        if fp_details:\n",
    "            image_id = dataset.image_stems[idx] if idx < len(dataset.image_stems) else f\"{args.split}_{idx:04d}\"\n",
    "            fp_records.append(\n",
    "                {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"false_positives\": fp_details,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if idx < inference_cfg.max_images:\n",
    "            image_np = (images[0].permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "            output_path = inference_cfg.output_dir / f\"{args.split}_{idx:04d}.png\"\n",
    "            save_detection_visual(\n",
    "                image_np,\n",
    "                prediction_np,\n",
    "                target_np if args.draw_ground_truth else None,\n",
    "                dataset_cfg.class_names,\n",
    "                inference_cfg.score_threshold,\n",
    "                inference_cfg.class_score_thresholds,\n",
    "                args.draw_ground_truth,\n",
    "                output_path,\n",
    "            )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, args.iou_threshold\n",
    "    )\n",
    "    metric_lines = format_epoch_metrics(\n",
    "        epoch=None,\n",
    "        train_loss=None,\n",
    "        metrics=metrics,\n",
    "        dataset_cfg=dataset_cfg,\n",
    "        header=f\"Inference @ IoU {args.iou_threshold:.2f}\",\n",
    "    )\n",
    "    emit_metric_lines(metric_lines, logger=LOGGER)\n",
    "\n",
    "    if args.fp_report:\n",
    "        write_false_positive_report(\n",
    "            fp_records,\n",
    "            args.fp_report,\n",
    "            split=args.split,\n",
    "            score_threshold=inference_cfg.score_threshold,\n",
    "            class_score_thresholds=inference_cfg.class_score_thresholds,\n",
    "            iou_threshold=args.iou_threshold,\n",
    "        )\n",
    "        LOGGER.info(\n",
    "            \"Wrote false-positive report for %d images to %s\",\n",
    "            len(fp_records),\n",
    "            args.fp_report,\n",
    "        )\n",
    "\n",
    "    if args.fp_list:\n",
    "        write_false_positive_list(fp_records, args.fp_list)\n",
    "        LOGGER.info(\n",
    "            \"Wrote %d image ids with false positives to %s\",\n",
    "            len({str(record[\"image_id\"]) for record in fp_records}),\n",
    "            args.fp_list,\n",
    "        )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = parse_args()\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "    run_inference(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7eab67",
   "metadata": {
    "papermill": {
     "duration": 0.003132,
     "end_time": "2025-10-21T07:01:27.477944",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.474812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed17aed",
   "metadata": {
    "papermill": {
     "duration": 0.002928,
     "end_time": "2025-10-21T07:01:27.483932",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.481004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. \u4f9d\u6b21\u8fd0\u884c\u4e0a\u9762\u7684\u4ee3\u7801\u5355\u5143\uff0c\u786e\u4fdd\u6570\u636e\u96c6\u914d\u7f6e\u3001\u6570\u636e\u52a0\u8f7d\u3001\u8bad\u7ec3\u4e0e\u63a8\u7406\u51fd\u6570\u5747\u5df2\u6ce8\u518c\u5230\u5f53\u524d\u4f1a\u8bdd\u3002\n",
    "2. \u5728\u793a\u4f8b\u4ee3\u7801\u5355\u5143\u4e2d\u6309\u9700\u8c03\u6574 `train_args` / `inference_args`\uff08\u5c24\u5176\u662f\u6570\u636e\u8def\u5f84\u3001\u6279\u5927\u5c0f\u3001\u662f\u5426\u6062\u590d\u8bad\u7ec3\u7b49\uff09\uff0c\u7136\u540e\u8c03\u7528 `run_training(train_args)` \u6216 `run_inference(inference_args)`\u3002\n",
    "3. \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u628a\u6700\u4f73\u6743\u91cd\u5199\u5165 `outputs/best_model.pth`\uff0c\u6bcf\u4e2a epoch \u7684\u65ad\u70b9\u5199\u5165 `outputs/last_checkpoint.pth`\uff1b\u63a8\u7406\u4f1a\u5c06\u53ef\u89c6\u5316\u7ed3\u679c\u8f93\u51fa\u5230 `InferenceConfig.output_dir`\u3002\n",
    "---\n",
    "Tuning History\n",
    "1. \u6539\u5c0flr\n",
    "2. \u6539\u5c0f0\u300116\u300125\u300130\u9608\u503c\n",
    "3. \u8c03\u6574\u7a97\u53e3\u6bd4\u4f8b((0.2, 0.5, 1.0, 2.0, 5.0),) * len(anchor_sizes)\n",
    "4. \u589e\u52a0epoch\u6b21\u6570\n",
    "5. \u6539\u592716\u9608\u503c\uff0c\u6539\u5c0f25\u300130\u9608\u503c\n",
    "6. shuffle dataset\n",
    "7. \u6539\u5927 25\u300130\u9608\u503c\n",
    "8. \u8c03\u6574RPN\u6bd4\u4f8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8be183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.491038Z",
     "iopub.status.busy": "2025-10-21T07:01:27.490804Z",
     "iopub.status.idle": "2025-10-21T09:11:21.526186Z",
     "shell.execute_reply": "2025-10-21T09:11:21.525244Z"
    },
    "papermill": {
     "duration": 7794.040395,
     "end_time": "2025-10-21T09:11:21.527487",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.487092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 167M/167M [00:00<00:00, 200MB/s]\n",
      "/tmp/ipykernel_19/3144854163.py:236: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=train_cfg.amp and device.type == \"cuda\")\n",
      "/tmp/ipykernel_19/87368670.py:110: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.7170 | val loss 0.7185 | mAP 0.1218\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.000 R=0.000  TP=0 FP=0 FN=35 AP=0.000\n",
      "class 02 | P=0.000 R=0.000  TP=0 FP=0 FN=35 AP=0.000\n",
      "class 04 | P=0.000 R=0.000  TP=0 FP=0 FN=27 AP=0.000\n",
      "class 05 | P=0.000 R=0.000  TP=0 FP=0 FN=75 AP=0.000\n",
      "class 06 | P=0.000 R=0.000  TP=0 FP=0 FN=5 AP=0.000\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=0 FN=72 AP=0.000\n",
      "class 09 | P=1.000 R=0.355  TP=11 FP=0 FN=20 AP=0.677\n",
      "class 10 | P=0.000 R=0.000  TP=0 FP=0 FN=45 AP=0.000\n",
      "class 11 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 13 | P=0.000 R=0.000  TP=0 FP=0 FN=85 AP=0.000\n",
      "class 14 | P=0.000 R=0.000  TP=0 FP=0 FN=93 AP=0.000\n",
      "class 15 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 16 | P=0.000 R=0.000  TP=0 FP=0 FN=6 AP=0.000\n",
      "class 18 | P=0.000 R=0.000  TP=0 FP=0 FN=37 AP=0.000\n",
      "class 19 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 20 | P=0.727 R=0.533  TP=8 FP=3 FN=7 AP=0.664\n",
      "class 21 | P=0.000 R=0.000  TP=0 FP=0 FN=7 AP=0.000\n",
      "class 22 | P=1.000 R=0.500  TP=1 FP=0 FN=1 AP=0.750\n",
      "class 23 | P=1.000 R=0.104  TP=5 FP=0 FN=43 AP=0.552\n",
      "class 25 | P=0.000 R=0.000  TP=0 FP=0 FN=3 AP=0.000\n",
      "class 27 | P=0.000 R=0.000  TP=0 FP=0 FN=45 AP=0.000\n",
      "class 28 | P=0.000 R=0.000  TP=0 FP=0 FN=50 AP=0.000\n",
      "class 29 | P=1.000 R=0.045  TP=2 FP=0 FN=42 AP=0.523\n",
      "class 30 | P=0.000 R=0.000  TP=0 FP=0 FN=4 AP=0.000\n",
      "class 31 | P=0.000 R=0.000  TP=0 FP=0 FN=79 AP=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train loss 0.4304 | val loss 0.4355 | mAP 0.5096\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.810 R=0.486  TP=17 FP=4 FN=18 AP=0.684\n",
      "class 02 | P=0.870 R=0.571  TP=20 FP=3 FN=15 AP=0.754\n",
      "class 04 | P=0.826 R=0.704  TP=19 FP=4 FN=8 AP=0.786\n",
      "class 05 | P=0.000 R=0.000  TP=0 FP=0 FN=75 AP=0.000\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=0 FN=72 AP=0.000\n",
      "class 09 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.929\n",
      "class 10 | P=0.515 R=0.756  TP=34 FP=32 FN=11 AP=0.753\n",
      "class 11 | P=0.833 R=0.806  TP=25 FP=5 FN=6 AP=0.887\n",
      "class 13 | P=0.000 R=0.000  TP=0 FP=0 FN=85 AP=0.000\n",
      "class 14 | P=0.000 R=0.000  TP=0 FP=0 FN=93 AP=0.000\n",
      "class 15 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 16 | P=0.400 R=0.333  TP=2 FP=3 FN=4 AP=0.300\n",
      "class 18 | P=0.000 R=0.000  TP=0 FP=0 FN=37 AP=0.000\n",
      "class 19 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 20 | P=0.733 R=0.733  TP=11 FP=4 FN=4 AP=0.762\n",
      "class 21 | P=1.000 R=0.143  TP=1 FP=0 FN=6 AP=0.571\n",
      "class 22 | P=0.143 R=1.000  TP=2 FP=12 FN=0 AP=0.995\n",
      "class 23 | P=0.922 R=0.979  TP=47 FP=4 FN=1 AP=0.986\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.931 R=0.600  TP=27 FP=2 FN=18 AP=0.785\n",
      "class 28 | P=0.744 R=0.640  TP=32 FP=11 FN=18 AP=0.725\n",
      "class 29 | P=0.761 R=0.795  TP=35 FP=11 FN=9 AP=0.847\n",
      "class 30 | P=0.333 R=0.250  TP=1 FP=2 FN=3 AP=0.208\n",
      "class 31 | P=0.667 R=0.127  TP=10 FP=5 FN=69 AP=0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train loss 0.2919 | val loss 0.3532 | mAP 0.6792\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.718 R=0.800  TP=28 FP=11 FN=7 AP=0.832\n",
      "class 02 | P=0.789 R=0.857  TP=30 FP=8 FN=5 AP=0.892\n",
      "class 04 | P=0.852 R=0.852  TP=23 FP=4 FN=4 AP=0.906\n",
      "class 05 | P=0.893 R=0.667  TP=50 FP=6 FN=25 AP=0.806\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=1 FN=72 AP=0.000\n",
      "class 09 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.950\n",
      "class 10 | P=0.704 R=0.844  TP=38 FP=16 FN=7 AP=0.880\n",
      "class 11 | P=0.722 R=0.839  TP=26 FP=10 FN=5 AP=0.887\n",
      "class 13 | P=1.000 R=0.024  TP=2 FP=0 FN=83 AP=0.512\n",
      "class 14 | P=0.912 R=0.333  TP=31 FP=3 FN=62 AP=0.626\n",
      "class 15 | P=0.950 R=0.613  TP=19 FP=1 FN=12 AP=0.781\n",
      "class 16 | P=0.286 R=0.333  TP=2 FP=5 FN=4 AP=0.206\n",
      "class 18 | P=1.000 R=0.081  TP=3 FP=0 FN=34 AP=0.541\n",
      "class 19 | P=1.000 R=0.097  TP=3 FP=0 FN=28 AP=0.548\n",
      "class 20 | P=0.786 R=0.733  TP=11 FP=3 FN=4 AP=0.808\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.828\n",
      "class 23 | P=0.870 R=0.979  TP=47 FP=7 FN=1 AP=0.987\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.913\n",
      "class 27 | P=0.971 R=0.756  TP=34 FP=1 FN=11 AP=0.873\n",
      "class 28 | P=0.795 R=0.700  TP=35 FP=9 FN=15 AP=0.782\n",
      "class 29 | P=0.786 R=0.750  TP=33 FP=9 FN=11 AP=0.823\n",
      "class 30 | P=0.091 R=0.250  TP=1 FP=10 FN=3 AP=0.059\n",
      "class 31 | P=0.621 R=0.747  TP=59 FP=36 FN=20 AP=0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train loss 0.2484 | val loss 0.3071 | mAP 0.7506\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.800 R=0.800  TP=28 FP=7 FN=7 AP=0.864\n",
      "class 02 | P=0.800 R=0.914  TP=32 FP=8 FN=3 AP=0.933\n",
      "class 04 | P=0.862 R=0.926  TP=25 FP=4 FN=2 AP=0.950\n",
      "class 05 | P=0.932 R=0.733  TP=55 FP=4 FN=20 AP=0.854\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.706 R=0.167  TP=12 FP=5 FN=60 AP=0.412\n",
      "class 09 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.948\n",
      "class 10 | P=0.709 R=0.867  TP=39 FP=16 FN=6 AP=0.882\n",
      "class 11 | P=0.634 R=0.839  TP=26 FP=15 FN=5 AP=0.867\n",
      "class 13 | P=1.000 R=0.059  TP=5 FP=0 FN=80 AP=0.529\n",
      "class 14 | P=0.750 R=0.839  TP=78 FP=26 FN=15 AP=0.865\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.888\n",
      "class 16 | P=0.600 R=0.500  TP=3 FP=2 FN=3 AP=0.566\n",
      "class 18 | P=1.000 R=0.568  TP=21 FP=0 FN=16 AP=0.784\n",
      "class 19 | P=0.917 R=0.710  TP=22 FP=2 FN=9 AP=0.837\n",
      "class 20 | P=0.750 R=0.800  TP=12 FP=4 FN=3 AP=0.766\n",
      "class 21 | P=0.286 R=0.286  TP=2 FP=5 FN=5 AP=0.292\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.828\n",
      "class 23 | P=1.000 R=0.979  TP=47 FP=0 FN=1 AP=0.989\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.894 R=0.933  TP=42 FP=5 FN=3 AP=0.958\n",
      "class 28 | P=0.731 R=0.760  TP=38 FP=14 FN=12 AP=0.809\n",
      "class 29 | P=0.822 R=0.841  TP=37 FP=8 FN=7 AP=0.887\n",
      "class 30 | P=0.250 R=0.500  TP=2 FP=6 FN=2 AP=0.188\n",
      "class 31 | P=0.566 R=0.810  TP=64 FP=49 FN=15 AP=0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train loss 0.2702 | val loss 0.2924 | mAP 0.8014\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.744 R=0.829  TP=29 FP=10 FN=6 AP=0.884\n",
      "class 02 | P=0.756 R=0.971  TP=34 FP=11 FN=1 AP=0.971\n",
      "class 04 | P=0.897 R=0.963  TP=26 FP=3 FN=1 AP=0.973\n",
      "class 05 | P=0.901 R=0.853  TP=64 FP=7 FN=11 AP=0.901\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.962\n",
      "class 07 | P=0.800 R=0.333  TP=24 FP=6 FN=48 AP=0.533\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.981\n",
      "class 10 | P=0.615 R=0.889  TP=40 FP=25 FN=5 AP=0.861\n",
      "class 11 | P=0.758 R=0.806  TP=25 FP=8 FN=6 AP=0.873\n",
      "class 13 | P=0.848 R=0.459  TP=39 FP=7 FN=46 AP=0.653\n",
      "class 14 | P=0.849 R=0.849  TP=79 FP=14 FN=14 AP=0.882\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.905\n",
      "class 16 | P=0.750 R=0.500  TP=3 FP=1 FN=3 AP=0.686\n",
      "class 18 | P=1.000 R=0.676  TP=25 FP=0 FN=12 AP=0.838\n",
      "class 19 | P=0.926 R=0.806  TP=25 FP=2 FN=6 AP=0.886\n",
      "class 20 | P=0.706 R=0.800  TP=12 FP=5 FN=3 AP=0.762\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=0.960 R=1.000  TP=48 FP=2 FN=0 AP=0.995\n",
      "class 25 | P=0.500 R=1.000  TP=3 FP=3 FN=0 AP=0.913\n",
      "class 27 | P=0.894 R=0.933  TP=42 FP=5 FN=3 AP=0.958\n",
      "class 28 | P=0.643 R=0.900  TP=45 FP=25 FN=5 AP=0.906\n",
      "class 29 | P=0.870 R=0.909  TP=40 FP=6 FN=4 AP=0.939\n",
      "class 30 | P=0.143 R=0.250  TP=1 FP=6 FN=3 AP=0.177\n",
      "class 31 | P=0.624 R=0.861  TP=68 FP=41 FN=11 AP=0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train loss 0.2430 | val loss 0.2736 | mAP 0.8187\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.848 R=0.800  TP=28 FP=5 FN=7 AP=0.882\n",
      "class 02 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.940\n",
      "class 04 | P=0.867 R=0.963  TP=26 FP=4 FN=1 AP=0.979\n",
      "class 05 | P=0.915 R=0.867  TP=65 FP=6 FN=10 AP=0.912\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.778 R=0.194  TP=14 FP=4 FN=58 AP=0.491\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.625 R=0.889  TP=40 FP=24 FN=5 AP=0.897\n",
      "class 11 | P=0.676 R=0.806  TP=25 FP=12 FN=6 AP=0.861\n",
      "class 13 | P=0.839 R=0.612  TP=52 FP=10 FN=33 AP=0.719\n",
      "class 14 | P=0.764 R=0.871  TP=81 FP=25 FN=12 AP=0.912\n",
      "class 15 | P=0.900 R=0.871  TP=27 FP=3 FN=4 AP=0.929\n",
      "class 16 | P=0.500 R=0.500  TP=3 FP=3 FN=3 AP=0.540\n",
      "class 18 | P=0.967 R=0.784  TP=29 FP=1 FN=8 AP=0.883\n",
      "class 19 | P=1.000 R=0.871  TP=27 FP=0 FN=4 AP=0.935\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.846\n",
      "class 21 | P=0.800 R=0.571  TP=4 FP=1 FN=3 AP=0.714\n",
      "class 22 | P=0.222 R=1.000  TP=2 FP=7 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.994\n",
      "class 28 | P=0.726 R=0.900  TP=45 FP=17 FN=5 AP=0.916\n",
      "class 29 | P=0.878 R=0.977  TP=43 FP=6 FN=1 AP=0.979\n",
      "class 30 | P=0.143 R=0.250  TP=1 FP=6 FN=3 AP=0.177\n",
      "class 31 | P=0.722 R=0.823  TP=65 FP=25 FN=14 AP=0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train loss 0.2182 | val loss 0.2625 | mAP 0.8238\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.844 R=0.771  TP=27 FP=5 FN=8 AP=0.864\n",
      "class 02 | P=0.744 R=0.914  TP=32 FP=11 FN=3 AP=0.939\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.929 R=0.867  TP=65 FP=5 FN=10 AP=0.915\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.694 R=0.347  TP=25 FP=11 FN=47 AP=0.501\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.714 R=0.889  TP=40 FP=16 FN=5 AP=0.916\n",
      "class 11 | P=0.781 R=0.806  TP=25 FP=7 FN=6 AP=0.877\n",
      "class 13 | P=0.742 R=0.776  TP=66 FP=23 FN=19 AP=0.763\n",
      "class 14 | P=0.872 R=0.882  TP=82 FP=12 FN=11 AP=0.912\n",
      "class 15 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.946\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.721\n",
      "class 18 | P=0.966 R=0.757  TP=28 FP=1 FN=9 AP=0.868\n",
      "class 19 | P=1.000 R=0.903  TP=28 FP=0 FN=3 AP=0.951\n",
      "class 20 | P=0.706 R=0.800  TP=12 FP=5 FN=3 AP=0.815\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.535\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.984\n",
      "class 28 | P=0.815 R=0.880  TP=44 FP=10 FN=6 AP=0.919\n",
      "class 29 | P=0.811 R=0.977  TP=43 FP=10 FN=1 AP=0.968\n",
      "class 30 | P=0.222 R=0.500  TP=2 FP=7 FN=2 AP=0.242\n",
      "class 31 | P=0.680 R=0.861  TP=68 FP=32 FN=11 AP=0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train loss 0.2244 | val loss 0.2720 | mAP 0.8203\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.816 R=0.886  TP=31 FP=7 FN=4 AP=0.922\n",
      "class 02 | P=0.780 R=0.914  TP=32 FP=9 FN=3 AP=0.937\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.928 R=0.853  TP=64 FP=5 FN=11 AP=0.898\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.794 R=0.375  TP=27 FP=7 FN=45 AP=0.569\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.700 R=0.933  TP=42 FP=18 FN=3 AP=0.932\n",
      "class 11 | P=0.743 R=0.839  TP=26 FP=9 FN=5 AP=0.897\n",
      "class 13 | P=0.780 R=0.753  TP=64 FP=18 FN=21 AP=0.784\n",
      "class 14 | P=0.889 R=0.860  TP=80 FP=10 FN=13 AP=0.893\n",
      "class 15 | P=1.000 R=0.806  TP=25 FP=0 FN=6 AP=0.903\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.743\n",
      "class 18 | P=0.969 R=0.838  TP=31 FP=1 FN=6 AP=0.910\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.918\n",
      "class 20 | P=0.750 R=0.800  TP=12 FP=4 FN=3 AP=0.859\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.167 R=1.000  TP=2 FP=10 FN=0 AP=0.745\n",
      "class 23 | P=0.904 R=0.979  TP=47 FP=5 FN=1 AP=0.988\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.987\n",
      "class 28 | P=0.860 R=0.860  TP=43 FP=7 FN=7 AP=0.913\n",
      "class 29 | P=0.792 R=0.955  TP=42 FP=11 FN=2 AP=0.954\n",
      "class 30 | P=0.286 R=0.500  TP=2 FP=5 FN=2 AP=0.214\n",
      "class 31 | P=0.776 R=0.835  TP=66 FP=19 FN=13 AP=0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train loss 0.2363 | val loss 0.2696 | mAP 0.8331\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.744 R=0.914  TP=32 FP=11 FN=3 AP=0.927\n",
      "class 02 | P=0.762 R=0.914  TP=32 FP=10 FN=3 AP=0.943\n",
      "class 04 | P=0.867 R=0.963  TP=26 FP=4 FN=1 AP=0.979\n",
      "class 05 | P=0.903 R=0.867  TP=65 FP=7 FN=10 AP=0.901\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.815 R=0.611  TP=44 FP=10 FN=28 AP=0.681\n",
      "class 09 | P=0.968 R=0.968  TP=30 FP=1 FN=1 AP=0.983\n",
      "class 10 | P=0.782 R=0.956  TP=43 FP=12 FN=2 AP=0.949\n",
      "class 11 | P=0.812 R=0.839  TP=26 FP=6 FN=5 AP=0.899\n",
      "class 13 | P=0.789 R=0.835  TP=71 FP=19 FN=14 AP=0.837\n",
      "class 14 | P=0.889 R=0.860  TP=80 FP=10 FN=13 AP=0.902\n",
      "class 15 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.964\n",
      "class 16 | P=0.600 R=0.500  TP=3 FP=2 FN=3 AP=0.608\n",
      "class 18 | P=0.958 R=0.622  TP=23 FP=1 FN=14 AP=0.781\n",
      "class 19 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.966\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.893\n",
      "class 21 | P=0.500 R=0.571  TP=4 FP=4 FN=3 AP=0.622\n",
      "class 22 | P=0.143 R=1.000  TP=2 FP=12 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.865 R=1.000  TP=45 FP=7 FN=0 AP=0.985\n",
      "class 28 | P=0.846 R=0.880  TP=44 FP=8 FN=6 AP=0.920\n",
      "class 29 | P=0.788 R=0.932  TP=41 FP=11 FN=3 AP=0.926\n",
      "class 30 | P=0.250 R=0.500  TP=2 FP=6 FN=2 AP=0.188\n",
      "class 31 | P=0.725 R=0.835  TP=66 FP=25 FN=13 AP=0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss 0.1676 | val loss 0.2566 | mAP 0.8374\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.861 R=0.886  TP=31 FP=5 FN=4 AP=0.928\n",
      "class 02 | P=0.838 R=0.886  TP=31 FP=6 FN=4 AP=0.926\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.868 R=0.880  TP=66 FP=10 FN=9 AP=0.906\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.788 R=0.569  TP=41 FP=11 FN=31 AP=0.619\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.638 R=0.978  TP=44 FP=25 FN=1 AP=0.944\n",
      "class 11 | P=0.788 R=0.839  TP=26 FP=7 FN=5 AP=0.894\n",
      "class 13 | P=0.734 R=0.812  TP=69 FP=25 FN=16 AP=0.778\n",
      "class 14 | P=0.884 R=0.903  TP=84 FP=11 FN=9 AP=0.917\n",
      "class 15 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 16 | P=0.400 R=0.667  TP=4 FP=6 FN=2 AP=0.566\n",
      "class 18 | P=0.971 R=0.919  TP=34 FP=1 FN=3 AP=0.953\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.960\n",
      "class 20 | P=0.722 R=0.867  TP=13 FP=5 FN=2 AP=0.863\n",
      "class 21 | P=0.800 R=0.571  TP=4 FP=1 FN=3 AP=0.714\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.849 R=1.000  TP=45 FP=8 FN=0 AP=0.989\n",
      "class 28 | P=0.880 R=0.880  TP=44 FP=6 FN=6 AP=0.924\n",
      "class 29 | P=0.804 R=0.932  TP=41 FP=10 FN=3 AP=0.946\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.262\n",
      "class 31 | P=0.708 R=0.797  TP=63 FP=26 FN=16 AP=0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss 0.1759 | val loss 0.2565 | mAP 0.8454\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.806 R=0.829  TP=29 FP=7 FN=6 AP=0.894\n",
      "class 02 | P=0.842 R=0.914  TP=32 FP=6 FN=3 AP=0.945\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.892 R=0.880  TP=66 FP=8 FN=9 AP=0.908\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.855 R=0.653  TP=47 FP=8 FN=25 AP=0.744\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.754 R=0.956  TP=43 FP=14 FN=2 AP=0.957\n",
      "class 11 | P=0.812 R=0.839  TP=26 FP=6 FN=5 AP=0.899\n",
      "class 13 | P=0.779 R=0.788  TP=67 FP=19 FN=18 AP=0.816\n",
      "class 14 | P=0.921 R=0.882  TP=82 FP=7 FN=11 AP=0.925\n",
      "class 15 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.964\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.638\n",
      "class 18 | P=0.970 R=0.865  TP=32 FP=1 FN=5 AP=0.924\n",
      "class 19 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 20 | P=0.778 R=0.933  TP=14 FP=4 FN=1 AP=0.888\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.988\n",
      "class 28 | P=0.898 R=0.880  TP=44 FP=5 FN=6 AP=0.930\n",
      "class 29 | P=0.860 R=0.977  TP=43 FP=7 FN=1 AP=0.967\n",
      "class 30 | P=0.333 R=0.500  TP=2 FP=4 FN=2 AP=0.291\n",
      "class 31 | P=0.730 R=0.823  TP=65 FP=24 FN=14 AP=0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss 0.1996 | val loss 0.2567 | mAP 0.8325\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.816 R=0.886  TP=31 FP=7 FN=4 AP=0.925\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.958\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.917\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.738 R=0.667  TP=48 FP=17 FN=24 AP=0.655\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.764 R=0.933  TP=42 FP=13 FN=3 AP=0.945\n",
      "class 11 | P=0.833 R=0.806  TP=25 FP=5 FN=6 AP=0.887\n",
      "class 13 | P=0.758 R=0.812  TP=69 FP=22 FN=16 AP=0.831\n",
      "class 14 | P=0.905 R=0.925  TP=86 FP=9 FN=7 AP=0.949\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.949\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.638\n",
      "class 18 | P=0.971 R=0.892  TP=33 FP=1 FN=4 AP=0.941\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.931\n",
      "class 20 | P=0.824 R=0.933  TP=14 FP=3 FN=1 AP=0.874\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.154 R=1.000  TP=2 FP=11 FN=0 AP=0.695\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.900 R=1.000  TP=45 FP=5 FN=0 AP=0.993\n",
      "class 28 | P=0.776 R=0.900  TP=45 FP=13 FN=5 AP=0.931\n",
      "class 29 | P=0.870 R=0.909  TP=40 FP=6 FN=4 AP=0.934\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.326\n",
      "class 31 | P=0.716 R=0.861  TP=68 FP=27 FN=11 AP=0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss 0.1858 | val loss 0.2462 | mAP 0.8512\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.872 R=0.971  TP=34 FP=5 FN=1 AP=0.975\n",
      "class 02 | P=0.825 R=0.943  TP=33 FP=7 FN=2 AP=0.954\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.904 R=0.880  TP=66 FP=7 FN=9 AP=0.915\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.745 R=0.528  TP=38 FP=13 FN=34 AP=0.588\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.741 R=0.956  TP=43 FP=15 FN=2 AP=0.961\n",
      "class 11 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.903\n",
      "class 13 | P=0.753 R=0.859  TP=73 FP=24 FN=12 AP=0.856\n",
      "class 14 | P=0.926 R=0.935  TP=87 FP=7 FN=6 AP=0.938\n",
      "class 15 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.933\n",
      "class 16 | P=0.400 R=0.667  TP=4 FP=6 FN=2 AP=0.599\n",
      "class 18 | P=0.971 R=0.919  TP=34 FP=1 FN=3 AP=0.950\n",
      "class 19 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.962\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.898\n",
      "class 21 | P=0.571 R=0.571  TP=4 FP=3 FN=3 AP=0.665\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.900 R=1.000  TP=45 FP=5 FN=0 AP=0.992\n",
      "class 28 | P=0.750 R=0.900  TP=45 FP=15 FN=5 AP=0.931\n",
      "class 29 | P=0.782 R=0.977  TP=43 FP=12 FN=1 AP=0.974\n",
      "class 30 | P=0.222 R=0.500  TP=2 FP=7 FN=2 AP=0.364\n",
      "class 31 | P=0.642 R=0.861  TP=68 FP=38 FN=11 AP=0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss 0.1832 | val loss 0.2566 | mAP 0.8438\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.974\n",
      "class 02 | P=0.767 R=0.943  TP=33 FP=10 FN=2 AP=0.944\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.930 R=0.880  TP=66 FP=5 FN=9 AP=0.915\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.875 R=0.486  TP=35 FP=5 FN=37 AP=0.691\n",
      "class 09 | P=1.000 R=0.968  TP=30 FP=0 FN=1 AP=0.984\n",
      "class 10 | P=0.754 R=0.956  TP=43 FP=14 FN=2 AP=0.953\n",
      "class 11 | P=0.818 R=0.871  TP=27 FP=6 FN=4 AP=0.916\n",
      "class 13 | P=0.806 R=0.882  TP=75 FP=18 FN=10 AP=0.866\n",
      "class 14 | P=0.913 R=0.903  TP=84 FP=8 FN=9 AP=0.938\n",
      "class 15 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.931\n",
      "class 16 | P=0.714 R=0.833  TP=5 FP=2 FN=1 AP=0.655\n",
      "class 18 | P=0.967 R=0.784  TP=29 FP=1 FN=8 AP=0.887\n",
      "class 19 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.947\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.930\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.789 R=1.000  TP=45 FP=12 FN=0 AP=0.994\n",
      "class 28 | P=0.875 R=0.840  TP=42 FP=6 FN=8 AP=0.904\n",
      "class 29 | P=0.857 R=0.955  TP=42 FP=7 FN=2 AP=0.943\n",
      "class 30 | P=0.214 R=0.750  TP=3 FP=11 FN=1 AP=0.214\n",
      "class 31 | P=0.722 R=0.823  TP=65 FP=25 FN=14 AP=0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss 0.1788 | val loss 0.2400 | mAP 0.8539\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.941 R=0.914  TP=32 FP=2 FN=3 AP=0.951\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.950\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.896\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.860 R=0.597  TP=43 FP=7 FN=29 AP=0.709\n",
      "class 09 | P=0.912 R=1.000  TP=31 FP=3 FN=0 AP=0.994\n",
      "class 10 | P=0.494 R=0.978  TP=44 FP=45 FN=1 AP=0.934\n",
      "class 11 | P=0.737 R=0.903  TP=28 FP=10 FN=3 AP=0.917\n",
      "class 13 | P=0.776 R=0.894  TP=76 FP=22 FN=9 AP=0.905\n",
      "class 14 | P=0.929 R=0.849  TP=79 FP=6 FN=14 AP=0.896\n",
      "class 15 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 16 | P=0.571 R=0.667  TP=4 FP=3 FN=2 AP=0.695\n",
      "class 18 | P=1.000 R=0.892  TP=33 FP=0 FN=4 AP=0.946\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.965\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.828\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.978 R=1.000  TP=45 FP=1 FN=0 AP=0.993\n",
      "class 28 | P=0.852 R=0.920  TP=46 FP=8 FN=4 AP=0.947\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.975\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.302\n",
      "class 31 | P=0.728 R=0.848  TP=67 FP=25 FN=12 AP=0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss 0.1420 | val loss 0.2502 | mAP 0.8538\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.917 R=0.943  TP=33 FP=3 FN=2 AP=0.966\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.966\n",
      "class 04 | P=0.794 R=1.000  TP=27 FP=7 FN=0 AP=0.989\n",
      "class 05 | P=0.905 R=0.893  TP=67 FP=7 FN=8 AP=0.904\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.833 R=0.625  TP=45 FP=9 FN=27 AP=0.712\n",
      "class 09 | P=0.838 R=1.000  TP=31 FP=6 FN=0 AP=0.987\n",
      "class 10 | P=0.694 R=0.956  TP=43 FP=19 FN=2 AP=0.949\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.941\n",
      "class 13 | P=0.795 R=0.824  TP=70 FP=18 FN=15 AP=0.861\n",
      "class 14 | P=0.906 R=0.828  TP=77 FP=8 FN=16 AP=0.871\n",
      "class 15 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.945\n",
      "class 16 | P=0.500 R=0.667  TP=4 FP=4 FN=2 AP=0.616\n",
      "class 18 | P=0.889 R=0.865  TP=32 FP=4 FN=5 AP=0.911\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.949\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.945\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.995\n",
      "class 23 | P=0.941 R=1.000  TP=48 FP=3 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.882 R=1.000  TP=45 FP=6 FN=0 AP=0.992\n",
      "class 28 | P=0.900 R=0.900  TP=45 FP=5 FN=5 AP=0.938\n",
      "class 29 | P=0.875 R=0.955  TP=42 FP=6 FN=2 AP=0.973\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.358\n",
      "class 31 | P=0.720 R=0.848  TP=67 FP=26 FN=12 AP=0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss 0.1386 | val loss 0.2581 | mAP 0.8503\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.946\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.968\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.905 R=0.893  TP=67 FP=7 FN=8 AP=0.918\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.823 R=0.708  TP=51 FP=11 FN=21 AP=0.744\n",
      "class 09 | P=0.886 R=1.000  TP=31 FP=4 FN=0 AP=0.992\n",
      "class 10 | P=0.688 R=0.978  TP=44 FP=20 FN=1 AP=0.953\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.940\n",
      "class 13 | P=0.847 R=0.847  TP=72 FP=13 FN=13 AP=0.870\n",
      "class 14 | P=0.903 R=0.903  TP=84 FP=9 FN=9 AP=0.928\n",
      "class 15 | P=0.871 R=0.871  TP=27 FP=4 FN=4 AP=0.912\n",
      "class 16 | P=0.444 R=0.667  TP=4 FP=5 FN=2 AP=0.518\n",
      "class 18 | P=1.000 R=0.838  TP=31 FP=0 FN=6 AP=0.919\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.923\n",
      "class 20 | P=0.824 R=0.933  TP=14 FP=3 FN=1 AP=0.923\n",
      "class 21 | P=0.571 R=0.571  TP=4 FP=3 FN=3 AP=0.665\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.992\n",
      "class 28 | P=0.821 R=0.920  TP=46 FP=10 FN=4 AP=0.948\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.972\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.262\n",
      "class 31 | P=0.729 R=0.886  TP=70 FP=26 FN=9 AP=0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss 0.1343 | val loss 0.2400 | mAP 0.8551\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.868 R=0.943  TP=33 FP=5 FN=2 AP=0.958\n",
      "class 02 | P=0.825 R=0.943  TP=33 FP=7 FN=2 AP=0.948\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.913\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.842 R=0.667  TP=48 FP=9 FN=24 AP=0.737\n",
      "class 09 | P=0.939 R=1.000  TP=31 FP=2 FN=0 AP=0.993\n",
      "class 10 | P=0.811 R=0.956  TP=43 FP=10 FN=2 AP=0.964\n",
      "class 11 | P=0.906 R=0.935  TP=29 FP=3 FN=2 AP=0.959\n",
      "class 13 | P=0.780 R=0.835  TP=71 FP=20 FN=14 AP=0.877\n",
      "class 14 | P=0.933 R=0.903  TP=84 FP=6 FN=9 AP=0.935\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.945\n",
      "class 16 | P=0.556 R=0.833  TP=5 FP=4 FN=1 AP=0.636\n",
      "class 18 | P=1.000 R=0.838  TP=31 FP=0 FN=6 AP=0.919\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.926\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.935\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.978 R=1.000  TP=45 FP=1 FN=0 AP=0.992\n",
      "class 28 | P=0.938 R=0.900  TP=45 FP=3 FN=5 AP=0.941\n",
      "class 29 | P=0.811 R=0.977  TP=43 FP=10 FN=1 AP=0.949\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.315\n",
      "class 31 | P=0.731 R=0.861  TP=68 FP=25 FN=11 AP=0.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss 0.1703 | val loss 0.2494 | mAP 0.8560\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.865 R=0.914  TP=32 FP=5 FN=3 AP=0.946\n",
      "class 02 | P=0.750 R=0.943  TP=33 FP=11 FN=2 AP=0.946\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.908\n",
      "class 06 | P=0.667 R=0.800  TP=4 FP=2 FN=1 AP=0.865\n",
      "class 07 | P=0.827 R=0.597  TP=43 FP=9 FN=29 AP=0.677\n",
      "class 09 | P=0.833 R=0.968  TP=30 FP=6 FN=1 AP=0.980\n",
      "class 10 | P=0.854 R=0.911  TP=41 FP=7 FN=4 AP=0.947\n",
      "class 11 | P=0.906 R=0.935  TP=29 FP=3 FN=2 AP=0.963\n",
      "class 13 | P=0.896 R=0.812  TP=69 FP=8 FN=16 AP=0.878\n",
      "class 14 | P=0.933 R=0.903  TP=84 FP=6 FN=9 AP=0.941\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.947\n",
      "class 16 | P=0.625 R=0.833  TP=5 FP=3 FN=1 AP=0.822\n",
      "class 18 | P=0.943 R=0.892  TP=33 FP=2 FN=4 AP=0.941\n",
      "class 19 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.925\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.904\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.987\n",
      "class 28 | P=0.815 R=0.880  TP=44 FP=10 FN=6 AP=0.918\n",
      "class 29 | P=0.824 R=0.955  TP=42 FP=9 FN=2 AP=0.948\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.355\n",
      "class 31 | P=0.747 R=0.899  TP=71 FP=24 FN=8 AP=0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss 0.1537 | val loss 0.2631 | mAP 0.8544\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.780 R=0.914  TP=32 FP=9 FN=3 AP=0.943\n",
      "class 02 | P=0.750 R=0.943  TP=33 FP=11 FN=2 AP=0.944\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.909 R=0.933  TP=70 FP=7 FN=5 AP=0.937\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.773 R=0.708  TP=51 FP=15 FN=21 AP=0.679\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.732 R=0.911  TP=41 FP=15 FN=4 AP=0.933\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.942\n",
      "class 13 | P=0.841 R=0.812  TP=69 FP=13 FN=16 AP=0.874\n",
      "class 14 | P=0.923 R=0.903  TP=84 FP=7 FN=9 AP=0.919\n",
      "class 15 | P=0.900 R=0.871  TP=27 FP=3 FN=4 AP=0.918\n",
      "class 16 | P=0.625 R=0.833  TP=5 FP=3 FN=1 AP=0.689\n",
      "class 18 | P=1.000 R=0.811  TP=30 FP=0 FN=7 AP=0.905\n",
      "class 19 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.943\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.903\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.222 R=1.000  TP=2 FP=7 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.938 R=1.000  TP=45 FP=3 FN=0 AP=0.994\n",
      "class 28 | P=0.917 R=0.880  TP=44 FP=4 FN=6 AP=0.927\n",
      "class 29 | P=0.827 R=0.977  TP=43 FP=9 FN=1 AP=0.962\n",
      "class 30 | P=0.375 R=0.750  TP=3 FP=5 FN=1 AP=0.368\n",
      "class 31 | P=0.667 R=0.886  TP=70 FP=35 FN=9 AP=0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train loss 0.1295 | val loss 0.2599 | mAP 0.8591\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.941\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.950\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.915 R=0.867  TP=65 FP=6 FN=10 AP=0.905\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.807 R=0.639  TP=46 FP=11 FN=26 AP=0.699\n",
      "class 09 | P=0.882 R=0.968  TP=30 FP=4 FN=1 AP=0.981\n",
      "class 10 | P=0.772 R=0.978  TP=44 FP=13 FN=1 AP=0.967\n",
      "class 11 | P=0.963 R=0.839  TP=26 FP=1 FN=5 AP=0.915\n",
      "class 13 | P=0.863 R=0.812  TP=69 FP=11 FN=16 AP=0.879\n",
      "class 14 | P=0.914 R=0.914  TP=85 FP=8 FN=8 AP=0.938\n",
      "class 15 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.944\n",
      "class 16 | P=0.500 R=0.667  TP=4 FP=4 FN=2 AP=0.692\n",
      "class 18 | P=0.971 R=0.892  TP=33 FP=1 FN=4 AP=0.938\n",
      "class 19 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.911\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.685\n",
      "class 22 | P=0.500 R=1.000  TP=2 FP=2 FN=0 AP=0.828\n",
      "class 23 | P=0.960 R=1.000  TP=48 FP=2 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.938 R=1.000  TP=45 FP=3 FN=0 AP=0.995\n",
      "class 28 | P=0.849 R=0.900  TP=45 FP=8 FN=5 AP=0.938\n",
      "class 29 | P=0.792 R=0.955  TP=42 FP=11 FN=2 AP=0.947\n",
      "class 30 | P=0.231 R=0.750  TP=3 FP=10 FN=1 AP=0.510\n",
      "class 31 | P=0.732 R=0.899  TP=71 FP=26 FN=8 AP=0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train loss 0.1403 | val loss 0.2596 | mAP 0.8675\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.865 R=0.914  TP=32 FP=5 FN=3 AP=0.947\n",
      "class 02 | P=0.829 R=0.971  TP=34 FP=7 FN=1 AP=0.955\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.896 R=0.920  TP=69 FP=8 FN=6 AP=0.932\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.864 R=0.708  TP=51 FP=8 FN=21 AP=0.781\n",
      "class 09 | P=0.857 R=0.968  TP=30 FP=5 FN=1 AP=0.981\n",
      "class 10 | P=0.786 R=0.978  TP=44 FP=12 FN=1 AP=0.964\n",
      "class 11 | P=0.848 R=0.903  TP=28 FP=5 FN=3 AP=0.934\n",
      "class 13 | P=0.812 R=0.812  TP=69 FP=16 FN=16 AP=0.850\n",
      "class 14 | P=0.902 R=0.892  TP=83 FP=9 FN=10 AP=0.920\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.905\n",
      "class 16 | P=0.714 R=0.833  TP=5 FP=2 FN=1 AP=0.811\n",
      "class 18 | P=0.943 R=0.892  TP=33 FP=2 FN=4 AP=0.942\n",
      "class 19 | P=0.929 R=0.839  TP=26 FP=2 FN=5 AP=0.913\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.911\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.657\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=1.000 R=1.000  TP=45 FP=0 FN=0 AP=0.995\n",
      "class 28 | P=0.833 R=0.900  TP=45 FP=9 FN=5 AP=0.934\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.968\n",
      "class 30 | P=0.250 R=0.750  TP=3 FP=9 FN=1 AP=0.431\n",
      "class 31 | P=0.750 R=0.873  TP=69 FP=23 FN=10 AP=0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train loss 0.1326 | val loss 0.2610 | mAP 0.8554\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.947\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.957\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.918 R=0.893  TP=67 FP=6 FN=8 AP=0.916\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.862 R=0.694  TP=50 FP=8 FN=22 AP=0.747\n",
      "class 09 | P=0.857 R=0.968  TP=30 FP=5 FN=1 AP=0.981\n",
      "class 10 | P=0.854 R=0.911  TP=41 FP=7 FN=4 AP=0.943\n",
      "class 11 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.945\n",
      "class 13 | P=0.787 R=0.824  TP=70 FP=19 FN=15 AP=0.839\n",
      "class 14 | P=0.884 R=0.903  TP=84 FP=11 FN=9 AP=0.910\n",
      "class 15 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.948\n",
      "class 16 | P=0.462 R=1.000  TP=6 FP=7 FN=0 AP=0.760\n",
      "class 18 | P=0.939 R=0.838  TP=31 FP=2 FN=6 AP=0.910\n",
      "class 19 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.968\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.870\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.630\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.828\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.995\n",
      "class 28 | P=0.860 R=0.860  TP=43 FP=7 FN=7 AP=0.913\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.959\n",
      "class 30 | P=0.214 R=0.750  TP=3 FP=11 FN=1 AP=0.452\n",
      "class 31 | P=0.693 R=0.886  TP=70 FP=31 FN=9 AP=0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200/200 [00:37<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference @ IoU 0.50 | mAP 0.8599\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=8 AP=0.000\n",
      "class 01 | P=0.967 R=0.989  TP=89 FP=3 FN=1 AP=0.994\n",
      "class 02 | P=0.889 R=0.941  TP=16 FP=2 FN=1 AP=0.927\n",
      "class 04 | P=1.000 R=0.842  TP=16 FP=0 FN=3 AP=0.921\n",
      "class 05 | P=0.647 R=0.917  TP=11 FP=6 FN=1 AP=0.943\n",
      "class 06 | P=0.500 R=1.000  TP=1 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.909 R=0.741  TP=20 FP=2 FN=7 AP=0.823\n",
      "class 09 | P=0.952 R=1.000  TP=20 FP=1 FN=0 AP=0.983\n",
      "class 10 | P=0.917 R=0.957  TP=22 FP=2 FN=1 AP=0.974\n",
      "class 11 | P=1.000 R=0.944  TP=17 FP=0 FN=1 AP=0.972\n",
      "class 13 | P=0.733 R=0.917  TP=22 FP=8 FN=2 AP=0.928\n",
      "class 14 | P=1.000 R=0.909  TP=20 FP=0 FN=2 AP=0.955\n",
      "class 15 | P=0.894 R=0.854  TP=76 FP=9 FN=13 AP=0.890\n",
      "class 16 | P=0.667 R=1.000  TP=2 FP=1 FN=0 AP=0.828\n",
      "class 17 | P=0.000 R=0.000  TP=0 FP=0 FN=2 AP=0.000\n",
      "class 18 | P=0.918 R=0.817  TP=67 FP=6 FN=15 AP=0.864\n",
      "class 19 | P=0.975 R=0.898  TP=79 FP=2 FN=9 AP=0.945\n",
      "class 20 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 21 | P=0.556 R=0.625  TP=5 FP=4 FN=3 AP=0.692\n",
      "class 22 | P=0.800 R=1.000  TP=4 FP=1 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=0.958  TP=23 FP=0 FN=1 AP=0.979\n",
      "class 25 | P=0.500 R=1.000  TP=1 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.905 R=0.864  TP=19 FP=2 FN=3 AP=0.925\n",
      "class 28 | P=0.950 R=0.864  TP=19 FP=1 FN=3 AP=0.928\n",
      "class 29 | P=0.909 R=0.909  TP=20 FP=2 FN=2 AP=0.948\n",
      "class 30 | P=1.000 R=1.000  TP=2 FP=0 FN=0 AP=0.995\n",
      "class 31 | P=0.583 R=0.933  TP=14 FP=10 FN=1 AP=0.823\n"
     ]
    }
   ],
   "source": [
    "# Example usage inside the notebook\n",
    "# 1) Configure training arguments\n",
    "train_args = argparse.Namespace(\n",
    "    data_dir=Path('/path/to/dataset'),\n",
    "    epochs=2,\n",
    "    batch_size=2,\n",
    "    lr=5e-5,\n",
    "    weight_decay=5e-5,\n",
    "    num_workers=2,\n",
    "    no_augmentation=True,\n",
    "    mosaic_prob=TrainingConfig().mosaic_prob,\n",
    "    mixup_prob=TrainingConfig().mixup_prob,\n",
    "    mixup_alpha=TrainingConfig().mixup_alpha,\n",
    "    scale_jitter=None,\n",
    "    rotation_prob=TrainingConfig().rotation_prob,\n",
    "    rotation_max_degrees=TrainingConfig().rotation_max_degrees,\n",
    "    affine_prob=TrainingConfig().affine_prob,\n",
    "    affine_translate=None,\n",
    "    affine_scale=None,\n",
    "    affine_shear=None,\n",
    "    small_object=True,\n",
    "    score_threshold=0.6,\n",
    "    class_threshold=[],\n",
    "    iou_threshold=0.5,\n",
    "    no_amp=False,\n",
    "    eval_interval=1,\n",
    "    seed=37,\n",
    "    checkpoint=Path('outputs/best_model.pth'),\n",
    "    pretrained_path=TrainingConfig().pretrained_weights_path,\n",
    "    resume=False,\n",
    "    resume_path=None,\n",
    "    log_every=20,\n",
    "    train_split=DatasetConfig().train_split,\n",
    "    valid_split=DatasetConfig().valid_split,\n",
    "    num_classes=DatasetConfig().num_classes,\n",
    "    exclude_list=[],\n",
    "    exclude_sample=[],\n",
    "    fp_dir=None,\n",
    "    fp_report=None,\n",
    "    fp_list=None,\n",
    "    fp_class=[],\n",
    ")\n",
    "\n",
    "# 2) Launch training (writes checkpoints to outputs/)\n",
    "# run_training(train_args)\n",
    "\n",
    "# 3) Run inference once a checkpoint is available\n",
    "# inference_args = argparse.Namespace(\n",
    "#     data_dir=train_args.data_dir,\n",
    "#     split=DatasetConfig().valid_split,\n",
    "#     checkpoint=Path('outputs/best_model.pth'),\n",
    "#     output_dir=Path('outputs/inference'),\n",
    "#     score_threshold=0.6,\n",
    "#     class_threshold=[],\n",
    "#     iou_threshold=0.5,\n",
    "#     max_images=50,\n",
    "#     num_classes=train_args.num_classes,\n",
    "#     draw_ground_truth=True,\n",
    "#     seed=2024,\n",
    "#     pretrained_path=TrainingConfig().pretrained_weights_path,\n",
    "#     fp_report=None,\n",
    "#     fp_list=None,\n",
    "# )\n",
    "# run_inference(inference_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b145413",
   "metadata": {
    "papermill": {
     "duration": 0.800242,
     "end_time": "2025-10-21T09:11:23.026892",
     "exception": false,
     "start_time": "2025-10-21T09:11:22.226650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**\u63d0\u793a\uff1a** `run_inference` \u4f1a\u5728\u8fd4\u56de\u7684 `metrics` \u4e2d\u9644\u5e26 `false_positive_images` \u548c `false_positive_stems`\u3002 \u5982\u679c\u60f3\u5728\u4e0b\u4e00\u6b21\u8bad\u7ec3\u65f6\u5ffd\u7565\u8fd9\u4e9b\u6837\u672c\uff0c\u53ef\u4ee5\u5c06 `TrainingConfig.exclude_samples` \u8bbe\u4e3a `tuple(metrics[\"false_positive_stems\"])`\uff0c\u6216\u5c06 `metrics[\"false_positive_stems\"]` \u5199\u5165\u6587\u672c\u6587\u4ef6\uff0c \u7136\u540e\u901a\u8fc7\u547d\u4ee4\u884c\u53c2\u6570 `--exclude-list` \u4f20\u5165\u3002"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8456082,
     "sourceId": 13448831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7814.129974,
   "end_time": "2025-10-21T09:11:26.346868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-21T07:01:12.216894",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}