{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrical Component Detection Pipeline\n",
    "\n",
    "This notebook consolidates the refactored Faster R-CNN training and inference workflow into a single place for convenient experimentation on Kaggle. It provides reusable configuration objects, dataset loaders with optional augmentation, detailed metric utilities (including per-class TP/FP/FN and mAP), and helpers for both training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image as PILImage, ImageDraw, ImageEnhance, ImageFont\n",
    "from torch import Tensor, nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models.detection import (\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "LOGGER = logging.getLogger(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PRETRAINED_URL = \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Configuration describing the dataset layout and metadata.\"\"\"\n",
    "\n",
    "    base_dir: Path = Path(\"data\")\n",
    "    train_split: str = \"train\"\n",
    "    valid_split: str = \"valid\"\n",
    "    test_split: str = \"test\"\n",
    "    image_folder: str = \"images\"\n",
    "    label_folder: str = \"labels\"\n",
    "    num_classes: int = 32\n",
    "    class_names: Tuple[str, ...] = ()\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if not self.class_names:\n",
    "            self.class_names = tuple(f\"class_{idx:02d}\" for idx in range(self.num_classes))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Hyper-parameters and runtime settings for model training.\"\"\"\n",
    "\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 1e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    num_workers: int = 0\n",
    "    amp: bool = True\n",
    "    augmentation: bool = True\n",
    "    small_object: bool = False\n",
    "    score_threshold: float = 0.05\n",
    "    iou_threshold: float = 0.5\n",
    "    eval_interval: int = 1\n",
    "    seed: int = 2024\n",
    "    output_dir: Path = Path(\"outputs\")\n",
    "    checkpoint_path: Path = Path(\"outputs/best_model.pth\")\n",
    "    pretrained_weights_path: Path = Path(\"weights/fasterrcnn_resnet50_fpn_v2_coco.pth\")\n",
    "    pretrained_weights_url: str = DEFAULT_PRETRAINED_URL\n",
    "    log_every: int = 20\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.pretrained_weights_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    \"\"\"Options for running model inference and visualisation.\"\"\"\n",
    "\n",
    "    score_threshold: float = 0.3\n",
    "    max_images: int = 50\n",
    "    output_dir: Path = Path(\"outputs/inference\")\n",
    "    draw_ground_truth: bool = True\n",
    "    class_colors: List[str] = field(default_factory=list)\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading and augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationParams:\n",
    "    \"\"\"Parameters controlling the dataset level image augmentations.\"\"\"\n",
    "\n",
    "    horizontal_flip_prob: float = 0.5\n",
    "    vertical_flip_prob: float = 0.2\n",
    "    brightness: float = 0.2\n",
    "    contrast: float = 0.2\n",
    "    saturation: float = 0.2\n",
    "    hue: float = 0.02\n",
    "\n",
    "\n",
    "def load_image_hwc_uint8(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load an ``.npy`` image stored as HWC and return an ``uint8`` array.\"\"\"\n",
    "    image = np.load(path, allow_pickle=False, mmap_mode=\"r\")\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.float32, copy=False)\n",
    "        vmin, vmax = float(image.min()), float(image.max())\n",
    "        if 0.0 <= vmin and vmax <= 1.0:\n",
    "            image = (image * 255.0).round()\n",
    "        elif -1.0 <= vmin and vmax <= 1.0:\n",
    "            image = ((image + 1.0) * 0.5 * 255.0).round()\n",
    "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    channels = image.shape[2]\n",
    "    if channels == 1:\n",
    "        image = np.repeat(image, 3, axis=2)\n",
    "    elif channels == 4:\n",
    "        image = image[..., :3]\n",
    "    return image\n",
    "\n",
    "\n",
    "class ElectricalComponentsDataset(Dataset):\n",
    "    \"\"\"Dataset of electrical component detections stored as ``.npy`` images and CSV labels.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Path,\n",
    "        split: str,\n",
    "        class_names: Iterable[str],\n",
    "        transform: Optional[AugmentationParams] = None,\n",
    "        use_augmentation: bool = False,\n",
    "    ) -> None:\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.class_names = list(class_names)\n",
    "        self.transform_params = transform or AugmentationParams()\n",
    "        self.use_augmentation = use_augmentation\n",
    "\n",
    "        self.image_dir = self.root / split / \"images\"\n",
    "        self.label_dir = self.root / split / \"labels\"\n",
    "\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing image directory: {self.image_dir}\")\n",
    "        if not self.label_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing label directory: {self.label_dir}\")\n",
    "\n",
    "        self.image_stems = sorted(p.stem for p in self.label_dir.glob(\"*.csv\"))\n",
    "        if not self.image_stems:\n",
    "            raise RuntimeError(f\"No label files found in {self.label_dir}\")\n",
    "\n",
    "        # Pre-load all annotations to reduce I/O during training.\n",
    "        self.annotations: Dict[str, pd.DataFrame] = {\n",
    "            stem: pd.read_csv(self.label_dir / f\"{stem}.csv\") for stem in self.image_stems\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_stems)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        stem = self.image_stems[index]\n",
    "        image_path = self.image_dir / f\"{stem}.npy\"\n",
    "        image = load_image_hwc_uint8(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        ann = self.annotations[stem]\n",
    "        x_center = ann[\"x_center\"].to_numpy(dtype=np.float32)\n",
    "        y_center = ann[\"y_center\"].to_numpy(dtype=np.float32)\n",
    "        box_width = ann[\"width\"].to_numpy(dtype=np.float32)\n",
    "        box_height = ann[\"height\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # Auto-detect normalised coordinates and scale back to pixel space.\n",
    "        if (\n",
    "            (x_center.size == 0 or float(x_center.max()) <= 1.0)\n",
    "            and (y_center.size == 0 or float(y_center.max()) <= 1.0)\n",
    "            and (box_width.size == 0 or float(box_width.max()) <= 1.0)\n",
    "            and (box_height.size == 0 or float(box_height.max()) <= 1.0)\n",
    "        ):\n",
    "            x_center *= width\n",
    "            y_center *= height\n",
    "            box_width *= width\n",
    "            box_height *= height\n",
    "\n",
    "        x1 = x_center - box_width / 2.0\n",
    "        y1 = y_center - box_height / 2.0\n",
    "        x2 = x_center + box_width / 2.0\n",
    "        y2 = y_center + box_height / 2.0\n",
    "\n",
    "        boxes = np.stack([x1, y1, x2, y2], axis=1)\n",
    "        labels = ann[\"class\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "        if self.use_augmentation and len(boxes):\n",
    "            image, boxes = self._apply_augmentations(image, boxes)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        boxes_tensor = torch.from_numpy(boxes).float()\n",
    "        labels_tensor = torch.from_numpy(labels).long()\n",
    "\n",
    "        boxes_tensor, labels_tensor = sanitize_boxes_and_labels(\n",
    "            boxes_tensor, labels_tensor, height, width\n",
    "        )\n",
    "\n",
    "        target: Dict[str, torch.Tensor] = {\n",
    "            \"boxes\": boxes_tensor,\n",
    "            \"labels\": labels_tensor,\n",
    "            \"image_id\": torch.tensor(index, dtype=torch.int64),\n",
    "            \"area\": (boxes_tensor[:, 2] - boxes_tensor[:, 0])\n",
    "            * (boxes_tensor[:, 3] - boxes_tensor[:, 1])\n",
    "            if boxes_tensor.numel()\n",
    "            else torch.tensor([], dtype=torch.float32),\n",
    "            \"iscrowd\": torch.zeros((boxes_tensor.shape[0],), dtype=torch.int64),\n",
    "            \"orig_size\": torch.tensor([height, width], dtype=torch.int64),\n",
    "        }\n",
    "\n",
    "        return image_tensor, target\n",
    "\n",
    "    def _apply_augmentations(\n",
    "        self, image: np.ndarray, boxes: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        params = self.transform_params\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        if random.random() < params.horizontal_flip_prob:\n",
    "            image = np.ascontiguousarray(image[:, ::-1, :])\n",
    "            x1 = width - boxes[:, 2]\n",
    "            x2 = width - boxes[:, 0]\n",
    "            boxes[:, 0], boxes[:, 2] = x1, x2\n",
    "\n",
    "        if random.random() < params.vertical_flip_prob:\n",
    "            image = np.ascontiguousarray(image[::-1, :, :])\n",
    "            y1 = height - boxes[:, 3]\n",
    "            y2 = height - boxes[:, 1]\n",
    "            boxes[:, 1], boxes[:, 3] = y1, y2\n",
    "\n",
    "        if params.brightness or params.contrast or params.saturation or params.hue:\n",
    "            pil = PILImage.fromarray(image)\n",
    "            if params.brightness:\n",
    "                enhancer = ImageEnhance.Brightness(pil)\n",
    "                factor = 1.0 + random.uniform(-params.brightness, params.brightness)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.contrast:\n",
    "                enhancer = ImageEnhance.Contrast(pil)\n",
    "                factor = 1.0 + random.uniform(-params.contrast, params.contrast)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.saturation:\n",
    "                enhancer = ImageEnhance.Color(pil)\n",
    "                factor = 1.0 + random.uniform(-params.saturation, params.saturation)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.hue:\n",
    "                # Hue adjustment via simple conversion to HSV.\n",
    "                hsv = np.array(pil.convert(\"HSV\"), dtype=np.uint8)\n",
    "                delta = int(params.hue * 255.0 * random.choice([-1, 1]))\n",
    "                hsv[..., 0] = (hsv[..., 0].astype(int) + delta) % 255\n",
    "                pil = PILImage.fromarray(hsv, mode=\"HSV\").convert(\"RGB\")\n",
    "            image = np.array(pil)\n",
    "\n",
    "        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, width)\n",
    "        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, height)\n",
    "        return image, boxes\n",
    "\n",
    "\n",
    "def detection_collate(batch: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]):\n",
    "    \"\"\"Collate function for detection datasets returning lists of tensors.\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "\n",
    "def _safe_worker_count(requested: int) -> int:\n",
    "    cpu_count = os.cpu_count() or 1\n",
    "    if requested <= 0:\n",
    "        return 0\n",
    "    max_workers = max(1, cpu_count - 1)\n",
    "    return min(requested, max_workers)\n",
    "\n",
    "\n",
    "def create_data_loaders(\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    num_workers: int,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Create a :class:`torch.utils.data.DataLoader` with notebook friendly defaults.\"\"\"\n",
    "\n",
    "    worker_count = _safe_worker_count(num_workers)\n",
    "    loader_kwargs = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=detection_collate,\n",
    "    )\n",
    "\n",
    "    if worker_count > 0:\n",
    "        loader_kwargs[\"num_workers\"] = worker_count\n",
    "        loader_kwargs[\"persistent_workers\"] = True\n",
    "        loader_kwargs[\"multiprocessing_context\"] = mp.get_context(\"spawn\")\n",
    "    else:\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "\n",
    "    try:\n",
    "        return DataLoader(**loader_kwargs)\n",
    "    except (RuntimeError, OSError, AssertionError) as exc:\n",
    "        if worker_count == 0:\n",
    "            raise\n",
    "        warnings.warn(\n",
    "            \"Falling back to num_workers=0 because DataLoader worker initialisation \"\n",
    "            f\"failed with: {exc}\",\n",
    "            RuntimeWarning,\n",
    "        )\n",
    "        LOGGER.warning(\"DataLoader workers failed to start (%s). Using num_workers=0 instead.\", exc)\n",
    "        loader_kwargs.pop(\"persistent_workers\", None)\n",
    "        loader_kwargs.pop(\"multiprocessing_context\", None)\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "        return DataLoader(**loader_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility helpers and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def sanitize_boxes_and_labels(\n",
    "    boxes: Tensor, labels: Tensor, height: int, width: int, min_size: float = 1.0\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    if boxes.numel() == 0:\n",
    "        return boxes.reshape(0, 4).float(), labels.reshape(0).long()\n",
    "\n",
    "    boxes = boxes.clone()\n",
    "    boxes[:, 0::2] = boxes[:, 0::2].clamp(0, float(width))\n",
    "    boxes[:, 1::2] = boxes[:, 1::2].clamp(0, float(height))\n",
    "\n",
    "    widths = boxes[:, 2] - boxes[:, 0]\n",
    "    heights = boxes[:, 3] - boxes[:, 1]\n",
    "    keep = (widths > min_size) & (heights > min_size)\n",
    "\n",
    "    if keep.sum() == 0:\n",
    "        return boxes.new_zeros((0, 4)), labels.new_zeros((0,), dtype=torch.long)\n",
    "    return boxes[keep].float(), labels[keep].long()\n",
    "\n",
    "\n",
    "def compute_iou_matrix(boxes1: np.ndarray, boxes2: np.ndarray) -> np.ndarray:\n",
    "    if boxes1.size == 0 or boxes2.size == 0:\n",
    "        return np.zeros((boxes1.shape[0], boxes2.shape[0]), dtype=np.float32)\n",
    "\n",
    "    x11, y11, x12, y12 = np.split(boxes1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(boxes2, 4, axis=1)\n",
    "\n",
    "    inter_x1 = np.maximum(x11, x21.T)\n",
    "    inter_y1 = np.maximum(y11, y21.T)\n",
    "    inter_x2 = np.minimum(x12, x22.T)\n",
    "    inter_y2 = np.minimum(y12, y22.T)\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, a_min=0.0, a_max=None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, a_min=0.0, a_max=None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area1 = (x12 - x11) * (y12 - y11)\n",
    "    area2 = (x22 - x21) * (y22 - y21)\n",
    "\n",
    "    union = area1 + area2.T - inter_area\n",
    "    return np.divide(inter_area, union, out=np.zeros_like(inter_area), where=union > 0)\n",
    "\n",
    "\n",
    "def compute_average_precision(recalls: np.ndarray, precisions: np.ndarray) -> float:\n",
    "    if recalls.size == 0 or precisions.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    mrec = np.concatenate(([0.0], recalls, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precisions, [0.0]))\n",
    "\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "\n",
    "    recall_points = np.linspace(0, 1, 101)\n",
    "    precision_interp = np.interp(recall_points, mrec, mpre)\n",
    "    return float(np.trapz(precision_interp, recall_points))\n",
    "\n",
    "\n",
    "def accumulate_classification_stats(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[List[float]], List[List[int]], np.ndarray]:\n",
    "    tp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fn = np.zeros(num_classes, dtype=np.int64)\n",
    "    scores: List[List[float]] = [[] for _ in range(num_classes)]\n",
    "    matches: List[List[int]] = [[] for _ in range(num_classes)]\n",
    "    gt_counter = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    for pred, tgt in zip(predictions, targets):\n",
    "        pred_boxes = pred[\"boxes\"]\n",
    "        pred_scores = pred[\"scores\"]\n",
    "        pred_labels = pred[\"labels\"].astype(np.int64)\n",
    "\n",
    "        gt_boxes = tgt[\"boxes\"]\n",
    "        gt_labels = tgt[\"labels\"].astype(np.int64)\n",
    "\n",
    "        unique_classes = np.unique(np.concatenate((pred_labels, gt_labels)))\n",
    "        for cls in unique_classes:\n",
    "            pb = pred_boxes[pred_labels == cls]\n",
    "            ps = pred_scores[pred_labels == cls]\n",
    "            tb = gt_boxes[gt_labels == cls]\n",
    "            gt_counter[cls] += len(tb)\n",
    "\n",
    "            if len(tb) == 0:\n",
    "                fp[cls] += len(pb)\n",
    "                scores[cls].extend(ps.tolist())\n",
    "                matches[cls].extend([0] * len(pb))\n",
    "                continue\n",
    "\n",
    "            order = np.argsort(-ps)\n",
    "            pb = pb[order]\n",
    "            ps = ps[order]\n",
    "            iou_matrix = compute_iou_matrix(pb, tb)\n",
    "\n",
    "            matched_gt: set[int] = set()\n",
    "            for det_idx, score in enumerate(ps):\n",
    "                if tb.size == 0:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "                    continue\n",
    "\n",
    "                best_gt = int(np.argmax(iou_matrix[det_idx]))\n",
    "                best_iou = iou_matrix[det_idx, best_gt]\n",
    "\n",
    "                if best_iou >= iou_threshold and best_gt not in matched_gt:\n",
    "                    tp[cls] += 1\n",
    "                    matched_gt.add(best_gt)\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(1)\n",
    "                else:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "\n",
    "            fn[cls] += len(tb) - len(matched_gt)\n",
    "\n",
    "    return tp, fp, fn, scores, matches, gt_counter\n",
    "\n",
    "\n",
    "def compute_detection_metrics(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    tp, fp, fn, scores, matches, gt_counter = accumulate_classification_stats(\n",
    "        predictions, targets, num_classes, iou_threshold\n",
    "    )\n",
    "\n",
    "    precision = np.divide(tp, np.clip(tp + fp, a_min=1, a_max=None))\n",
    "    recall = np.divide(tp, np.clip(tp + fn, a_min=1, a_max=None))\n",
    "\n",
    "    ap = np.zeros(num_classes, dtype=np.float32)\n",
    "    for cls in range(num_classes):\n",
    "        if gt_counter[cls] == 0:\n",
    "            ap[cls] = np.nan\n",
    "            continue\n",
    "        if not scores[cls]:\n",
    "            ap[cls] = 0.0\n",
    "            continue\n",
    "\n",
    "        order = np.argsort(-np.asarray(scores[cls]))\n",
    "        match_array = np.asarray(matches[cls], dtype=np.int32)[order]\n",
    "        cumulative_tp = np.cumsum(match_array)\n",
    "        cumulative_fp = np.cumsum(1 - match_array)\n",
    "\n",
    "        recalls = cumulative_tp / gt_counter[cls]\n",
    "        precisions = cumulative_tp / np.maximum(cumulative_tp + cumulative_fp, 1)\n",
    "        ap[cls] = compute_average_precision(recalls, precisions)\n",
    "\n",
    "    valid_ap = ap[np.isfinite(ap)]\n",
    "    map_value = float(valid_ap.mean()) if valid_ap.size else 0.0\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"AP\": ap,\n",
    "        \"mAP\": map_value,\n",
    "        \"gt_counter\": gt_counter,\n",
    "    }\n",
    "\n",
    "\n",
    "class SmoothedValue:\n",
    "    def __init__(self, window_size: int = 20) -> None:\n",
    "        self.window_size = window_size\n",
    "        self.deque: List[float] = []\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value: float) -> None:\n",
    "        if len(self.deque) == self.window_size:\n",
    "            self.total -= self.deque.pop(0)\n",
    "        self.deque.append(value)\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "\n",
    "    @property\n",
    "    def avg(self) -> float:\n",
    "        if not self.deque:\n",
    "            return 0.0\n",
    "        return self.total / len(self.deque)\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self) -> None:\n",
    "        self.meters: Dict[str, SmoothedValue] = {}\n",
    "\n",
    "    def update(self, **kwargs: float) -> None:\n",
    "        for name, value in kwargs.items():\n",
    "            if name not in self.meters:\n",
    "                self.meters[name] = SmoothedValue()\n",
    "            self.meters[name].update(float(value))\n",
    "\n",
    "    def format(self) -> str:\n",
    "        parts = [f\"{name}: {meter.avg:.4f}\" for name, meter in self.meters.items()]\n",
    "        return \" | \".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_state_dict(model: nn.Module, path: Path) -> None:\n",
    "    try:\n",
    "        torch.save(model.state_dict(), path)\n",
    "        LOGGER.info(\"Saved pretrained weights to %s\", path)\n",
    "    except Exception as exc:\n",
    "        LOGGER.warning(\"Unable to save pretrained weights: %s\", exc)\n",
    "\n",
    "\n",
    "def _load_pretrained_model(train_cfg: TrainingConfig) -> nn.Module:\n",
    "    pretrained_path = train_cfg.pretrained_weights_path\n",
    "    pretrained_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    weights_enum = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    try:\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=weights_enum)\n",
    "        LOGGER.info(\"Loaded torchvision Faster R-CNN weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            _save_state_dict(model, pretrained_path)\n",
    "        return model\n",
    "    except Exception:\n",
    "        LOGGER.warning(\"Falling back to locally saved pretrained detector weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            raise RuntimeError(\n",
    "                \"No pretrained weights available. Download them manually and place them at \"\n",
    "                + str(pretrained_path)\n",
    "            )\n",
    "        state_dict = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=None)\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> nn.Module:\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = _load_pretrained_model(train_cfg)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    num_classes_with_background = dataset_cfg.num_classes + 1\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num_classes_with_background\n",
    "    )\n",
    "\n",
    "    if train_cfg.small_object:\n",
    "        anchor_generator = AnchorGenerator(\n",
    "            sizes=((16, 32, 64, 128, 256),) * 5,\n",
    "            aspect_ratios=((0.5, 1.0, 2.0),) * 5,\n",
    "        )\n",
    "        model.rpn.anchor_generator = anchor_generator\n",
    "        LOGGER.info(\"Using custom anchor sizes optimised for small objects\")\n",
    "\n",
    "    model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_device(targets: List[Dict[str, torch.Tensor]], device: torch.device) -> List[Dict[str, torch.Tensor]]:\n",
    "    return [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scaler: GradScaler,\n",
    "    device: torch.device,\n",
    "    amp: bool,\n",
    "    log_every: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger()\n",
    "    progress = tqdm(loader, desc=\"Train\", leave=False)\n",
    "\n",
    "    for step, (images, targets) in enumerate(progress, start=1):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = move_to_device(targets, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=amp):\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss_dict.values())\n",
    "\n",
    "        if torch.isfinite(loss):\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            LOGGER.warning(\"Skipping step %s due to non-finite loss\", step)\n",
    "            scaler.update()\n",
    "            continue\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        if step % log_every == 0:\n",
    "            progress.set_postfix_str(metric_logger.format())\n",
    "\n",
    "    return metric_logger.meters.get(\"loss\").avg if metric_logger.meters else 0.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    ") -> Dict[str, torch.Tensor | float | List[float]]:\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    targets_for_eval = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets_device = move_to_device(targets, device)\n",
    "\n",
    "        model.train()\n",
    "        loss_dict = model(images, targets_device)\n",
    "        total_loss += sum(loss_dict.values()).item()\n",
    "        num_batches += 1\n",
    "        model.eval()\n",
    "\n",
    "        outputs = model(images)\n",
    "        for output, target in zip(outputs, targets_device):\n",
    "            scores = output[\"scores\"].detach().cpu().numpy()\n",
    "            keep = scores >= train_cfg.score_threshold\n",
    "            predictions.append(\n",
    "                {\n",
    "                    \"boxes\": output[\"boxes\"].detach().cpu().numpy()[keep],\n",
    "                    \"scores\": scores[keep],\n",
    "                    \"labels\": output[\"labels\"].detach().cpu().numpy()[keep],\n",
    "                }\n",
    "            )\n",
    "            targets_for_eval.append(\n",
    "                {\n",
    "                    \"boxes\": target[\"boxes\"].detach().cpu().numpy(),\n",
    "                    \"labels\": target[\"labels\"].detach().cpu().numpy(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, train_cfg.iou_threshold\n",
    "    )\n",
    "    metrics[\"loss\"] = total_loss / max(num_batches, 1)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_checkpoint(model: nn.Module, path: Path) -> None:\n",
    "    torch.save(model.state_dict(), path)\n",
    "    LOGGER.info(\"Saved checkpoint to %s\", path)\n",
    "\n",
    "\n",
    "def train_pipeline(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    *,\n",
    "    resume_from: Optional[Path] = None,\n",
    ") -> Tuple[nn.Module, List[Dict[str, float]]]:\n",
    "    train_cfg.ensure_directories()\n",
    "    set_seed(train_cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "\n",
    "    if resume_from is not None and Path(resume_from).exists():\n",
    "        LOGGER.info(\"Resuming model weights from %s\", resume_from)\n",
    "        state_dict = torch.load(resume_from, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    train_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.train_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=train_cfg.augmentation,\n",
    "    )\n",
    "    valid_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.valid_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "\n",
    "    train_loader = create_data_loaders(\n",
    "        train_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "    )\n",
    "    valid_loader = create_data_loaders(\n",
    "        valid_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=max(1, train_cfg.num_workers // 2),\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=train_cfg.learning_rate, weight_decay=train_cfg.weight_decay)\n",
    "    scaler = GradScaler(enabled=train_cfg.amp and device.type == \"cuda\")\n",
    "\n",
    "    best_map = -float(\"inf\")\n",
    "    history: List[Dict[str, float]] = []\n",
    "\n",
    "    for epoch in range(1, train_cfg.epochs + 1):\n",
    "        LOGGER.info(\"Epoch %s/%s\", epoch, train_cfg.epochs)\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, scaler, device, train_cfg.amp, train_cfg.log_every\n",
    "        )\n",
    "        LOGGER.info(\"Training loss: %.4f\", train_loss)\n",
    "\n",
    "        if epoch % train_cfg.eval_interval == 0:\n",
    "            metrics = evaluate(model, valid_loader, device, dataset_cfg, train_cfg)\n",
    "            LOGGER.info(\n",
    "                \"Validation loss: %.4f | mAP@%.2f: %.4f\",\n",
    "                metrics[\"loss\"],\n",
    "                train_cfg.iou_threshold,\n",
    "                metrics[\"mAP\"],\n",
    "            )\n",
    "\n",
    "            for cls_idx, (tp, fp, fn, ap) in enumerate(\n",
    "                zip(metrics[\"TP\"], metrics[\"FP\"], metrics[\"FN\"], metrics[\"AP\"])\n",
    "            ):\n",
    "                class_name = dataset_cfg.class_names[cls_idx]\n",
    "                LOGGER.info(\n",
    "                    \"Class %-15s | TP: %3d FP: %3d FN: %3d | Precision: %.3f Recall: %.3f | AP: %s\",\n",
    "                    class_name,\n",
    "                    int(tp),\n",
    "                    int(fp),\n",
    "                    int(fn),\n",
    "                    float(metrics[\"precision\"][cls_idx]),\n",
    "                    float(metrics[\"recall\"][cls_idx]),\n",
    "                    \"nan\" if np.isnan(ap) else f\"{ap:.3f}\",\n",
    "                )\n",
    "\n",
    "            history.append(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": float(train_loss),\n",
    "                    \"val_loss\": float(metrics[\"loss\"]),\n",
    "                    \"mAP\": float(metrics[\"mAP\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if metrics[\"mAP\"] > best_map:\n",
    "                best_map = float(metrics[\"mAP\"])\n",
    "                save_checkpoint(model, train_cfg.checkpoint_path)\n",
    "\n",
    "    (train_cfg.output_dir / \"training_history.json\").write_text(json.dumps(history, indent=2))\n",
    "    LOGGER.info(\"Training complete. Best mAP: %.4f\", best_map)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = [\n",
    "    \"#FF6B6B\",\n",
    "    \"#4ECDC4\",\n",
    "    \"#556270\",\n",
    "    \"#C44D58\",\n",
    "    \"#FFB347\",\n",
    "    \"#6B5B95\",\n",
    "    \"#88B04B\",\n",
    "    \"#92A8D1\",\n",
    "    \"#955251\",\n",
    "    \"#B565A7\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_font() -> ImageFont.FreeTypeFont | ImageFont.ImageFont:\n",
    "    try:\n",
    "        return ImageFont.truetype(\"DejaVuSans.ttf\", size=14)\n",
    "    except Exception:\n",
    "        return ImageFont.load_default()\n",
    "\n",
    "\n",
    "def draw_boxes(\n",
    "    image: np.ndarray,\n",
    "    prediction: Dict[str, np.ndarray],\n",
    "    target: Dict[str, np.ndarray] | None,\n",
    "    class_names: List[str],\n",
    "    score_threshold: float,\n",
    "    draw_ground_truth: bool,\n",
    "    output_path: Path,\n",
    ") -> None:\n",
    "    pil = PILImage.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil)\n",
    "    font = load_font()\n",
    "\n",
    "    colors = DEFAULT_COLORS\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    labels = prediction[\"labels\"].astype(int)\n",
    "    scores = prediction[\"scores\"]\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score < score_threshold:\n",
    "            continue\n",
    "        color = colors[label % len(colors)]\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "        caption = f\"{class_names[label]} {score:.2f}\"\n",
    "        text_size = draw.textlength(caption, font=font)\n",
    "        draw.rectangle([x1, y1 - 16, x1 + text_size + 8, y1], fill=color)\n",
    "        draw.text((x1 + 4, y1 - 14), caption, fill=\"white\", font=font)\n",
    "\n",
    "    if draw_ground_truth and target is not None:\n",
    "        gt_boxes = target[\"boxes\"]\n",
    "        gt_labels = target[\"labels\"].astype(int)\n",
    "        for box, label in zip(gt_boxes, gt_labels):\n",
    "            color = \"#FFFFFF\"\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=color, width=1)\n",
    "            caption = f\"GT {class_names[label]}\"\n",
    "            text_size = draw.textlength(caption, font=font)\n",
    "            draw.rectangle([x1, y2, x1 + text_size + 6, y2 + 14], fill=color)\n",
    "            draw.text((x1 + 3, y2), caption, fill=\"black\", font=font)\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pil.save(output_path)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    inference_cfg: InferenceConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    checkpoint_path: Path,\n",
    "    split: Optional[str] = None,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    inference_cfg.ensure_directories()\n",
    "    set_seed(train_cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=split or dataset_cfg.test_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "    loader = create_data_loaders(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    predictions: List[Dict[str, np.ndarray]] = []\n",
    "    targets_for_eval: List[Dict[str, np.ndarray]] = []\n",
    "\n",
    "    progress = tqdm(loader, desc=\"Infer\")\n",
    "    for idx, (images, targets) in enumerate(progress):\n",
    "        image = images[0].to(device)\n",
    "        output = model([image])[0]\n",
    "\n",
    "        prediction_np = {\n",
    "            \"boxes\": output[\"boxes\"].detach().cpu().numpy(),\n",
    "            \"scores\": output[\"scores\"].detach().cpu().numpy(),\n",
    "            \"labels\": output[\"labels\"].detach().cpu().numpy(),\n",
    "        }\n",
    "        target_np = {\n",
    "            \"boxes\": targets[0][\"boxes\"].detach().cpu().numpy(),\n",
    "            \"labels\": targets[0][\"labels\"].detach().cpu().numpy(),\n",
    "        }\n",
    "\n",
    "        predictions.append(prediction_np)\n",
    "        targets_for_eval.append(target_np)\n",
    "\n",
    "        if idx < inference_cfg.max_images:\n",
    "            image_np = (images[0].permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "            output_path = inference_cfg.output_dir / f\"{split or dataset_cfg.test_split}_{idx:04d}.png\"\n",
    "            draw_boxes(\n",
    "                image_np,\n",
    "                prediction_np,\n",
    "                target_np if inference_cfg.draw_ground_truth else None,\n",
    "                dataset_cfg.class_names,\n",
    "                inference_cfg.score_threshold,\n",
    "                inference_cfg.draw_ground_truth,\n",
    "                output_path,\n",
    "            )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, train_cfg.iou_threshold\n",
    "    )\n",
    "    LOGGER.info(\"mAP@%.2f: %.4f\", train_cfg.iou_threshold, metrics[\"mAP\"])\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration overrides (adjust paths to your Kaggle dataset structure)\n",
    "# dataset_cfg = DatasetConfig(base_dir=Path('/kaggle/input/your-dataset'))\n",
    "# train_cfg = TrainingConfig(epochs=10, batch_size=2, augmentation=True)\n",
    "# inference_cfg = InferenceConfig(score_threshold=0.4, draw_ground_truth=True)\n",
    "\n",
    "# model, history = train_pipeline(dataset_cfg, train_cfg)\n",
    "# metrics = run_inference(\n",
    "#     dataset_cfg,\n",
    "#     inference_cfg,\n",
    "#     train_cfg,\n",
    "#     checkpoint_path=train_cfg.checkpoint_path,\n",
    "# )\n",
    "\n",
    "print(\n",
    "    \"Notebook utilities loaded. Configure DatasetConfig/TrainingConfig and call \"\n",
    "    \"train_pipeline/run_inference as needed.\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}