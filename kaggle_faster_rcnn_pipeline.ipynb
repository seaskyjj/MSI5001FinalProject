{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254ff11c",
   "metadata": {
    "papermill": {
     "duration": 0.004731,
     "end_time": "2025-10-21T07:01:15.851900",
     "exception": false,
     "start_time": "2025-10-21T07:01:15.847169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Electrical Component Detection Pipeline\n",
    "\n",
    "This notebook consolidates the refactored Faster R-CNN training and inference workflow into a single place for convenient experimentation on Kaggle. It provides reusable configuration objects, dataset loaders with optional augmentation, detailed metric utilities (including per-class TP/FP/FN and mAP), and helpers for both training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ea6263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:15.860657Z",
     "iopub.status.busy": "2025-10-21T07:01:15.860399Z",
     "iopub.status.idle": "2025-10-21T07:01:27.269948Z",
     "shell.execute_reply": "2025-10-21T07:01:27.269289Z"
    },
    "papermill": {
     "duration": 11.415509,
     "end_time": "2025-10-21T07:01:27.271402",
     "exception": false,
     "start_time": "2025-10-21T07:01:15.855893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import contextlib\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Mapping, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image as PILImage, ImageDraw, ImageEnhance, ImageFont\n",
    "from torch import Tensor, nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models.detection import (\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "LOGGER = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85042471",
   "metadata": {
    "papermill": {
     "duration": 0.003251,
     "end_time": "2025-10-21T07:01:27.278475",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.275224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e69414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.286115Z",
     "iopub.status.busy": "2025-10-21T07:01:27.285751Z",
     "iopub.status.idle": "2025-10-21T07:01:27.296393Z",
     "shell.execute_reply": "2025-10-21T07:01:27.295821Z"
    },
    "papermill": {
     "duration": 0.015709,
     "end_time": "2025-10-21T07:01:27.297445",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.281736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_PRETRAINED_URL = \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\"\n",
    "\n",
    "#0.999 menas class does not exist\n",
    "DEFAULT_CLASS_SCORE_THRESHOLDS = {\n",
    "    0: 0.3,\n",
    "    3: 0.999,  \n",
    "    6: 0.8,\n",
    "    7: 0.9,\n",
    "    8: 0.999,\n",
    "    12: 0.999,\n",
    "    16: 0.95,\n",
    "    17: 0.999,\n",
    "    20: 0.9,\n",
    "    21: 0.8,\n",
    "    24: 0.999,\n",
    "    25: 0.95,\n",
    "    26: 0.999,\n",
    "    30: 0.95,\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    \"\"\"Configuration describing the dataset layout and metadata.\"\"\"\n",
    "\n",
    "    base_dir: Path = Path(\"data\")\n",
    "    train_split: str = \"train\"\n",
    "    valid_split: str = \"valid\"\n",
    "    test_split: str = \"test\"\n",
    "    image_folder: str = \"images\"\n",
    "    label_folder: str = \"labels\"\n",
    "    num_classes: int = 32\n",
    "    class_names: Tuple[str, ...] = ()\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if not self.class_names:\n",
    "            self.class_names = tuple(f\"class_{idx:02d}\" for idx in range(self.num_classes))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Hyper-parameters and runtime settings for model training.\"\"\"\n",
    "\n",
    "    epochs: int = 24\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 1e-5\n",
    "    weight_decay: float = 1e-5\n",
    "    num_workers: int = 0\n",
    "    amp: bool = True\n",
    "    augmentation: bool = True\n",
    "    small_object: bool = True\n",
    "    score_threshold: float = 0.6\n",
    "    iou_threshold: float = 0.5\n",
    "    eval_interval: int = 1\n",
    "    seed: int = 2024\n",
    "    output_dir: Path = Path(\"outputs\")\n",
    "    checkpoint_path: Path = Path(\"outputs/best_model.pth\")\n",
    "    pretrained_weights_path: Path = Path(\"weights/fasterrcnn_resnet50_fpn_v2_coco.pth\")\n",
    "    pretrained_weights_url: str = DEFAULT_PRETRAINED_URL\n",
    "    log_every: int = 20\n",
    "    class_score_thresholds: Dict[int, float] = field(\n",
    "        default_factory=lambda: DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    )\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.pretrained_weights_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    \"\"\"Options for running model inference and visualisation.\"\"\"\n",
    "\n",
    "    score_threshold: float = 0.6\n",
    "    max_images: int = 50\n",
    "    output_dir: Path = Path(\"outputs/inference\")\n",
    "    draw_ground_truth: bool = True\n",
    "    class_colors: List[str] = field(default_factory=list)\n",
    "    class_score_thresholds: Dict[int, float] = field(\n",
    "        default_factory=lambda: DEFAULT_CLASS_SCORE_THRESHOLDS.copy()\n",
    "    )\n",
    "\n",
    "    def ensure_directories(self) -> None:\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b06fe",
   "metadata": {
    "papermill": {
     "duration": 0.002924,
     "end_time": "2025-10-21T07:01:27.303648",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.300724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset loading and augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9c00ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.310981Z",
     "iopub.status.busy": "2025-10-21T07:01:27.310767Z",
     "iopub.status.idle": "2025-10-21T07:01:27.338390Z",
     "shell.execute_reply": "2025-10-21T07:01:27.337847Z"
    },
    "papermill": {
     "duration": 0.032579,
     "end_time": "2025-10-21T07:01:27.339401",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.306822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationParams:\n",
    "    \"\"\"Parameters controlling the dataset level image augmentations.\"\"\"\n",
    "\n",
    "    horizontal_flip_prob: float = 0.5\n",
    "    vertical_flip_prob: float = 0.2\n",
    "    brightness: float = 0.2\n",
    "    contrast: float = 0.2\n",
    "    saturation: float = 0.2\n",
    "    hue: float = 0.02\n",
    "\n",
    "\n",
    "def load_image_hwc_uint8(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load an ``.npy`` image stored as HWC and return an ``uint8`` array.\"\"\"\n",
    "    image = np.load(path, allow_pickle=False, mmap_mode=\"r\")\n",
    "\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.float32, copy=False)\n",
    "        vmin, vmax = float(image.min()), float(image.max())\n",
    "        if 0.0 <= vmin and vmax <= 1.0:\n",
    "            image = (image * 255.0).round()\n",
    "        elif -1.0 <= vmin and vmax <= 1.0:\n",
    "            image = ((image + 1.0) * 0.5 * 255.0).round()\n",
    "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    channels = image.shape[2]\n",
    "    if channels == 1:\n",
    "        image = np.repeat(image, 3, axis=2)\n",
    "    elif channels == 4:\n",
    "        image = image[..., :3]\n",
    "    return image\n",
    "\n",
    "\n",
    "class ElectricalComponentsDataset(Dataset):\n",
    "    \"\"\"Dataset of electrical component detections stored as ``.npy`` images and CSV labels.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Path,\n",
    "        split: str,\n",
    "        class_names: Iterable[str],\n",
    "        transform: Optional[AugmentationParams] = None,\n",
    "        use_augmentation: bool = False,\n",
    "    ) -> None:\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.class_names = list(class_names)\n",
    "        self.transform_params = transform or AugmentationParams()\n",
    "        self.use_augmentation = use_augmentation\n",
    "\n",
    "        self.image_dir = self.root / split / \"images\"\n",
    "        self.label_dir = self.root / split / \"labels\"\n",
    "\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing image directory: {self.image_dir}\")\n",
    "        if not self.label_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing label directory: {self.label_dir}\")\n",
    "\n",
    "        self.image_stems = sorted(p.stem for p in self.label_dir.glob(\"*.csv\"))\n",
    "        if not self.image_stems:\n",
    "            raise RuntimeError(f\"No label files found in {self.label_dir}\")\n",
    "\n",
    "        # Pre-load all annotations to reduce I/O during training.\n",
    "        self.annotations: Dict[str, pd.DataFrame] = {\n",
    "            stem: pd.read_csv(self.label_dir / f\"{stem}.csv\") for stem in self.image_stems\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_stems)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        stem = self.image_stems[index]\n",
    "        image_path = self.image_dir / f\"{stem}.npy\"\n",
    "        image = load_image_hwc_uint8(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        ann = self.annotations[stem]\n",
    "        x_center = ann[\"x_center\"].to_numpy(dtype=np.float32)\n",
    "        y_center = ann[\"y_center\"].to_numpy(dtype=np.float32)\n",
    "        box_width = ann[\"width\"].to_numpy(dtype=np.float32)\n",
    "        box_height = ann[\"height\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # Auto-detect normalised coordinates and scale back to pixel space.\n",
    "        if (\n",
    "            (x_center.size == 0 or float(x_center.max()) <= 1.0)\n",
    "            and (y_center.size == 0 or float(y_center.max()) <= 1.0)\n",
    "            and (box_width.size == 0 or float(box_width.max()) <= 1.0)\n",
    "            and (box_height.size == 0 or float(box_height.max()) <= 1.0)\n",
    "        ):\n",
    "            x_center *= width\n",
    "            y_center *= height\n",
    "            box_width *= width\n",
    "            box_height *= height\n",
    "\n",
    "        x1 = x_center - box_width / 2.0\n",
    "        y1 = y_center - box_height / 2.0\n",
    "        x2 = x_center + box_width / 2.0\n",
    "        y2 = y_center + box_height / 2.0\n",
    "\n",
    "        boxes = np.stack([x1, y1, x2, y2], axis=1)\n",
    "        labels = ann[\"class\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "        if self.use_augmentation and len(boxes):\n",
    "            image, boxes = self._apply_augmentations(image, boxes)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        boxes_tensor = torch.from_numpy(boxes).float()\n",
    "        labels_tensor = torch.from_numpy(labels).long()\n",
    "\n",
    "        boxes_tensor, labels_tensor = sanitize_boxes_and_labels(\n",
    "            boxes_tensor, labels_tensor, height, width\n",
    "        )\n",
    "\n",
    "        target: Dict[str, torch.Tensor] = {\n",
    "            \"boxes\": boxes_tensor,\n",
    "            \"labels\": labels_tensor,\n",
    "            \"image_id\": torch.tensor(index, dtype=torch.int64),\n",
    "            \"area\": (boxes_tensor[:, 2] - boxes_tensor[:, 0])\n",
    "            * (boxes_tensor[:, 3] - boxes_tensor[:, 1])\n",
    "            if boxes_tensor.numel()\n",
    "            else torch.tensor([], dtype=torch.float32),\n",
    "            \"iscrowd\": torch.zeros((boxes_tensor.shape[0],), dtype=torch.int64),\n",
    "            \"orig_size\": torch.tensor([height, width], dtype=torch.int64),\n",
    "        }\n",
    "\n",
    "        return image_tensor, target\n",
    "\n",
    "    def _apply_augmentations(\n",
    "        self, image: np.ndarray, boxes: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        params = self.transform_params\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        if random.random() < params.horizontal_flip_prob:\n",
    "            image = np.ascontiguousarray(image[:, ::-1, :])\n",
    "            x1 = width - boxes[:, 2]\n",
    "            x2 = width - boxes[:, 0]\n",
    "            boxes[:, 0], boxes[:, 2] = x1, x2\n",
    "\n",
    "        if random.random() < params.vertical_flip_prob:\n",
    "            image = np.ascontiguousarray(image[::-1, :, :])\n",
    "            y1 = height - boxes[:, 3]\n",
    "            y2 = height - boxes[:, 1]\n",
    "            boxes[:, 1], boxes[:, 3] = y1, y2\n",
    "\n",
    "        if params.brightness or params.contrast or params.saturation or params.hue:\n",
    "            pil = PILImage.fromarray(image)\n",
    "            if params.brightness:\n",
    "                enhancer = ImageEnhance.Brightness(pil)\n",
    "                factor = 1.0 + random.uniform(-params.brightness, params.brightness)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.contrast:\n",
    "                enhancer = ImageEnhance.Contrast(pil)\n",
    "                factor = 1.0 + random.uniform(-params.contrast, params.contrast)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.saturation:\n",
    "                enhancer = ImageEnhance.Color(pil)\n",
    "                factor = 1.0 + random.uniform(-params.saturation, params.saturation)\n",
    "                pil = enhancer.enhance(max(0.1, factor))\n",
    "            if params.hue:\n",
    "                hsv_image = pil.convert(\"HSV\")\n",
    "                h_channel, s_channel, v_channel = hsv_image.split()\n",
    "                delta = int(params.hue * 255.0 * random.choice([-1, 1]))\n",
    "                h_channel = h_channel.point(lambda h: (h + delta) % 255)\n",
    "                hsv_image = PILImage.merge(\"HSV\", (h_channel, s_channel, v_channel))\n",
    "                pil = hsv_image.convert(\"RGB\")\n",
    "                # Hue adjustment via simple conversion to HSV.\n",
    "            image = np.array(pil)\n",
    "\n",
    "        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, width)\n",
    "        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, height)\n",
    "        return image, boxes\n",
    "\n",
    "\n",
    "def detection_collate(batch: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]):\n",
    "    \"\"\"Collate function for detection datasets returning lists of tensors.\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "\n",
    "def _safe_worker_count(requested: int) -> int:\n",
    "    cpu_count = os.cpu_count() or 1\n",
    "    if requested <= 0:\n",
    "        return 0\n",
    "    max_workers = max(1, cpu_count - 1)\n",
    "    return min(requested, max_workers)\n",
    "def _running_in_ipython_kernel() -> bool:\n",
    "    \"\"\"Return ``True`` when executing inside an IPython/Jupyter kernel.\"\"\"\n",
    "\n",
    "    try:  # ``IPython`` is an optional dependency in our runtime.\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "    except Exception:  # pragma: no cover - depends on environment\n",
    "        return False\n",
    "\n",
    "    shell = get_ipython()\n",
    "    return bool(shell and getattr(shell, \"kernel\", None))\n",
    "\n",
    "\n",
    "def emit_metric_lines(\n",
    "    lines: Sequence[str],\n",
    "    *,\n",
    "    logger: Optional[logging.Logger] = None,\n",
    "    force_print: Optional[bool] = None,\n",
    ") -> None:\n",
    "    \"\"\"Log metric lines and optionally mirror them with ``print`` output.\"\"\"\n",
    "\n",
    "    if logger is None:\n",
    "        logger = LOGGER\n",
    "\n",
    "    should_print = force_print if force_print is not None else _running_in_ipython_kernel()\n",
    "\n",
    "    for line in lines:\n",
    "        if logger is not None:\n",
    "            logger.info(line)\n",
    "        if should_print:\n",
    "            print(line)\n",
    "\n",
    "\n",
    "def _should_force_single_worker(dataset: Dataset) -> bool:\n",
    "    \"\"\"Determine whether multiprocessing workers should be disabled.\"\"\"\n",
    "\n",
    "    module_name = getattr(dataset.__class__, \"__module__\", \"\")\n",
    "    if module_name in {\"__main__\", \"__mp_main__\", \"builtins\"}:\n",
    "        return True\n",
    "\n",
    "    if module_name.startswith(\"ipykernel\"):  # pragma: no cover - notebook specific\n",
    "        return True\n",
    "\n",
    "    return _running_in_ipython_kernel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_data_loaders(\n",
    "    dataset: Dataset,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    num_workers: int,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Create a :class:`torch.utils.data.DataLoader` with notebook friendly defaults.\"\"\"\n",
    "\n",
    "    worker_count = _safe_worker_count(num_workers)\n",
    "    if worker_count > 0 and _should_force_single_worker(dataset):\n",
    "        LOGGER.info(\n",
    "            \"Detected interactive environment or in-notebook dataset definition; forcing num_workers=0.\"\n",
    "        )\n",
    "        worker_count = 0\n",
    "    loader_kwargs = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=detection_collate,\n",
    "    )\n",
    "\n",
    "    if worker_count > 0:\n",
    "        loader_kwargs[\"num_workers\"] = worker_count\n",
    "        loader_kwargs[\"persistent_workers\"] = True\n",
    "        loader_kwargs[\"multiprocessing_context\"] = mp.get_context(\"spawn\")\n",
    "    else:\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "\n",
    "    try:\n",
    "        return DataLoader(**loader_kwargs)\n",
    "    except (RuntimeError, OSError, AssertionError) as exc:\n",
    "        if worker_count == 0:\n",
    "            raise\n",
    "        warnings.warn(\n",
    "            \"Falling back to num_workers=0 because DataLoader worker initialisation \"\n",
    "            f\"failed with: {exc}\",\n",
    "            RuntimeWarning,\n",
    "        )\n",
    "        LOGGER.warning(\"DataLoader workers failed to start (%s). Using num_workers=0 instead.\", exc)\n",
    "        loader_kwargs.pop(\"persistent_workers\", None)\n",
    "        loader_kwargs.pop(\"multiprocessing_context\", None)\n",
    "        loader_kwargs[\"num_workers\"] = 0\n",
    "        return DataLoader(**loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e689c",
   "metadata": {
    "papermill": {
     "duration": 0.002974,
     "end_time": "2025-10-21T07:01:27.345614",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.342640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility helpers and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3637ad51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.353389Z",
     "iopub.status.busy": "2025-10-21T07:01:27.353214Z",
     "iopub.status.idle": "2025-10-21T07:01:27.378943Z",
     "shell.execute_reply": "2025-10-21T07:01:27.378326Z"
    },
    "papermill": {
     "duration": 0.030954,
     "end_time": "2025-10-21T07:01:27.379919",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.348965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def sanitize_boxes_and_labels(\n",
    "    boxes: Tensor, labels: Tensor, height: int, width: int, min_size: float = 1.0\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    if boxes.numel() == 0:\n",
    "        return boxes.reshape(0, 4).float(), labels.reshape(0).long()\n",
    "\n",
    "    boxes = boxes.clone()\n",
    "    boxes[:, 0::2] = boxes[:, 0::2].clamp(0, float(width))\n",
    "    boxes[:, 1::2] = boxes[:, 1::2].clamp(0, float(height))\n",
    "\n",
    "    widths = boxes[:, 2] - boxes[:, 0]\n",
    "    heights = boxes[:, 3] - boxes[:, 1]\n",
    "    keep = (widths > min_size) & (heights > min_size)\n",
    "\n",
    "    if keep.sum() == 0:\n",
    "        return boxes.new_zeros((0, 4)), labels.new_zeros((0,), dtype=torch.long)\n",
    "    return boxes[keep].float(), labels[keep].long()\n",
    "\n",
    "\n",
    "def compute_iou_matrix(boxes1: np.ndarray, boxes2: np.ndarray) -> np.ndarray:\n",
    "    if boxes1.size == 0 or boxes2.size == 0:\n",
    "        return np.zeros((boxes1.shape[0], boxes2.shape[0]), dtype=np.float32)\n",
    "\n",
    "    x11, y11, x12, y12 = np.split(boxes1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(boxes2, 4, axis=1)\n",
    "\n",
    "    inter_x1 = np.maximum(x11, x21.T)\n",
    "    inter_y1 = np.maximum(y11, y21.T)\n",
    "    inter_x2 = np.minimum(x12, x22.T)\n",
    "    inter_y2 = np.minimum(y12, y22.T)\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, a_min=0.0, a_max=None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, a_min=0.0, a_max=None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area1 = (x12 - x11) * (y12 - y11)\n",
    "    area2 = (x22 - x21) * (y22 - y21)\n",
    "\n",
    "    union = area1 + area2.T - inter_area\n",
    "    return np.divide(inter_area, union, out=np.zeros_like(inter_area), where=union > 0)\n",
    "\n",
    "\n",
    "def compute_average_precision(recalls: np.ndarray, precisions: np.ndarray) -> float:\n",
    "    if recalls.size == 0 or precisions.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    mrec = np.concatenate(([0.0], recalls, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precisions, [0.0]))\n",
    "\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "\n",
    "    recall_points = np.linspace(0, 1, 101)\n",
    "    precision_interp = np.interp(recall_points, mrec, mpre)\n",
    "    return float(np.trapz(precision_interp, recall_points))\n",
    "\n",
    "\n",
    "def accumulate_classification_stats(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[List[float]], List[List[int]], np.ndarray]:\n",
    "    tp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fp = np.zeros(num_classes, dtype=np.int64)\n",
    "    fn = np.zeros(num_classes, dtype=np.int64)\n",
    "    scores: List[List[float]] = [[] for _ in range(num_classes)]\n",
    "    matches: List[List[int]] = [[] for _ in range(num_classes)]\n",
    "    gt_counter = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    for pred, tgt in zip(predictions, targets):\n",
    "        pred_boxes = pred[\"boxes\"]\n",
    "        pred_scores = pred[\"scores\"]\n",
    "        pred_labels = pred[\"labels\"].astype(np.int64)\n",
    "\n",
    "        gt_boxes = tgt[\"boxes\"]\n",
    "        gt_labels = tgt[\"labels\"].astype(np.int64)\n",
    "\n",
    "        unique_classes = np.unique(np.concatenate((pred_labels, gt_labels)))\n",
    "        for cls in unique_classes:\n",
    "            pb = pred_boxes[pred_labels == cls]\n",
    "            ps = pred_scores[pred_labels == cls]\n",
    "            tb = gt_boxes[gt_labels == cls]\n",
    "            gt_counter[cls] += len(tb)\n",
    "\n",
    "            if len(tb) == 0:\n",
    "                fp[cls] += len(pb)\n",
    "                scores[cls].extend(ps.tolist())\n",
    "                matches[cls].extend([0] * len(pb))\n",
    "                continue\n",
    "\n",
    "            order = np.argsort(-ps)\n",
    "            pb = pb[order]\n",
    "            ps = ps[order]\n",
    "            iou_matrix = compute_iou_matrix(pb, tb)\n",
    "\n",
    "            matched_gt: set[int] = set()\n",
    "            for det_idx, score in enumerate(ps):\n",
    "                if tb.size == 0:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "                    continue\n",
    "\n",
    "                best_gt = int(np.argmax(iou_matrix[det_idx]))\n",
    "                best_iou = iou_matrix[det_idx, best_gt]\n",
    "\n",
    "                if best_iou >= iou_threshold and best_gt not in matched_gt:\n",
    "                    tp[cls] += 1\n",
    "                    matched_gt.add(best_gt)\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(1)\n",
    "                else:\n",
    "                    fp[cls] += 1\n",
    "                    scores[cls].append(float(score))\n",
    "                    matches[cls].append(0)\n",
    "\n",
    "            fn[cls] += len(tb) - len(matched_gt)\n",
    "\n",
    "    return tp, fp, fn, scores, matches, gt_counter\n",
    "\n",
    "\n",
    "def compute_detection_metrics(\n",
    "    predictions: Sequence[Dict[str, np.ndarray]],\n",
    "    targets: Sequence[Dict[str, np.ndarray]],\n",
    "    num_classes: int,\n",
    "    iou_threshold: float,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    tp, fp, fn, scores, matches, gt_counter = accumulate_classification_stats(\n",
    "        predictions, targets, num_classes, iou_threshold\n",
    "    )\n",
    "\n",
    "    precision = np.divide(tp, np.clip(tp + fp, a_min=1, a_max=None))\n",
    "    recall = np.divide(tp, np.clip(tp + fn, a_min=1, a_max=None))\n",
    "\n",
    "    ap = np.zeros(num_classes, dtype=np.float32)\n",
    "    for cls in range(num_classes):\n",
    "        if gt_counter[cls] == 0:\n",
    "            ap[cls] = np.nan\n",
    "            continue\n",
    "        if not scores[cls]:\n",
    "            ap[cls] = 0.0\n",
    "            continue\n",
    "\n",
    "        order = np.argsort(-np.asarray(scores[cls]))\n",
    "        match_array = np.asarray(matches[cls], dtype=np.int32)[order]\n",
    "        cumulative_tp = np.cumsum(match_array)\n",
    "        cumulative_fp = np.cumsum(1 - match_array)\n",
    "\n",
    "        recalls = cumulative_tp / gt_counter[cls]\n",
    "        precisions = cumulative_tp / np.maximum(cumulative_tp + cumulative_fp, 1)\n",
    "        ap[cls] = compute_average_precision(recalls, precisions)\n",
    "\n",
    "    valid_ap = ap[np.isfinite(ap)]\n",
    "    map_value = float(valid_ap.mean()) if valid_ap.size else 0.0\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"AP\": ap,\n",
    "        \"mAP\": map_value,\n",
    "        \"gt_counter\": gt_counter,\n",
    "    }\n",
    "\n",
    "\n",
    "class SmoothedValue:\n",
    "    def __init__(self, window_size: int = 20) -> None:\n",
    "        self.window_size = window_size\n",
    "        self.deque: List[float] = []\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value: float) -> None:\n",
    "        if len(self.deque) == self.window_size:\n",
    "            self.total -= self.deque.pop(0)\n",
    "        self.deque.append(value)\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "\n",
    "    @property\n",
    "    def avg(self) -> float:\n",
    "        if not self.deque:\n",
    "            return 0.0\n",
    "        return self.total / len(self.deque)\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self) -> None:\n",
    "        self.meters: Dict[str, SmoothedValue] = {}\n",
    "\n",
    "    def update(self, **kwargs: float) -> None:\n",
    "        for name, value in kwargs.items():\n",
    "            if name not in self.meters:\n",
    "                self.meters[name] = SmoothedValue()\n",
    "            self.meters[name].update(float(value))\n",
    "\n",
    "    def format(self) -> str:\n",
    "        parts = [f\"{name}: {meter.avg:.4f}\" for name, meter in self.meters.items()]\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "def score_threshold_mask(\n",
    "    scores: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    default_threshold: float,\n",
    "    class_thresholds: Mapping[int, float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return a boolean mask keeping predictions that pass per-class thresholds.\"\"\"\n",
    "\n",
    "    if scores.size == 0:\n",
    "        return np.zeros_like(scores, dtype=bool)\n",
    "\n",
    "    thresholds = np.full(scores.shape, default_threshold, dtype=scores.dtype)\n",
    "    if class_thresholds:\n",
    "        labels_int = labels.astype(np.int64, copy=False)\n",
    "        for cls, value in class_thresholds.items():\n",
    "            thresholds[labels_int == int(cls)] = float(value)\n",
    "\n",
    "    return scores >= thresholds\n",
    "\n",
    "\n",
    "def parse_class_threshold_entries(entries: Sequence[str]) -> Dict[int, float]:\n",
    "    \"\"\"Parse `CLS=THRESH` strings into a mapping of per-class thresholds.\"\"\"\n",
    "\n",
    "    thresholds: Dict[int, float] = {}\n",
    "    for entry in entries:\n",
    "        if not entry:\n",
    "            continue\n",
    "\n",
    "        if \"=\" in entry:\n",
    "            key, value = entry.split(\"=\", 1)\n",
    "        elif \":\" in entry:\n",
    "            key, value = entry.split(\":\", 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid class threshold format: {entry!r}\")\n",
    "\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        if not key or not value:\n",
    "            raise ValueError(f\"Invalid class threshold entry: {entry!r}\")\n",
    "\n",
    "        thresholds[int(key)] = float(value)\n",
    "\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca99e12",
   "metadata": {
    "papermill": {
     "duration": 0.003005,
     "end_time": "2025-10-21T07:01:27.386218",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.383213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07e4d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.393604Z",
     "iopub.status.busy": "2025-10-21T07:01:27.393381Z",
     "iopub.status.idle": "2025-10-21T07:01:27.401990Z",
     "shell.execute_reply": "2025-10-21T07:01:27.401426Z"
    },
    "papermill": {
     "duration": 0.013596,
     "end_time": "2025-10-21T07:01:27.403015",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.389419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "\n",
    "def _save_state_dict(model: nn.Module, path: Path) -> None:\n",
    "    try:\n",
    "        torch.save(model.state_dict(), path)\n",
    "        LOGGER.info(\"Saved pretrained weights to %s\", path)\n",
    "    except Exception as exc:\n",
    "        LOGGER.warning(\"Unable to save pretrained weights: %s\", exc)\n",
    "\n",
    "\n",
    "def _load_pretrained_model(train_cfg: TrainingConfig) -> nn.Module:\n",
    "    pretrained_path = train_cfg.pretrained_weights_path\n",
    "    pretrained_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    weights_enum = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    try:\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=weights_enum)\n",
    "        LOGGER.info(\"Loaded torchvision Faster R-CNN weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            _save_state_dict(model, pretrained_path)\n",
    "        return model\n",
    "    except Exception:\n",
    "        LOGGER.warning(\"Falling back to locally saved pretrained detector weights\")\n",
    "        if not pretrained_path.exists():\n",
    "            raise RuntimeError(\n",
    "                \"No pretrained weights available. Download them manually and place them at \"\n",
    "                + str(pretrained_path)\n",
    "            )\n",
    "        state_dict = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=None)\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    device: Optional[torch.device] = None,\n",
    ") -> nn.Module:\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = _load_pretrained_model(train_cfg)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    num_classes_with_background = dataset_cfg.num_classes + 1\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num_classes_with_background\n",
    "    )\n",
    "    \n",
    "    if train_cfg.small_object:\n",
    "        anchor_generator = AnchorGenerator(\n",
    "            #sizes=((16,), (32,), (64,), (128,), (256,)),\n",
    "            #aspect_ratios=((0.2, 0.5, 1.0, 2.0, 5.0),) * 5,\n",
    "            sizes=((16, 24), (32, 48), (64, 96), (128, 192), (256, 384)),\n",
    "            aspect_ratios=((0.2, 0.5, 1.0, 2.0, 5.0),) * 5\n",
    "        )\n",
    "        model.rpn.anchor_generator = anchor_generator\n",
    "        LOGGER.info(\"Using custom anchor sizes optimised for small objects\")\n",
    "\n",
    "        # 1. 从旧的 RPNHead 中获取 in_channels\n",
    "        in_channels = model.rpn.head.cls_logits.in_channels\n",
    "\n",
    "        # 2. 从新的 AnchorGenerator 获取每个位置的锚框数\n",
    "        #    (例如，5 个 aspect_ratios * 2 个 sizes = 10)\n",
    "        num_anchors_per_location = anchor_generator.num_anchors_per_location()[0]\n",
    "    \n",
    "        # 3. 创建并替换 RPNHead\n",
    "        new_head = RPNHead(in_channels, num_anchors_per_location)\n",
    "        model.rpn.head = new_head\n",
    "        LOGGER.info(\n",
    "            \"Re-created RPN head for %d anchors per location to match AnchorGenerator.\",\n",
    "            num_anchors_per_location\n",
    "        )\n",
    "        \n",
    "    model.to(device)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb051f6",
   "metadata": {
    "papermill": {
     "duration": 0.003072,
     "end_time": "2025-10-21T07:01:27.409284",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.406212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820377d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.416584Z",
     "iopub.status.busy": "2025-10-21T07:01:27.416371Z",
     "iopub.status.idle": "2025-10-21T07:01:27.440605Z",
     "shell.execute_reply": "2025-10-21T07:01:27.440046Z"
    },
    "papermill": {
     "duration": 0.029234,
     "end_time": "2025-10-21T07:01:27.441714",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.412480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_to_device(targets: List[Dict[str, torch.Tensor]], device: torch.device) -> List[Dict[str, torch.Tensor]]:\n",
    "    return [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scaler: GradScaler,\n",
    "    device: torch.device,\n",
    "    amp: bool,\n",
    "    log_every: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger()\n",
    "    progress = tqdm(loader, desc=\"Train\", leave=False)\n",
    "\n",
    "    for step, (images, targets) in enumerate(progress, start=1):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = move_to_device(targets, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        autocast_enabled = amp and device.type == \"cuda\"\n",
    "        autocast_context = (\n",
    "            torch.amp.autocast(device_type=\"cuda\") if autocast_enabled else contextlib.nullcontext()\n",
    "        )\n",
    "        with autocast_context:\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss_dict.values())\n",
    "\n",
    "        if torch.isfinite(loss):\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            LOGGER.warning(\"Skipping step %s due to non-finite loss\", step)\n",
    "            scaler.update()\n",
    "            continue\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        if step % log_every == 0:\n",
    "            progress.set_postfix_str(metric_logger.format())\n",
    "\n",
    "    return metric_logger.meters.get(\"loss\").avg if metric_logger.meters else 0.0\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    ") -> Dict[str, torch.Tensor | float | List[float]]:\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    targets_for_eval = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets_device = move_to_device(targets, device)\n",
    "\n",
    "        model.train()\n",
    "        loss_dict = model(images, targets_device)\n",
    "        total_loss += sum(loss_dict.values()).item()\n",
    "        num_batches += 1\n",
    "        model.eval()\n",
    "\n",
    "        outputs = model(images)\n",
    "        for output, target in zip(outputs, targets_device):\n",
    "            scores = output[\"scores\"].detach().cpu().numpy()\n",
    "            labels = output[\"labels\"].detach().cpu().numpy()\n",
    "            keep = score_threshold_mask(\n",
    "                scores,\n",
    "                labels,\n",
    "                train_cfg.score_threshold,\n",
    "                train_cfg.class_score_thresholds,\n",
    "            )\n",
    "            predictions.append(\n",
    "                {\n",
    "                    \"boxes\": output[\"boxes\"].detach().cpu().numpy()[keep],\n",
    "                    \"scores\": scores[keep],\n",
    "                    \"labels\": labels[keep],\n",
    "                }\n",
    "            )\n",
    "            targets_for_eval.append(\n",
    "                {\n",
    "                    \"boxes\": target[\"boxes\"].detach().cpu().numpy(),\n",
    "                    \"labels\": target[\"labels\"].detach().cpu().numpy(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, train_cfg.iou_threshold\n",
    "    )\n",
    "    metrics[\"loss\"] = total_loss / max(num_batches, 1)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _resolve_class_label(dataset_cfg: DatasetConfig, index: int) -> str:\n",
    "    if index < len(dataset_cfg.class_names):\n",
    "        label = dataset_cfg.class_names[index]\n",
    "    else:\n",
    "        label = f\"class_{index:02d}\"\n",
    "\n",
    "    if label.startswith(\"class_\") and label[6:].isdigit():\n",
    "        return f\"class {int(label[6:]):02d}\"\n",
    "    return label\n",
    "\n",
    "\n",
    "def format_epoch_metrics(\n",
    "    epoch: Optional[int],\n",
    "    train_loss: Optional[float],\n",
    "    metrics: Dict[str, torch.Tensor | float | List[float]],\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    *,\n",
    "    header: Optional[str] = None,\n",
    ") -> List[str]:\n",
    "    lines: List[str] = []\n",
    "\n",
    "    val_loss = float(metrics.get(\"loss\", float(\"nan\")))\n",
    "    map_value = float(metrics.get(\"mAP\", float(\"nan\")))\n",
    "\n",
    "    if header is not None:\n",
    "        summary = header\n",
    "    elif epoch is not None:\n",
    "        summary = f\"Epoch {epoch:02d}\"\n",
    "    else:\n",
    "        summary = \"Metrics\"\n",
    "\n",
    "    if train_loss is not None and np.isfinite(train_loss):\n",
    "        summary += f\" | train loss {train_loss:.4f}\"\n",
    "    if np.isfinite(val_loss):\n",
    "        summary += f\" | val loss {val_loss:.4f}\"\n",
    "    if np.isfinite(map_value):\n",
    "        summary += f\" | mAP {map_value:.4f}\"\n",
    "    lines.append(summary)\n",
    "\n",
    "    precision = np.asarray(metrics.get(\"precision\", []), dtype=float)\n",
    "    recall = np.asarray(metrics.get(\"recall\", []), dtype=float)\n",
    "    tp = np.asarray(metrics.get(\"TP\", []), dtype=int)\n",
    "    fp = np.asarray(metrics.get(\"FP\", []), dtype=int)\n",
    "    fn = np.asarray(metrics.get(\"FN\", []), dtype=int)\n",
    "    ap = np.asarray(metrics.get(\"AP\", []), dtype=float)\n",
    "    gt_counter = np.asarray(metrics.get(\"gt_counter\", np.zeros_like(tp)), dtype=int)\n",
    "\n",
    "    num_classes = min(len(tp), dataset_cfg.num_classes)\n",
    "    for cls_idx in range(num_classes):\n",
    "        gt_value = int(gt_counter[cls_idx]) if gt_counter.size > cls_idx else 0\n",
    "        tp_value = int(tp[cls_idx]) if tp.size > cls_idx else 0\n",
    "        fp_value = int(fp[cls_idx]) if fp.size > cls_idx else 0\n",
    "        fn_value = int(fn[cls_idx]) if fn.size > cls_idx else 0\n",
    "\n",
    "        if gt_value == 0 and tp_value == 0 and fp_value == 0 and fn_value == 0:\n",
    "            continue\n",
    "\n",
    "        label = _resolve_class_label(dataset_cfg, cls_idx)\n",
    "        if precision.size > cls_idx:\n",
    "            p_val = float(np.nan_to_num(precision[cls_idx], nan=0.0))\n",
    "        else:\n",
    "            p_val = 0.0\n",
    "        if recall.size > cls_idx:\n",
    "            r_val = float(np.nan_to_num(recall[cls_idx], nan=0.0))\n",
    "        else:\n",
    "            r_val = 0.0\n",
    "\n",
    "        line = f\"{label} | P={p_val:.3f} R={r_val:.3f}  TP={tp_value} FP={fp_value} FN={fn_value}\"\n",
    "        if ap.size > cls_idx and np.isfinite(ap[cls_idx]):\n",
    "            line += f\" AP={ap[cls_idx]:.3f}\"\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def save_checkpoint(model: nn.Module, path: Path) -> None:\n",
    "    torch.save(model.state_dict(), path)\n",
    "    LOGGER.info(\"Saved checkpoint to %s\", path)\n",
    "\n",
    "\n",
    "def train_pipeline(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    *,\n",
    "    resume_from: Optional[Path] = None,\n",
    ") -> Tuple[nn.Module, List[Dict[str, float]]]:\n",
    "    train_cfg.ensure_directories()\n",
    "    set_seed(train_cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "\n",
    "    if resume_from is not None and Path(resume_from).exists():\n",
    "        LOGGER.info(\"Resuming model weights from %s\", resume_from)\n",
    "        state_dict = torch.load(resume_from, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    train_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.train_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=train_cfg.augmentation,\n",
    "    )\n",
    "    valid_dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=dataset_cfg.valid_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "\n",
    "    train_loader = create_data_loaders(\n",
    "        train_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=train_cfg.num_workers,\n",
    "    )\n",
    "    if train_cfg.num_workers > 1:\n",
    "        valid_workers = max(1, train_cfg.num_workers // 2)\n",
    "    else:\n",
    "        valid_workers = train_cfg.num_workers\n",
    "\n",
    "    valid_loader = create_data_loaders(\n",
    "        valid_dataset,\n",
    "        batch_size=train_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=valid_workers,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=train_cfg.learning_rate, weight_decay=train_cfg.weight_decay)\n",
    "    scaler = GradScaler(enabled=train_cfg.amp and device.type == \"cuda\")\n",
    "\n",
    "    best_map = -float(\"inf\")\n",
    "    history: List[Dict[str, float]] = []\n",
    "\n",
    "    for epoch in range(1, train_cfg.epochs + 1):\n",
    "        LOGGER.info(\"Epoch %s/%s\", epoch, train_cfg.epochs)\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, scaler, device, train_cfg.amp, train_cfg.log_every\n",
    "        )\n",
    "\n",
    "        if epoch % train_cfg.eval_interval == 0:\n",
    "            metrics = evaluate(model, valid_loader, device, dataset_cfg, train_cfg)\n",
    "            metric_lines = format_epoch_metrics(epoch, train_loss, metrics, dataset_cfg)\n",
    "            emit_metric_lines(metric_lines, logger=LOGGER)\n",
    "\n",
    "            history.append(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": float(train_loss),\n",
    "                    \"val_loss\": float(metrics[\"loss\"]),\n",
    "                    \"mAP\": float(metrics[\"mAP\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if metrics[\"mAP\"] > best_map:\n",
    "                best_map = float(metrics[\"mAP\"])\n",
    "                save_checkpoint(model, train_cfg.checkpoint_path)\n",
    "        else:\n",
    "            LOGGER.info(\n",
    "                \"Epoch %02d | train loss %.4f | evaluation skipped (eval_interval=%d)\",\n",
    "                epoch,\n",
    "                train_loss,\n",
    "                train_cfg.eval_interval,\n",
    "            )\n",
    "\n",
    "    (train_cfg.output_dir / \"training_history.json\").write_text(json.dumps(history, indent=2))\n",
    "    LOGGER.info(\"Training complete. Best mAP: %.4f\", best_map)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6760e",
   "metadata": {
    "papermill": {
     "duration": 0.003126,
     "end_time": "2025-10-21T07:01:27.448074",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.444948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f63ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.455528Z",
     "iopub.status.busy": "2025-10-21T07:01:27.455315Z",
     "iopub.status.idle": "2025-10-21T07:01:27.470282Z",
     "shell.execute_reply": "2025-10-21T07:01:27.469714Z"
    },
    "papermill": {
     "duration": 0.020147,
     "end_time": "2025-10-21T07:01:27.471429",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.451282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = [\n",
    "    \"#FF6B6B\",\n",
    "    \"#4ECDC4\",\n",
    "    \"#556270\",\n",
    "    \"#C44D58\",\n",
    "    \"#FFB347\",\n",
    "    \"#6B5B95\",\n",
    "    \"#88B04B\",\n",
    "    \"#92A8D1\",\n",
    "    \"#955251\",\n",
    "    \"#B565A7\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_font() -> ImageFont.FreeTypeFont | ImageFont.ImageFont:\n",
    "    try:\n",
    "        return ImageFont.truetype(\"DejaVuSans.ttf\", size=14)\n",
    "    except Exception:\n",
    "        return ImageFont.load_default()\n",
    "\n",
    "\n",
    "def draw_boxes(\n",
    "    image: np.ndarray,\n",
    "    prediction: Dict[str, np.ndarray],\n",
    "    target: Dict[str, np.ndarray] | None,\n",
    "    class_names: List[str],\n",
    "    score_threshold: float,\n",
    "    class_thresholds: Dict[int, float],\n",
    "    draw_ground_truth: bool,\n",
    "    output_path: Path,\n",
    ") -> None:\n",
    "    pil = PILImage.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil)\n",
    "    font = load_font()\n",
    "\n",
    "    colors = DEFAULT_COLORS\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    labels = prediction[\"labels\"].astype(int)\n",
    "    scores = prediction[\"scores\"]\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        threshold = class_thresholds.get(int(label), score_threshold)\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        color = colors[label % len(colors)]\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "        caption = f\"{class_names[label]} {score:.2f}\"\n",
    "        text_size = draw.textlength(caption, font=font)\n",
    "        draw.rectangle([x1, y1 - 16, x1 + text_size + 8, y1], fill=color)\n",
    "        draw.text((x1 + 4, y1 - 14), caption, fill=\"white\", font=font)\n",
    "\n",
    "    if draw_ground_truth and target is not None:\n",
    "        gt_boxes = target[\"boxes\"]\n",
    "        gt_labels = target[\"labels\"].astype(int)\n",
    "        for box, label in zip(gt_boxes, gt_labels):\n",
    "            color = \"#FFFFFF\"\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=color, width=1)\n",
    "            caption = f\"GT {class_names[label]}\"\n",
    "            text_size = draw.textlength(caption, font=font)\n",
    "            draw.rectangle([x1, y2, x1 + text_size + 6, y2 + 14], fill=color)\n",
    "            draw.text((x1 + 3, y2), caption, fill=\"black\", font=font)\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pil.save(output_path)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_inference(\n",
    "    dataset_cfg: DatasetConfig,\n",
    "    inference_cfg: InferenceConfig,\n",
    "    train_cfg: TrainingConfig,\n",
    "    checkpoint_path: Path,\n",
    "    split: Optional[str] = None,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    inference_cfg.ensure_directories()\n",
    "    set_seed(train_cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(dataset_cfg, train_cfg, device=device)\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = ElectricalComponentsDataset(\n",
    "        root=dataset_cfg.base_dir,\n",
    "        split=split or dataset_cfg.test_split,\n",
    "        class_names=dataset_cfg.class_names,\n",
    "        use_augmentation=False,\n",
    "    )\n",
    "    loader = create_data_loaders(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    predictions: List[Dict[str, np.ndarray]] = []\n",
    "    targets_for_eval: List[Dict[str, np.ndarray]] = []\n",
    "\n",
    "    progress = tqdm(loader, desc=\"Infer\")\n",
    "    for idx, (images, targets) in enumerate(progress):\n",
    "        image = images[0].to(device)\n",
    "        output = model([image])[0]\n",
    "\n",
    "        boxes_np = output[\"boxes\"].detach().cpu().numpy()\n",
    "        scores_np = output[\"scores\"].detach().cpu().numpy()\n",
    "        labels_np = output[\"labels\"].detach().cpu().numpy()\n",
    "        keep = score_threshold_mask(\n",
    "            scores_np,\n",
    "            labels_np,\n",
    "            inference_cfg.score_threshold,\n",
    "            inference_cfg.class_score_thresholds,\n",
    "        )\n",
    "        prediction_np = {\n",
    "            \"boxes\": boxes_np[keep],\n",
    "            \"scores\": scores_np[keep],\n",
    "            \"labels\": labels_np[keep],\n",
    "        }\n",
    "        target_np = {\n",
    "            \"boxes\": targets[0][\"boxes\"].detach().cpu().numpy(),\n",
    "            \"labels\": targets[0][\"labels\"].detach().cpu().numpy(),\n",
    "        }\n",
    "\n",
    "        predictions.append(prediction_np)\n",
    "        targets_for_eval.append(target_np)\n",
    "\n",
    "        if idx < inference_cfg.max_images:\n",
    "            image_np = (images[0].permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "            output_path = inference_cfg.output_dir / f\"{split or dataset_cfg.test_split}_{idx:04d}.png\"\n",
    "            draw_boxes(\n",
    "                image_np,\n",
    "                prediction_np,\n",
    "                target_np if inference_cfg.draw_ground_truth else None,\n",
    "                dataset_cfg.class_names,\n",
    "                inference_cfg.score_threshold,\n",
    "                inference_cfg.class_score_thresholds,\n",
    "                inference_cfg.draw_ground_truth,\n",
    "                output_path,\n",
    "            )\n",
    "\n",
    "    metrics = compute_detection_metrics(\n",
    "        predictions, targets_for_eval, dataset_cfg.num_classes, train_cfg.iou_threshold\n",
    "    )\n",
    "    metric_lines = format_epoch_metrics(\n",
    "        epoch=None,\n",
    "        train_loss=None,\n",
    "        metrics=metrics,\n",
    "        dataset_cfg=dataset_cfg,\n",
    "        header=f\"Inference @ IoU {train_cfg.iou_threshold:.2f}\",\n",
    "    )\n",
    "    emit_metric_lines(metric_lines, logger=LOGGER)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7eab67",
   "metadata": {
    "papermill": {
     "duration": 0.003132,
     "end_time": "2025-10-21T07:01:27.477944",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.474812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed17aed",
   "metadata": {
    "papermill": {
     "duration": 0.002928,
     "end_time": "2025-10-21T07:01:27.483932",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.481004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. 改小lr\n",
    "2. 改小0、16、25、30阈值\n",
    "3. 调整窗口比例((0.2, 0.5, 1.0, 2.0, 5.0),) * len(anchor_sizes)\n",
    "4. 增加epoch次数\n",
    "---\n",
    "5. 改大16阈值，改小25、30阈值\n",
    "6. shuffle dataset\n",
    "---\n",
    "7. 改大 25、30阈值\n",
    "8. 调整RPN比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8be183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T07:01:27.491038Z",
     "iopub.status.busy": "2025-10-21T07:01:27.490804Z",
     "iopub.status.idle": "2025-10-21T09:11:21.526186Z",
     "shell.execute_reply": "2025-10-21T09:11:21.525244Z"
    },
    "papermill": {
     "duration": 7794.040395,
     "end_time": "2025-10-21T09:11:21.527487",
     "exception": false,
     "start_time": "2025-10-21T07:01:27.487092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n",
      "100%|██████████| 167M/167M [00:00<00:00, 200MB/s]\n",
      "/tmp/ipykernel_19/3144854163.py:236: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=train_cfg.amp and device.type == \"cuda\")\n",
      "/tmp/ipykernel_19/87368670.py:110: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.7170 | val loss 0.7185 | mAP 0.1218\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.000 R=0.000  TP=0 FP=0 FN=35 AP=0.000\n",
      "class 02 | P=0.000 R=0.000  TP=0 FP=0 FN=35 AP=0.000\n",
      "class 04 | P=0.000 R=0.000  TP=0 FP=0 FN=27 AP=0.000\n",
      "class 05 | P=0.000 R=0.000  TP=0 FP=0 FN=75 AP=0.000\n",
      "class 06 | P=0.000 R=0.000  TP=0 FP=0 FN=5 AP=0.000\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=0 FN=72 AP=0.000\n",
      "class 09 | P=1.000 R=0.355  TP=11 FP=0 FN=20 AP=0.677\n",
      "class 10 | P=0.000 R=0.000  TP=0 FP=0 FN=45 AP=0.000\n",
      "class 11 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 13 | P=0.000 R=0.000  TP=0 FP=0 FN=85 AP=0.000\n",
      "class 14 | P=0.000 R=0.000  TP=0 FP=0 FN=93 AP=0.000\n",
      "class 15 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 16 | P=0.000 R=0.000  TP=0 FP=0 FN=6 AP=0.000\n",
      "class 18 | P=0.000 R=0.000  TP=0 FP=0 FN=37 AP=0.000\n",
      "class 19 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 20 | P=0.727 R=0.533  TP=8 FP=3 FN=7 AP=0.664\n",
      "class 21 | P=0.000 R=0.000  TP=0 FP=0 FN=7 AP=0.000\n",
      "class 22 | P=1.000 R=0.500  TP=1 FP=0 FN=1 AP=0.750\n",
      "class 23 | P=1.000 R=0.104  TP=5 FP=0 FN=43 AP=0.552\n",
      "class 25 | P=0.000 R=0.000  TP=0 FP=0 FN=3 AP=0.000\n",
      "class 27 | P=0.000 R=0.000  TP=0 FP=0 FN=45 AP=0.000\n",
      "class 28 | P=0.000 R=0.000  TP=0 FP=0 FN=50 AP=0.000\n",
      "class 29 | P=1.000 R=0.045  TP=2 FP=0 FN=42 AP=0.523\n",
      "class 30 | P=0.000 R=0.000  TP=0 FP=0 FN=4 AP=0.000\n",
      "class 31 | P=0.000 R=0.000  TP=0 FP=0 FN=79 AP=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train loss 0.4304 | val loss 0.4355 | mAP 0.5096\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.810 R=0.486  TP=17 FP=4 FN=18 AP=0.684\n",
      "class 02 | P=0.870 R=0.571  TP=20 FP=3 FN=15 AP=0.754\n",
      "class 04 | P=0.826 R=0.704  TP=19 FP=4 FN=8 AP=0.786\n",
      "class 05 | P=0.000 R=0.000  TP=0 FP=0 FN=75 AP=0.000\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=0 FN=72 AP=0.000\n",
      "class 09 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.929\n",
      "class 10 | P=0.515 R=0.756  TP=34 FP=32 FN=11 AP=0.753\n",
      "class 11 | P=0.833 R=0.806  TP=25 FP=5 FN=6 AP=0.887\n",
      "class 13 | P=0.000 R=0.000  TP=0 FP=0 FN=85 AP=0.000\n",
      "class 14 | P=0.000 R=0.000  TP=0 FP=0 FN=93 AP=0.000\n",
      "class 15 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 16 | P=0.400 R=0.333  TP=2 FP=3 FN=4 AP=0.300\n",
      "class 18 | P=0.000 R=0.000  TP=0 FP=0 FN=37 AP=0.000\n",
      "class 19 | P=0.000 R=0.000  TP=0 FP=0 FN=31 AP=0.000\n",
      "class 20 | P=0.733 R=0.733  TP=11 FP=4 FN=4 AP=0.762\n",
      "class 21 | P=1.000 R=0.143  TP=1 FP=0 FN=6 AP=0.571\n",
      "class 22 | P=0.143 R=1.000  TP=2 FP=12 FN=0 AP=0.995\n",
      "class 23 | P=0.922 R=0.979  TP=47 FP=4 FN=1 AP=0.986\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.931 R=0.600  TP=27 FP=2 FN=18 AP=0.785\n",
      "class 28 | P=0.744 R=0.640  TP=32 FP=11 FN=18 AP=0.725\n",
      "class 29 | P=0.761 R=0.795  TP=35 FP=11 FN=9 AP=0.847\n",
      "class 30 | P=0.333 R=0.250  TP=1 FP=2 FN=3 AP=0.208\n",
      "class 31 | P=0.667 R=0.127  TP=10 FP=5 FN=69 AP=0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train loss 0.2919 | val loss 0.3532 | mAP 0.6792\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.718 R=0.800  TP=28 FP=11 FN=7 AP=0.832\n",
      "class 02 | P=0.789 R=0.857  TP=30 FP=8 FN=5 AP=0.892\n",
      "class 04 | P=0.852 R=0.852  TP=23 FP=4 FN=4 AP=0.906\n",
      "class 05 | P=0.893 R=0.667  TP=50 FP=6 FN=25 AP=0.806\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.000 R=0.000  TP=0 FP=1 FN=72 AP=0.000\n",
      "class 09 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.950\n",
      "class 10 | P=0.704 R=0.844  TP=38 FP=16 FN=7 AP=0.880\n",
      "class 11 | P=0.722 R=0.839  TP=26 FP=10 FN=5 AP=0.887\n",
      "class 13 | P=1.000 R=0.024  TP=2 FP=0 FN=83 AP=0.512\n",
      "class 14 | P=0.912 R=0.333  TP=31 FP=3 FN=62 AP=0.626\n",
      "class 15 | P=0.950 R=0.613  TP=19 FP=1 FN=12 AP=0.781\n",
      "class 16 | P=0.286 R=0.333  TP=2 FP=5 FN=4 AP=0.206\n",
      "class 18 | P=1.000 R=0.081  TP=3 FP=0 FN=34 AP=0.541\n",
      "class 19 | P=1.000 R=0.097  TP=3 FP=0 FN=28 AP=0.548\n",
      "class 20 | P=0.786 R=0.733  TP=11 FP=3 FN=4 AP=0.808\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.828\n",
      "class 23 | P=0.870 R=0.979  TP=47 FP=7 FN=1 AP=0.987\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.913\n",
      "class 27 | P=0.971 R=0.756  TP=34 FP=1 FN=11 AP=0.873\n",
      "class 28 | P=0.795 R=0.700  TP=35 FP=9 FN=15 AP=0.782\n",
      "class 29 | P=0.786 R=0.750  TP=33 FP=9 FN=11 AP=0.823\n",
      "class 30 | P=0.091 R=0.250  TP=1 FP=10 FN=3 AP=0.059\n",
      "class 31 | P=0.621 R=0.747  TP=59 FP=36 FN=20 AP=0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train loss 0.2484 | val loss 0.3071 | mAP 0.7506\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.800 R=0.800  TP=28 FP=7 FN=7 AP=0.864\n",
      "class 02 | P=0.800 R=0.914  TP=32 FP=8 FN=3 AP=0.933\n",
      "class 04 | P=0.862 R=0.926  TP=25 FP=4 FN=2 AP=0.950\n",
      "class 05 | P=0.932 R=0.733  TP=55 FP=4 FN=20 AP=0.854\n",
      "class 06 | P=1.000 R=0.800  TP=4 FP=0 FN=1 AP=0.900\n",
      "class 07 | P=0.706 R=0.167  TP=12 FP=5 FN=60 AP=0.412\n",
      "class 09 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.948\n",
      "class 10 | P=0.709 R=0.867  TP=39 FP=16 FN=6 AP=0.882\n",
      "class 11 | P=0.634 R=0.839  TP=26 FP=15 FN=5 AP=0.867\n",
      "class 13 | P=1.000 R=0.059  TP=5 FP=0 FN=80 AP=0.529\n",
      "class 14 | P=0.750 R=0.839  TP=78 FP=26 FN=15 AP=0.865\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.888\n",
      "class 16 | P=0.600 R=0.500  TP=3 FP=2 FN=3 AP=0.566\n",
      "class 18 | P=1.000 R=0.568  TP=21 FP=0 FN=16 AP=0.784\n",
      "class 19 | P=0.917 R=0.710  TP=22 FP=2 FN=9 AP=0.837\n",
      "class 20 | P=0.750 R=0.800  TP=12 FP=4 FN=3 AP=0.766\n",
      "class 21 | P=0.286 R=0.286  TP=2 FP=5 FN=5 AP=0.292\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.828\n",
      "class 23 | P=1.000 R=0.979  TP=47 FP=0 FN=1 AP=0.989\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.894 R=0.933  TP=42 FP=5 FN=3 AP=0.958\n",
      "class 28 | P=0.731 R=0.760  TP=38 FP=14 FN=12 AP=0.809\n",
      "class 29 | P=0.822 R=0.841  TP=37 FP=8 FN=7 AP=0.887\n",
      "class 30 | P=0.250 R=0.500  TP=2 FP=6 FN=2 AP=0.188\n",
      "class 31 | P=0.566 R=0.810  TP=64 FP=49 FN=15 AP=0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train loss 0.2702 | val loss 0.2924 | mAP 0.8014\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.744 R=0.829  TP=29 FP=10 FN=6 AP=0.884\n",
      "class 02 | P=0.756 R=0.971  TP=34 FP=11 FN=1 AP=0.971\n",
      "class 04 | P=0.897 R=0.963  TP=26 FP=3 FN=1 AP=0.973\n",
      "class 05 | P=0.901 R=0.853  TP=64 FP=7 FN=11 AP=0.901\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.962\n",
      "class 07 | P=0.800 R=0.333  TP=24 FP=6 FN=48 AP=0.533\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.981\n",
      "class 10 | P=0.615 R=0.889  TP=40 FP=25 FN=5 AP=0.861\n",
      "class 11 | P=0.758 R=0.806  TP=25 FP=8 FN=6 AP=0.873\n",
      "class 13 | P=0.848 R=0.459  TP=39 FP=7 FN=46 AP=0.653\n",
      "class 14 | P=0.849 R=0.849  TP=79 FP=14 FN=14 AP=0.882\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.905\n",
      "class 16 | P=0.750 R=0.500  TP=3 FP=1 FN=3 AP=0.686\n",
      "class 18 | P=1.000 R=0.676  TP=25 FP=0 FN=12 AP=0.838\n",
      "class 19 | P=0.926 R=0.806  TP=25 FP=2 FN=6 AP=0.886\n",
      "class 20 | P=0.706 R=0.800  TP=12 FP=5 FN=3 AP=0.762\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=0.960 R=1.000  TP=48 FP=2 FN=0 AP=0.995\n",
      "class 25 | P=0.500 R=1.000  TP=3 FP=3 FN=0 AP=0.913\n",
      "class 27 | P=0.894 R=0.933  TP=42 FP=5 FN=3 AP=0.958\n",
      "class 28 | P=0.643 R=0.900  TP=45 FP=25 FN=5 AP=0.906\n",
      "class 29 | P=0.870 R=0.909  TP=40 FP=6 FN=4 AP=0.939\n",
      "class 30 | P=0.143 R=0.250  TP=1 FP=6 FN=3 AP=0.177\n",
      "class 31 | P=0.624 R=0.861  TP=68 FP=41 FN=11 AP=0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train loss 0.2430 | val loss 0.2736 | mAP 0.8187\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.848 R=0.800  TP=28 FP=5 FN=7 AP=0.882\n",
      "class 02 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.940\n",
      "class 04 | P=0.867 R=0.963  TP=26 FP=4 FN=1 AP=0.979\n",
      "class 05 | P=0.915 R=0.867  TP=65 FP=6 FN=10 AP=0.912\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.778 R=0.194  TP=14 FP=4 FN=58 AP=0.491\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.625 R=0.889  TP=40 FP=24 FN=5 AP=0.897\n",
      "class 11 | P=0.676 R=0.806  TP=25 FP=12 FN=6 AP=0.861\n",
      "class 13 | P=0.839 R=0.612  TP=52 FP=10 FN=33 AP=0.719\n",
      "class 14 | P=0.764 R=0.871  TP=81 FP=25 FN=12 AP=0.912\n",
      "class 15 | P=0.900 R=0.871  TP=27 FP=3 FN=4 AP=0.929\n",
      "class 16 | P=0.500 R=0.500  TP=3 FP=3 FN=3 AP=0.540\n",
      "class 18 | P=0.967 R=0.784  TP=29 FP=1 FN=8 AP=0.883\n",
      "class 19 | P=1.000 R=0.871  TP=27 FP=0 FN=4 AP=0.935\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.846\n",
      "class 21 | P=0.800 R=0.571  TP=4 FP=1 FN=3 AP=0.714\n",
      "class 22 | P=0.222 R=1.000  TP=2 FP=7 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.994\n",
      "class 28 | P=0.726 R=0.900  TP=45 FP=17 FN=5 AP=0.916\n",
      "class 29 | P=0.878 R=0.977  TP=43 FP=6 FN=1 AP=0.979\n",
      "class 30 | P=0.143 R=0.250  TP=1 FP=6 FN=3 AP=0.177\n",
      "class 31 | P=0.722 R=0.823  TP=65 FP=25 FN=14 AP=0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train loss 0.2182 | val loss 0.2625 | mAP 0.8238\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.844 R=0.771  TP=27 FP=5 FN=8 AP=0.864\n",
      "class 02 | P=0.744 R=0.914  TP=32 FP=11 FN=3 AP=0.939\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.929 R=0.867  TP=65 FP=5 FN=10 AP=0.915\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.694 R=0.347  TP=25 FP=11 FN=47 AP=0.501\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.714 R=0.889  TP=40 FP=16 FN=5 AP=0.916\n",
      "class 11 | P=0.781 R=0.806  TP=25 FP=7 FN=6 AP=0.877\n",
      "class 13 | P=0.742 R=0.776  TP=66 FP=23 FN=19 AP=0.763\n",
      "class 14 | P=0.872 R=0.882  TP=82 FP=12 FN=11 AP=0.912\n",
      "class 15 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.946\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.721\n",
      "class 18 | P=0.966 R=0.757  TP=28 FP=1 FN=9 AP=0.868\n",
      "class 19 | P=1.000 R=0.903  TP=28 FP=0 FN=3 AP=0.951\n",
      "class 20 | P=0.706 R=0.800  TP=12 FP=5 FN=3 AP=0.815\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.535\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.984\n",
      "class 28 | P=0.815 R=0.880  TP=44 FP=10 FN=6 AP=0.919\n",
      "class 29 | P=0.811 R=0.977  TP=43 FP=10 FN=1 AP=0.968\n",
      "class 30 | P=0.222 R=0.500  TP=2 FP=7 FN=2 AP=0.242\n",
      "class 31 | P=0.680 R=0.861  TP=68 FP=32 FN=11 AP=0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train loss 0.2244 | val loss 0.2720 | mAP 0.8203\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.816 R=0.886  TP=31 FP=7 FN=4 AP=0.922\n",
      "class 02 | P=0.780 R=0.914  TP=32 FP=9 FN=3 AP=0.937\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.928 R=0.853  TP=64 FP=5 FN=11 AP=0.898\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.794 R=0.375  TP=27 FP=7 FN=45 AP=0.569\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.700 R=0.933  TP=42 FP=18 FN=3 AP=0.932\n",
      "class 11 | P=0.743 R=0.839  TP=26 FP=9 FN=5 AP=0.897\n",
      "class 13 | P=0.780 R=0.753  TP=64 FP=18 FN=21 AP=0.784\n",
      "class 14 | P=0.889 R=0.860  TP=80 FP=10 FN=13 AP=0.893\n",
      "class 15 | P=1.000 R=0.806  TP=25 FP=0 FN=6 AP=0.903\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.743\n",
      "class 18 | P=0.969 R=0.838  TP=31 FP=1 FN=6 AP=0.910\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.918\n",
      "class 20 | P=0.750 R=0.800  TP=12 FP=4 FN=3 AP=0.859\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.167 R=1.000  TP=2 FP=10 FN=0 AP=0.745\n",
      "class 23 | P=0.904 R=0.979  TP=47 FP=5 FN=1 AP=0.988\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.987\n",
      "class 28 | P=0.860 R=0.860  TP=43 FP=7 FN=7 AP=0.913\n",
      "class 29 | P=0.792 R=0.955  TP=42 FP=11 FN=2 AP=0.954\n",
      "class 30 | P=0.286 R=0.500  TP=2 FP=5 FN=2 AP=0.214\n",
      "class 31 | P=0.776 R=0.835  TP=66 FP=19 FN=13 AP=0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train loss 0.2363 | val loss 0.2696 | mAP 0.8331\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.744 R=0.914  TP=32 FP=11 FN=3 AP=0.927\n",
      "class 02 | P=0.762 R=0.914  TP=32 FP=10 FN=3 AP=0.943\n",
      "class 04 | P=0.867 R=0.963  TP=26 FP=4 FN=1 AP=0.979\n",
      "class 05 | P=0.903 R=0.867  TP=65 FP=7 FN=10 AP=0.901\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.815 R=0.611  TP=44 FP=10 FN=28 AP=0.681\n",
      "class 09 | P=0.968 R=0.968  TP=30 FP=1 FN=1 AP=0.983\n",
      "class 10 | P=0.782 R=0.956  TP=43 FP=12 FN=2 AP=0.949\n",
      "class 11 | P=0.812 R=0.839  TP=26 FP=6 FN=5 AP=0.899\n",
      "class 13 | P=0.789 R=0.835  TP=71 FP=19 FN=14 AP=0.837\n",
      "class 14 | P=0.889 R=0.860  TP=80 FP=10 FN=13 AP=0.902\n",
      "class 15 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.964\n",
      "class 16 | P=0.600 R=0.500  TP=3 FP=2 FN=3 AP=0.608\n",
      "class 18 | P=0.958 R=0.622  TP=23 FP=1 FN=14 AP=0.781\n",
      "class 19 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.966\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.893\n",
      "class 21 | P=0.500 R=0.571  TP=4 FP=4 FN=3 AP=0.622\n",
      "class 22 | P=0.143 R=1.000  TP=2 FP=12 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.865 R=1.000  TP=45 FP=7 FN=0 AP=0.985\n",
      "class 28 | P=0.846 R=0.880  TP=44 FP=8 FN=6 AP=0.920\n",
      "class 29 | P=0.788 R=0.932  TP=41 FP=11 FN=3 AP=0.926\n",
      "class 30 | P=0.250 R=0.500  TP=2 FP=6 FN=2 AP=0.188\n",
      "class 31 | P=0.725 R=0.835  TP=66 FP=25 FN=13 AP=0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss 0.1676 | val loss 0.2566 | mAP 0.8374\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.861 R=0.886  TP=31 FP=5 FN=4 AP=0.928\n",
      "class 02 | P=0.838 R=0.886  TP=31 FP=6 FN=4 AP=0.926\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.868 R=0.880  TP=66 FP=10 FN=9 AP=0.906\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.788 R=0.569  TP=41 FP=11 FN=31 AP=0.619\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.638 R=0.978  TP=44 FP=25 FN=1 AP=0.944\n",
      "class 11 | P=0.788 R=0.839  TP=26 FP=7 FN=5 AP=0.894\n",
      "class 13 | P=0.734 R=0.812  TP=69 FP=25 FN=16 AP=0.778\n",
      "class 14 | P=0.884 R=0.903  TP=84 FP=11 FN=9 AP=0.917\n",
      "class 15 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 16 | P=0.400 R=0.667  TP=4 FP=6 FN=2 AP=0.566\n",
      "class 18 | P=0.971 R=0.919  TP=34 FP=1 FN=3 AP=0.953\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.960\n",
      "class 20 | P=0.722 R=0.867  TP=13 FP=5 FN=2 AP=0.863\n",
      "class 21 | P=0.800 R=0.571  TP=4 FP=1 FN=3 AP=0.714\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.849 R=1.000  TP=45 FP=8 FN=0 AP=0.989\n",
      "class 28 | P=0.880 R=0.880  TP=44 FP=6 FN=6 AP=0.924\n",
      "class 29 | P=0.804 R=0.932  TP=41 FP=10 FN=3 AP=0.946\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.262\n",
      "class 31 | P=0.708 R=0.797  TP=63 FP=26 FN=16 AP=0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss 0.1759 | val loss 0.2565 | mAP 0.8454\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.806 R=0.829  TP=29 FP=7 FN=6 AP=0.894\n",
      "class 02 | P=0.842 R=0.914  TP=32 FP=6 FN=3 AP=0.945\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.892 R=0.880  TP=66 FP=8 FN=9 AP=0.908\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.855 R=0.653  TP=47 FP=8 FN=25 AP=0.744\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.754 R=0.956  TP=43 FP=14 FN=2 AP=0.957\n",
      "class 11 | P=0.812 R=0.839  TP=26 FP=6 FN=5 AP=0.899\n",
      "class 13 | P=0.779 R=0.788  TP=67 FP=19 FN=18 AP=0.816\n",
      "class 14 | P=0.921 R=0.882  TP=82 FP=7 FN=11 AP=0.925\n",
      "class 15 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.964\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.638\n",
      "class 18 | P=0.970 R=0.865  TP=32 FP=1 FN=5 AP=0.924\n",
      "class 19 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 20 | P=0.778 R=0.933  TP=14 FP=4 FN=1 AP=0.888\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.988\n",
      "class 28 | P=0.898 R=0.880  TP=44 FP=5 FN=6 AP=0.930\n",
      "class 29 | P=0.860 R=0.977  TP=43 FP=7 FN=1 AP=0.967\n",
      "class 30 | P=0.333 R=0.500  TP=2 FP=4 FN=2 AP=0.291\n",
      "class 31 | P=0.730 R=0.823  TP=65 FP=24 FN=14 AP=0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss 0.1996 | val loss 0.2567 | mAP 0.8325\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.816 R=0.886  TP=31 FP=7 FN=4 AP=0.925\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.958\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.917\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.738 R=0.667  TP=48 FP=17 FN=24 AP=0.655\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.764 R=0.933  TP=42 FP=13 FN=3 AP=0.945\n",
      "class 11 | P=0.833 R=0.806  TP=25 FP=5 FN=6 AP=0.887\n",
      "class 13 | P=0.758 R=0.812  TP=69 FP=22 FN=16 AP=0.831\n",
      "class 14 | P=0.905 R=0.925  TP=86 FP=9 FN=7 AP=0.949\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.949\n",
      "class 16 | P=0.667 R=0.667  TP=4 FP=2 FN=2 AP=0.638\n",
      "class 18 | P=0.971 R=0.892  TP=33 FP=1 FN=4 AP=0.941\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.931\n",
      "class 20 | P=0.824 R=0.933  TP=14 FP=3 FN=1 AP=0.874\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.154 R=1.000  TP=2 FP=11 FN=0 AP=0.695\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.900 R=1.000  TP=45 FP=5 FN=0 AP=0.993\n",
      "class 28 | P=0.776 R=0.900  TP=45 FP=13 FN=5 AP=0.931\n",
      "class 29 | P=0.870 R=0.909  TP=40 FP=6 FN=4 AP=0.934\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.326\n",
      "class 31 | P=0.716 R=0.861  TP=68 FP=27 FN=11 AP=0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss 0.1858 | val loss 0.2462 | mAP 0.8512\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.872 R=0.971  TP=34 FP=5 FN=1 AP=0.975\n",
      "class 02 | P=0.825 R=0.943  TP=33 FP=7 FN=2 AP=0.954\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.904 R=0.880  TP=66 FP=7 FN=9 AP=0.915\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.745 R=0.528  TP=38 FP=13 FN=34 AP=0.588\n",
      "class 09 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 10 | P=0.741 R=0.956  TP=43 FP=15 FN=2 AP=0.961\n",
      "class 11 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.903\n",
      "class 13 | P=0.753 R=0.859  TP=73 FP=24 FN=12 AP=0.856\n",
      "class 14 | P=0.926 R=0.935  TP=87 FP=7 FN=6 AP=0.938\n",
      "class 15 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.933\n",
      "class 16 | P=0.400 R=0.667  TP=4 FP=6 FN=2 AP=0.599\n",
      "class 18 | P=0.971 R=0.919  TP=34 FP=1 FN=3 AP=0.950\n",
      "class 19 | P=0.967 R=0.935  TP=29 FP=1 FN=2 AP=0.962\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.898\n",
      "class 21 | P=0.571 R=0.571  TP=4 FP=3 FN=3 AP=0.665\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.900 R=1.000  TP=45 FP=5 FN=0 AP=0.992\n",
      "class 28 | P=0.750 R=0.900  TP=45 FP=15 FN=5 AP=0.931\n",
      "class 29 | P=0.782 R=0.977  TP=43 FP=12 FN=1 AP=0.974\n",
      "class 30 | P=0.222 R=0.500  TP=2 FP=7 FN=2 AP=0.364\n",
      "class 31 | P=0.642 R=0.861  TP=68 FP=38 FN=11 AP=0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss 0.1832 | val loss 0.2566 | mAP 0.8438\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.974\n",
      "class 02 | P=0.767 R=0.943  TP=33 FP=10 FN=2 AP=0.944\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.930 R=0.880  TP=66 FP=5 FN=9 AP=0.915\n",
      "class 06 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 07 | P=0.875 R=0.486  TP=35 FP=5 FN=37 AP=0.691\n",
      "class 09 | P=1.000 R=0.968  TP=30 FP=0 FN=1 AP=0.984\n",
      "class 10 | P=0.754 R=0.956  TP=43 FP=14 FN=2 AP=0.953\n",
      "class 11 | P=0.818 R=0.871  TP=27 FP=6 FN=4 AP=0.916\n",
      "class 13 | P=0.806 R=0.882  TP=75 FP=18 FN=10 AP=0.866\n",
      "class 14 | P=0.913 R=0.903  TP=84 FP=8 FN=9 AP=0.938\n",
      "class 15 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.931\n",
      "class 16 | P=0.714 R=0.833  TP=5 FP=2 FN=1 AP=0.655\n",
      "class 18 | P=0.967 R=0.784  TP=29 FP=1 FN=8 AP=0.887\n",
      "class 19 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.947\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.930\n",
      "class 21 | P=0.500 R=0.429  TP=3 FP=3 FN=4 AP=0.570\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.789 R=1.000  TP=45 FP=12 FN=0 AP=0.994\n",
      "class 28 | P=0.875 R=0.840  TP=42 FP=6 FN=8 AP=0.904\n",
      "class 29 | P=0.857 R=0.955  TP=42 FP=7 FN=2 AP=0.943\n",
      "class 30 | P=0.214 R=0.750  TP=3 FP=11 FN=1 AP=0.214\n",
      "class 31 | P=0.722 R=0.823  TP=65 FP=25 FN=14 AP=0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss 0.1788 | val loss 0.2400 | mAP 0.8539\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.941 R=0.914  TP=32 FP=2 FN=3 AP=0.951\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.950\n",
      "class 04 | P=1.000 R=0.963  TP=26 FP=0 FN=1 AP=0.981\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.896\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.860 R=0.597  TP=43 FP=7 FN=29 AP=0.709\n",
      "class 09 | P=0.912 R=1.000  TP=31 FP=3 FN=0 AP=0.994\n",
      "class 10 | P=0.494 R=0.978  TP=44 FP=45 FN=1 AP=0.934\n",
      "class 11 | P=0.737 R=0.903  TP=28 FP=10 FN=3 AP=0.917\n",
      "class 13 | P=0.776 R=0.894  TP=76 FP=22 FN=9 AP=0.905\n",
      "class 14 | P=0.929 R=0.849  TP=79 FP=6 FN=14 AP=0.896\n",
      "class 15 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.982\n",
      "class 16 | P=0.571 R=0.667  TP=4 FP=3 FN=2 AP=0.695\n",
      "class 18 | P=1.000 R=0.892  TP=33 FP=0 FN=4 AP=0.946\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.965\n",
      "class 20 | P=0.765 R=0.867  TP=13 FP=4 FN=2 AP=0.828\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.978 R=1.000  TP=45 FP=1 FN=0 AP=0.993\n",
      "class 28 | P=0.852 R=0.920  TP=46 FP=8 FN=4 AP=0.947\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.975\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.302\n",
      "class 31 | P=0.728 R=0.848  TP=67 FP=25 FN=12 AP=0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss 0.1420 | val loss 0.2502 | mAP 0.8538\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.917 R=0.943  TP=33 FP=3 FN=2 AP=0.966\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.966\n",
      "class 04 | P=0.794 R=1.000  TP=27 FP=7 FN=0 AP=0.989\n",
      "class 05 | P=0.905 R=0.893  TP=67 FP=7 FN=8 AP=0.904\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.833 R=0.625  TP=45 FP=9 FN=27 AP=0.712\n",
      "class 09 | P=0.838 R=1.000  TP=31 FP=6 FN=0 AP=0.987\n",
      "class 10 | P=0.694 R=0.956  TP=43 FP=19 FN=2 AP=0.949\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.941\n",
      "class 13 | P=0.795 R=0.824  TP=70 FP=18 FN=15 AP=0.861\n",
      "class 14 | P=0.906 R=0.828  TP=77 FP=8 FN=16 AP=0.871\n",
      "class 15 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.945\n",
      "class 16 | P=0.500 R=0.667  TP=4 FP=4 FN=2 AP=0.616\n",
      "class 18 | P=0.889 R=0.865  TP=32 FP=4 FN=5 AP=0.911\n",
      "class 19 | P=0.935 R=0.935  TP=29 FP=2 FN=2 AP=0.949\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.945\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.995\n",
      "class 23 | P=0.941 R=1.000  TP=48 FP=3 FN=0 AP=0.995\n",
      "class 25 | P=0.600 R=1.000  TP=3 FP=2 FN=0 AP=0.995\n",
      "class 27 | P=0.882 R=1.000  TP=45 FP=6 FN=0 AP=0.992\n",
      "class 28 | P=0.900 R=0.900  TP=45 FP=5 FN=5 AP=0.938\n",
      "class 29 | P=0.875 R=0.955  TP=42 FP=6 FN=2 AP=0.973\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.358\n",
      "class 31 | P=0.720 R=0.848  TP=67 FP=26 FN=12 AP=0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss 0.1386 | val loss 0.2581 | mAP 0.8503\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.946\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.968\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.905 R=0.893  TP=67 FP=7 FN=8 AP=0.918\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.823 R=0.708  TP=51 FP=11 FN=21 AP=0.744\n",
      "class 09 | P=0.886 R=1.000  TP=31 FP=4 FN=0 AP=0.992\n",
      "class 10 | P=0.688 R=0.978  TP=44 FP=20 FN=1 AP=0.953\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.940\n",
      "class 13 | P=0.847 R=0.847  TP=72 FP=13 FN=13 AP=0.870\n",
      "class 14 | P=0.903 R=0.903  TP=84 FP=9 FN=9 AP=0.928\n",
      "class 15 | P=0.871 R=0.871  TP=27 FP=4 FN=4 AP=0.912\n",
      "class 16 | P=0.444 R=0.667  TP=4 FP=5 FN=2 AP=0.518\n",
      "class 18 | P=1.000 R=0.838  TP=31 FP=0 FN=6 AP=0.919\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.923\n",
      "class 20 | P=0.824 R=0.933  TP=14 FP=3 FN=1 AP=0.923\n",
      "class 21 | P=0.571 R=0.571  TP=4 FP=3 FN=3 AP=0.665\n",
      "class 22 | P=0.333 R=1.000  TP=2 FP=4 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.992\n",
      "class 28 | P=0.821 R=0.920  TP=46 FP=10 FN=4 AP=0.948\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.972\n",
      "class 30 | P=0.300 R=0.750  TP=3 FP=7 FN=1 AP=0.262\n",
      "class 31 | P=0.729 R=0.886  TP=70 FP=26 FN=9 AP=0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss 0.1343 | val loss 0.2400 | mAP 0.8551\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.868 R=0.943  TP=33 FP=5 FN=2 AP=0.958\n",
      "class 02 | P=0.825 R=0.943  TP=33 FP=7 FN=2 AP=0.948\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.913\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.842 R=0.667  TP=48 FP=9 FN=24 AP=0.737\n",
      "class 09 | P=0.939 R=1.000  TP=31 FP=2 FN=0 AP=0.993\n",
      "class 10 | P=0.811 R=0.956  TP=43 FP=10 FN=2 AP=0.964\n",
      "class 11 | P=0.906 R=0.935  TP=29 FP=3 FN=2 AP=0.959\n",
      "class 13 | P=0.780 R=0.835  TP=71 FP=20 FN=14 AP=0.877\n",
      "class 14 | P=0.933 R=0.903  TP=84 FP=6 FN=9 AP=0.935\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.945\n",
      "class 16 | P=0.556 R=0.833  TP=5 FP=4 FN=1 AP=0.636\n",
      "class 18 | P=1.000 R=0.838  TP=31 FP=0 FN=6 AP=0.919\n",
      "class 19 | P=0.964 R=0.871  TP=27 FP=1 FN=4 AP=0.926\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.935\n",
      "class 21 | P=0.600 R=0.429  TP=3 FP=2 FN=4 AP=0.599\n",
      "class 22 | P=0.250 R=1.000  TP=2 FP=6 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.978 R=1.000  TP=45 FP=1 FN=0 AP=0.992\n",
      "class 28 | P=0.938 R=0.900  TP=45 FP=3 FN=5 AP=0.941\n",
      "class 29 | P=0.811 R=0.977  TP=43 FP=10 FN=1 AP=0.949\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.315\n",
      "class 31 | P=0.731 R=0.861  TP=68 FP=25 FN=11 AP=0.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss 0.1703 | val loss 0.2494 | mAP 0.8560\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.865 R=0.914  TP=32 FP=5 FN=3 AP=0.946\n",
      "class 02 | P=0.750 R=0.943  TP=33 FP=11 FN=2 AP=0.946\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.917 R=0.880  TP=66 FP=6 FN=9 AP=0.908\n",
      "class 06 | P=0.667 R=0.800  TP=4 FP=2 FN=1 AP=0.865\n",
      "class 07 | P=0.827 R=0.597  TP=43 FP=9 FN=29 AP=0.677\n",
      "class 09 | P=0.833 R=0.968  TP=30 FP=6 FN=1 AP=0.980\n",
      "class 10 | P=0.854 R=0.911  TP=41 FP=7 FN=4 AP=0.947\n",
      "class 11 | P=0.906 R=0.935  TP=29 FP=3 FN=2 AP=0.963\n",
      "class 13 | P=0.896 R=0.812  TP=69 FP=8 FN=16 AP=0.878\n",
      "class 14 | P=0.933 R=0.903  TP=84 FP=6 FN=9 AP=0.941\n",
      "class 15 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.947\n",
      "class 16 | P=0.625 R=0.833  TP=5 FP=3 FN=1 AP=0.822\n",
      "class 18 | P=0.943 R=0.892  TP=33 FP=2 FN=4 AP=0.941\n",
      "class 19 | P=0.931 R=0.871  TP=27 FP=2 FN=4 AP=0.925\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.904\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.429 R=1.000  TP=3 FP=4 FN=0 AP=0.995\n",
      "class 27 | P=0.936 R=0.978  TP=44 FP=3 FN=1 AP=0.987\n",
      "class 28 | P=0.815 R=0.880  TP=44 FP=10 FN=6 AP=0.918\n",
      "class 29 | P=0.824 R=0.955  TP=42 FP=9 FN=2 AP=0.948\n",
      "class 30 | P=0.273 R=0.750  TP=3 FP=8 FN=1 AP=0.355\n",
      "class 31 | P=0.747 R=0.899  TP=71 FP=24 FN=8 AP=0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss 0.1537 | val loss 0.2631 | mAP 0.8544\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.780 R=0.914  TP=32 FP=9 FN=3 AP=0.943\n",
      "class 02 | P=0.750 R=0.943  TP=33 FP=11 FN=2 AP=0.944\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.909 R=0.933  TP=70 FP=7 FN=5 AP=0.937\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.773 R=0.708  TP=51 FP=15 FN=21 AP=0.679\n",
      "class 09 | P=0.909 R=0.968  TP=30 FP=3 FN=1 AP=0.982\n",
      "class 10 | P=0.732 R=0.911  TP=41 FP=15 FN=4 AP=0.933\n",
      "class 11 | P=0.903 R=0.903  TP=28 FP=3 FN=3 AP=0.942\n",
      "class 13 | P=0.841 R=0.812  TP=69 FP=13 FN=16 AP=0.874\n",
      "class 14 | P=0.923 R=0.903  TP=84 FP=7 FN=9 AP=0.919\n",
      "class 15 | P=0.900 R=0.871  TP=27 FP=3 FN=4 AP=0.918\n",
      "class 16 | P=0.625 R=0.833  TP=5 FP=3 FN=1 AP=0.689\n",
      "class 18 | P=1.000 R=0.811  TP=30 FP=0 FN=7 AP=0.905\n",
      "class 19 | P=0.966 R=0.903  TP=28 FP=1 FN=3 AP=0.943\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.903\n",
      "class 21 | P=0.750 R=0.429  TP=3 FP=1 FN=4 AP=0.642\n",
      "class 22 | P=0.222 R=1.000  TP=2 FP=7 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.938 R=1.000  TP=45 FP=3 FN=0 AP=0.994\n",
      "class 28 | P=0.917 R=0.880  TP=44 FP=4 FN=6 AP=0.927\n",
      "class 29 | P=0.827 R=0.977  TP=43 FP=9 FN=1 AP=0.962\n",
      "class 30 | P=0.375 R=0.750  TP=3 FP=5 FN=1 AP=0.368\n",
      "class 31 | P=0.667 R=0.886  TP=70 FP=35 FN=9 AP=0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train loss 0.1295 | val loss 0.2599 | mAP 0.8591\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.941\n",
      "class 02 | P=0.805 R=0.943  TP=33 FP=8 FN=2 AP=0.950\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.915 R=0.867  TP=65 FP=6 FN=10 AP=0.905\n",
      "class 06 | P=0.833 R=1.000  TP=5 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.807 R=0.639  TP=46 FP=11 FN=26 AP=0.699\n",
      "class 09 | P=0.882 R=0.968  TP=30 FP=4 FN=1 AP=0.981\n",
      "class 10 | P=0.772 R=0.978  TP=44 FP=13 FN=1 AP=0.967\n",
      "class 11 | P=0.963 R=0.839  TP=26 FP=1 FN=5 AP=0.915\n",
      "class 13 | P=0.863 R=0.812  TP=69 FP=11 FN=16 AP=0.879\n",
      "class 14 | P=0.914 R=0.914  TP=85 FP=8 FN=8 AP=0.938\n",
      "class 15 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.944\n",
      "class 16 | P=0.500 R=0.667  TP=4 FP=4 FN=2 AP=0.692\n",
      "class 18 | P=0.971 R=0.892  TP=33 FP=1 FN=4 AP=0.938\n",
      "class 19 | P=1.000 R=0.839  TP=26 FP=0 FN=5 AP=0.919\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.911\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.685\n",
      "class 22 | P=0.500 R=1.000  TP=2 FP=2 FN=0 AP=0.828\n",
      "class 23 | P=0.960 R=1.000  TP=48 FP=2 FN=0 AP=0.995\n",
      "class 25 | P=1.000 R=1.000  TP=3 FP=0 FN=0 AP=0.995\n",
      "class 27 | P=0.938 R=1.000  TP=45 FP=3 FN=0 AP=0.995\n",
      "class 28 | P=0.849 R=0.900  TP=45 FP=8 FN=5 AP=0.938\n",
      "class 29 | P=0.792 R=0.955  TP=42 FP=11 FN=2 AP=0.947\n",
      "class 30 | P=0.231 R=0.750  TP=3 FP=10 FN=1 AP=0.510\n",
      "class 31 | P=0.732 R=0.899  TP=71 FP=26 FN=8 AP=0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train loss 0.1403 | val loss 0.2596 | mAP 0.8675\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.865 R=0.914  TP=32 FP=5 FN=3 AP=0.947\n",
      "class 02 | P=0.829 R=0.971  TP=34 FP=7 FN=1 AP=0.955\n",
      "class 04 | P=0.963 R=0.963  TP=26 FP=1 FN=1 AP=0.981\n",
      "class 05 | P=0.896 R=0.920  TP=69 FP=8 FN=6 AP=0.932\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.864 R=0.708  TP=51 FP=8 FN=21 AP=0.781\n",
      "class 09 | P=0.857 R=0.968  TP=30 FP=5 FN=1 AP=0.981\n",
      "class 10 | P=0.786 R=0.978  TP=44 FP=12 FN=1 AP=0.964\n",
      "class 11 | P=0.848 R=0.903  TP=28 FP=5 FN=3 AP=0.934\n",
      "class 13 | P=0.812 R=0.812  TP=69 FP=16 FN=16 AP=0.850\n",
      "class 14 | P=0.902 R=0.892  TP=83 FP=9 FN=10 AP=0.920\n",
      "class 15 | P=0.867 R=0.839  TP=26 FP=4 FN=5 AP=0.905\n",
      "class 16 | P=0.714 R=0.833  TP=5 FP=2 FN=1 AP=0.811\n",
      "class 18 | P=0.943 R=0.892  TP=33 FP=2 FN=4 AP=0.942\n",
      "class 19 | P=0.929 R=0.839  TP=26 FP=2 FN=5 AP=0.913\n",
      "class 20 | P=0.875 R=0.933  TP=14 FP=2 FN=1 AP=0.911\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.657\n",
      "class 22 | P=0.286 R=1.000  TP=2 FP=5 FN=0 AP=0.995\n",
      "class 23 | P=0.980 R=1.000  TP=48 FP=1 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=1.000 R=1.000  TP=45 FP=0 FN=0 AP=0.995\n",
      "class 28 | P=0.833 R=0.900  TP=45 FP=9 FN=5 AP=0.934\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.968\n",
      "class 30 | P=0.250 R=0.750  TP=3 FP=9 FN=1 AP=0.431\n",
      "class 31 | P=0.750 R=0.873  TP=69 FP=23 FN=10 AP=0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train loss 0.1326 | val loss 0.2610 | mAP 0.8554\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=41 AP=0.000\n",
      "class 01 | P=0.821 R=0.914  TP=32 FP=7 FN=3 AP=0.947\n",
      "class 02 | P=0.791 R=0.971  TP=34 FP=9 FN=1 AP=0.957\n",
      "class 04 | P=0.929 R=0.963  TP=26 FP=2 FN=1 AP=0.980\n",
      "class 05 | P=0.918 R=0.893  TP=67 FP=6 FN=8 AP=0.916\n",
      "class 06 | P=0.714 R=1.000  TP=5 FP=2 FN=0 AP=0.995\n",
      "class 07 | P=0.862 R=0.694  TP=50 FP=8 FN=22 AP=0.747\n",
      "class 09 | P=0.857 R=0.968  TP=30 FP=5 FN=1 AP=0.981\n",
      "class 10 | P=0.854 R=0.911  TP=41 FP=7 FN=4 AP=0.943\n",
      "class 11 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.945\n",
      "class 13 | P=0.787 R=0.824  TP=70 FP=19 FN=15 AP=0.839\n",
      "class 14 | P=0.884 R=0.903  TP=84 FP=11 FN=9 AP=0.910\n",
      "class 15 | P=0.933 R=0.903  TP=28 FP=2 FN=3 AP=0.948\n",
      "class 16 | P=0.462 R=1.000  TP=6 FP=7 FN=0 AP=0.760\n",
      "class 18 | P=0.939 R=0.838  TP=31 FP=2 FN=6 AP=0.910\n",
      "class 19 | P=0.938 R=0.968  TP=30 FP=2 FN=1 AP=0.968\n",
      "class 20 | P=0.812 R=0.867  TP=13 FP=3 FN=2 AP=0.870\n",
      "class 21 | P=0.667 R=0.571  TP=4 FP=2 FN=3 AP=0.630\n",
      "class 22 | P=0.400 R=1.000  TP=2 FP=3 FN=0 AP=0.828\n",
      "class 23 | P=1.000 R=1.000  TP=48 FP=0 FN=0 AP=0.995\n",
      "class 25 | P=0.750 R=1.000  TP=3 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.918 R=1.000  TP=45 FP=4 FN=0 AP=0.995\n",
      "class 28 | P=0.860 R=0.860  TP=43 FP=7 FN=7 AP=0.913\n",
      "class 29 | P=0.843 R=0.977  TP=43 FP=8 FN=1 AP=0.959\n",
      "class 30 | P=0.214 R=0.750  TP=3 FP=11 FN=1 AP=0.452\n",
      "class 31 | P=0.693 R=0.886  TP=70 FP=31 FN=9 AP=0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer: 100%|██████████| 200/200 [00:37<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference @ IoU 0.50 | mAP 0.8599\n",
      "class 00 | P=0.000 R=0.000  TP=0 FP=0 FN=8 AP=0.000\n",
      "class 01 | P=0.967 R=0.989  TP=89 FP=3 FN=1 AP=0.994\n",
      "class 02 | P=0.889 R=0.941  TP=16 FP=2 FN=1 AP=0.927\n",
      "class 04 | P=1.000 R=0.842  TP=16 FP=0 FN=3 AP=0.921\n",
      "class 05 | P=0.647 R=0.917  TP=11 FP=6 FN=1 AP=0.943\n",
      "class 06 | P=0.500 R=1.000  TP=1 FP=1 FN=0 AP=0.995\n",
      "class 07 | P=0.909 R=0.741  TP=20 FP=2 FN=7 AP=0.823\n",
      "class 09 | P=0.952 R=1.000  TP=20 FP=1 FN=0 AP=0.983\n",
      "class 10 | P=0.917 R=0.957  TP=22 FP=2 FN=1 AP=0.974\n",
      "class 11 | P=1.000 R=0.944  TP=17 FP=0 FN=1 AP=0.972\n",
      "class 13 | P=0.733 R=0.917  TP=22 FP=8 FN=2 AP=0.928\n",
      "class 14 | P=1.000 R=0.909  TP=20 FP=0 FN=2 AP=0.955\n",
      "class 15 | P=0.894 R=0.854  TP=76 FP=9 FN=13 AP=0.890\n",
      "class 16 | P=0.667 R=1.000  TP=2 FP=1 FN=0 AP=0.828\n",
      "class 17 | P=0.000 R=0.000  TP=0 FP=0 FN=2 AP=0.000\n",
      "class 18 | P=0.918 R=0.817  TP=67 FP=6 FN=15 AP=0.864\n",
      "class 19 | P=0.975 R=0.898  TP=79 FP=2 FN=9 AP=0.945\n",
      "class 20 | P=1.000 R=1.000  TP=5 FP=0 FN=0 AP=0.995\n",
      "class 21 | P=0.556 R=0.625  TP=5 FP=4 FN=3 AP=0.692\n",
      "class 22 | P=0.800 R=1.000  TP=4 FP=1 FN=0 AP=0.995\n",
      "class 23 | P=1.000 R=0.958  TP=23 FP=0 FN=1 AP=0.979\n",
      "class 25 | P=0.500 R=1.000  TP=1 FP=1 FN=0 AP=0.995\n",
      "class 27 | P=0.905 R=0.864  TP=19 FP=2 FN=3 AP=0.925\n",
      "class 28 | P=0.950 R=0.864  TP=19 FP=1 FN=3 AP=0.928\n",
      "class 29 | P=0.909 R=0.909  TP=20 FP=2 FN=2 AP=0.948\n",
      "class 30 | P=1.000 R=1.000  TP=2 FP=0 FN=0 AP=0.995\n",
      "class 31 | P=0.583 R=0.933  TP=14 FP=10 FN=1 AP=0.823\n"
     ]
    }
   ],
   "source": [
    "dataset_cfg = DatasetConfig(base_dir=Path('/kaggle/input/electrical-component/dataset_1021/dataset'))\n",
    "train_cfg = TrainingConfig(epochs=23, batch_size=2, augmentation=True)\n",
    "inference_cfg = InferenceConfig(score_threshold=0.6, draw_ground_truth=True)\n",
    "\n",
    "model, history = train_pipeline(dataset_cfg, train_cfg)\n",
    "metrics = run_inference(\n",
    "    dataset_cfg,\n",
    "    inference_cfg,\n",
    "    train_cfg,\n",
    "    checkpoint_path=train_cfg.checkpoint_path,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b145413",
   "metadata": {
    "papermill": {
     "duration": 0.800242,
     "end_time": "2025-10-21T09:11:23.026892",
     "exception": false,
     "start_time": "2025-10-21T09:11:22.226650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**提示：** `run_inference` 会在返回的 `metrics` 中附带 `false_positive_images` 和 `false_positive_stems`。 如果想在下一次训练时忽略这些样本，可以将 `TrainingConfig.exclude_samples` 设为 `tuple(metrics[\"false_positive_stems\"])`，或将 `metrics[\"false_positive_stems\"]` 写入文本文件， 然后通过命令行参数 `--exclude-list` 传入。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8456082,
     "sourceId": 13448831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7814.129974,
   "end_time": "2025-10-21T09:11:26.346868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-21T07:01:12.216894",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
